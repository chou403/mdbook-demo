<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>chou401</title>
        <meta name="robots" content="noindex" />


        <!-- Custom HTML head -->
        
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->

    </head>
    <body>
    <div id="body-container">
        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var html = document.querySelector('html');
            var sidebar = null;
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="算法.html">算法</a></li><li class="chapter-item expanded affix "><a href="阻塞队列.html">阻塞队列</a></li><li class="chapter-item expanded affix "><a href="CompletableFuture.html">CompletableFuture</a></li><li class="chapter-item expanded affix "><a href="docker.html">docker</a></li><li class="chapter-item expanded affix "><a href="GC.html">GC</a></li><li class="chapter-item expanded affix "><a href="interview.html">interview</a></li><li class="chapter-item expanded affix "><a href="JDBC.html">JDBC</a></li><li class="chapter-item expanded affix "><a href="jenkins.html">jenkins</a></li><li class="chapter-item expanded affix "><a href="Lock.html">Lock</a></li><li class="chapter-item expanded affix "><a href="MQ.html">MQ</a></li><li class="chapter-item expanded affix "><a href="Mybatis.html">Mybatis</a></li><li class="chapter-item expanded affix "><a href="Mysql.html">Mysql</a></li><li class="chapter-item expanded affix "><a href="Netty.html">Netty</a></li><li class="chapter-item expanded affix "><a href="Slf4j.html">Slf4j</a></li><li class="chapter-item expanded affix "><a href="Spring.html">Spring</a></li><li class="chapter-item expanded affix "><a href="ThreadPoolExecutor.html">ThreadPoolExecutor</a></li><li class="chapter-item expanded affix "><a href="tools-install.html">tools-install</a></li><li class="chapter-item expanded affix "><a href="typora.html">typora</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <!-- Track and set sidebar scroll position -->
        <script>
            var sidebarScrollbox = document.querySelector('#sidebar .sidebar-scrollbox');
            sidebarScrollbox.addEventListener('click', function(e) {
                if (e.target.tagName === 'A') {
                    sessionStorage.setItem('sidebar-scroll', sidebarScrollbox.scrollTop);
                }
            }, { passive: true });
            var sidebarScrollTop = sessionStorage.getItem('sidebar-scroll');
            sessionStorage.removeItem('sidebar-scroll');
            if (sidebarScrollTop) {
                // preserve sidebar scroll position when navigating via links within sidebar
                sidebarScrollbox.scrollTop = sidebarScrollTop;
            } else {
                // scroll sidebar to current active section when navigating via "next/previous chapter" buttons
                var activeSection = document.querySelector('#sidebar .active');
                if (activeSection) {
                    activeSection.scrollIntoView({ block: 'center' });
                }
            }
        </script>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">chou401</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="算法"><a class="header" href="#算法">算法</a></h1>
<h2 id="算法复杂度"><a class="header" href="#算法复杂度">算法复杂度</a></h2>
<p>算法的复杂度：复杂度分析、事后统计法、大O表示法、时间复杂度。</p>
<h3 id="时间复杂度分析"><a class="header" href="#时间复杂度分析">时间复杂度分析</a></h3>
<p>衡量算法运行速度的指标。</p>
<ul>
<li>
<p>只关注循环执行次数最多的一段代码。</p>
</li>
<li>
<p>总复杂度等于最高阶项的复杂度。</p>
</li>
<li>
<p>嵌套代码的复杂度等于嵌套内外代码复杂度的乘积。</p>
<p>推导大O阶：</p>
<ol>
<li>用常数1取代运行时间中的所有加法常数。</li>
<li>在修改后的运行次数函数中，只保留最高阶项。</li>
<li>如果最高阶项存在切不是1，则去除与这个项相乘的常数。得到的结果就是大O阶。</li>
</ol>
<p>常见的时间复杂度：</p>
<ol>
<li>O(1) 常数阶</li>
<li>O(n) 线性阶</li>
<li>O(n<sup>2</sup>) 平方阶</li>
<li>O(logn) 对数阶</li>
<li>O(nlogn) 线性对数阶</li>
<li>O(n<sup>3</sup>) 立方阶</li>
<li>O(2<sup>n</sup>) 指数阶</li>
<li>O(n!) 阶乘阶</li>
</ol>
<p>从小到大依次是：</p>
<ul>
<li>O(1)&lt;O(logn)&lt;O(n)&lt;O(nlogn)&lt;O(n<sup>2</sup>)&lt;O(n<sup>3</sup>)&lt;O(2<sup>n</sup>)&lt;O(n!)&lt;O(n<sup>n</sup>)。</li>
</ul>
</li>
</ul>
<h3 id="空间复杂度"><a class="header" href="#空间复杂度">空间复杂度</a></h3>
<p>衡量程序运行临时占用存储空间大小的指标。</p>
<ul>
<li>
<p>算法的存储量包括：</p>
<ol>
<li>程序本身所占空间。</li>
<li>输入数据所占空间。</li>
<li>辅助变量所占空间。</li>
</ol>
</li>
<li>
<p>输入数据所占空间只取决于问题本身，和算法无关，则只需分析除输入和程序之外的辅助变量所占额外空间。</p>
</li>
<li>
<p>空间复杂度对一个算法在运行过程中临时占用的存储空间大小的量度，一般也作为问题规模n的函数，以数量级形式给出，记作：S(n)=O(g(n))。</p>
<ul>
<li>
<p>g(n)的计算规则和时间复杂度一致。</p>
<ul>
<li>
<p>分析1</p>
<pre><code class="language-java">public int fun(int n){
        int i,j,k,s;
        s=0;
        for (i=0;i&lt;=n;i++)
            for (j=0;j&lt;=i;j++)
                for (k=0;k&lt;=j;k++)
                    s++;
        return(s);
    }
</code></pre>
<p>由于算法中临时标量的个数与问题规模n无关，所以空间复杂度均为S(n) = O(1)。</p>
</li>
<li>
<p>分析2</p>
<pre><code class="language-java">public void fun(int a[], int n, int k) {
        int i;
        if (k == n - 1) {
            for (i = 0; i &lt; n; i++) {
                //执行n次
                System.out.println(a[i]);
            }
        } else {
            for (i = k; i &lt; n; i++) {
                //执行n-k次
                a[i] = a[i] + i * i;
            }
            fun(a, n, k + 1);
        }
    }
</code></pre>
<p>S(n) = O(g(1*n))，此方法属于递归算法，每次调用本身都要分配空间，fun(a,n,0)的空间复杂度为O(n)。</p>
</li>
</ul>
</li>
</ul>
<p>注意：</p>
<ol>
<li>空间复杂度相比时间复杂度分析要少。</li>
<li>对于递归算法来说，代码一般都比较简短，算法本身所占用的存储空间较少，但运行时需要占用较多的临时工作单元。</li>
<li>若写成非递归算法，代码一般可能比较长，算法本身占用的存储空间较多，但运行时将可能需要较少的存储单元。</li>
</ol>
</li>
</ul>
<h3 id="递归"><a class="header" href="#递归">递归</a></h3>
<ol>
<li>一个问题的解可以分解为几个子问题的解。</li>
<li>这个问题与分解之后的子问题，除了数据规模不同，求解思路完全一样。</li>
<li>存在基线/终止条件。</li>
</ol>
<h3 id="栈和队列"><a class="header" href="#栈和队列">栈和队列</a></h3>
<ol>
<li>栈(堆栈)：后进先出的结构，简称LIFO结构。</li>
<li>队列：先进先出的结构，简称FIFO结构。</li>
</ol>
<h3 id="树"><a class="header" href="#树">树</a></h3>
<p>树是n(n&gt;=0) 个结点的有限集。n=0时称为空数。在任何一棵非空树中：</p>
<ol>
<li>有且仅有一个特定的称为跟(Root)的结点。</li>
<li>当n&gt;1时，其余结点可分为m(m&gt;0)个互不相交的有限集T1、T2、...、Tm，其中每一个集合本身又是一棵树，并且称为跟的子树(SubTree)。</li>
</ol>
<p><strong>树的度</strong>：</p>
<ul>
<li>结点拥有的字段数量称为结点的度。根据各个结点的度的不同，结点可以分为：
<ul>
<li>叶子结点：度为0的结点。</li>
<li>分支结点：度不为0
<ul>
<li>内部结点：除了跟结点之外，分支结点也叫作内部结点。</li>
</ul>
</li>
</ul>
</li>
<li>树的度是树内各结点的度的最大值。</li>
</ul>
<p><strong>结点间关系</strong>：</p>
<ul>
<li>当前结点的子树的跟称为该结点的孩子(子结点)。</li>
<li>当前结点称为其子结点的双亲【因为当前结点只有一个，所以叫做双亲结点，而不是父/母结点】。</li>
<li>同一个双亲的孩子之间互称为兄弟。</li>
<li>结点的祖先是从跟结点到当前结点所经分支上的所有结点。</li>
<li>以某结点为跟的子树中任一结点都称为该结点的子孙。</li>
</ul>
<p><strong>树的深度</strong>(层)：</p>
<ul>
<li>结点的层：从跟结点开始，跟结点为第一层，根的孩子为第二层。若某结点为第i层，则其子树的跟就在第i+1层。</li>
<li>其双亲在同一层的结点互为堂兄弟。</li>
<li>树中结点的最大层次称为树的深度。</li>
</ul>
<p>结点的高度=结点到叶子结点的最长路径(边数)。</p>
<p>结点的深度=跟结点到这个结点所经历的边的个数。</p>
<p>结点的层数=结点的深度+1。</p>
<p>树的高度==跟结点的高度。</p>
<p><strong>树的有序性</strong>：</p>
<ul>
<li>如果树中结点的各子树从左向右是有序的，子树间不能互换位置，则称该树为有序树，否则为无序树。</li>
</ul>
<p><strong>二叉树</strong>：</p>
<ul>
<li>二叉树是n(n&gt;=0)个结点的有限集合，该集合或者为空集。或者由一个根结点和两棵互不相交的、分别称为跟结点的左子树和右子树的二叉树组成。</li>
<li>特殊二叉树、斜树、满二叉树、完全二叉树。
<ul>
<li>满二叉树：
<ul>
<li>二叉树中除了叶子结点，每个结点的度都为2。</li>
<li>满二叉树钟第i层的结点数为2<sup>n-1</sup> 个。</li>
<li>满二叉树为k的满二叉树必有2<sup>k</sup>-1个结点，叶子数为2<sup>k-1</sup>。</li>
<li>满二叉树中不存在度为1的结点，每个分支点钟都有两棵深度相同的子树，切叶子结点都在最底层。</li>
<li>具有n个结点的满二叉树的深度为log<sub>2</sub>(n+1)。</li>
</ul>
</li>
<li>完全二叉树：
<ul>
<li>二叉树中除去最后一层结点为满二叉树，且最后一层的结点依次从左到右分布。</li>
<li>对于位置为k的结点，左子结点=2<em>k+1,右子结点=2</em>(k+1)。</li>
<li>最后一个非叶结点的位置为(n/2)-1,n为数组长度。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="排序"><a class="header" href="#排序">排序</a></h2>
<p><img src="https://github.com/chou401/pic-md/raw/master/img/image-20230201155528854.png" alt="image-20230201155528854" /></p>
<h3 id="冒泡排序"><a class="header" href="#冒泡排序">冒泡排序</a></h3>
<p>一种简单的排序算法。它重复地走访过要排序的数列，一次比较两个元素，如果它们的顺序错误就把它们交换过来。走访数列的工作室重复地进行直到没有再需要交换，也就是说该数列已排序完成。这个算法的名字又来是因为元素会经由交换慢慢‘浮’到数列的顶端。</p>
<ol>
<li>比较响铃的元素。如果第一个比第二个大，就交换它们两个;</li>
<li>对每一对相邻元素做同样的工作，从开始第一队到结尾的最后一对，这样在最后的元素应该会是最大的数;</li>
<li>针对所有的元素重复以上的步骤，除了最后一个;</li>
<li>重复步骤1~3，直到排序完成。</li>
</ol>
<h3 id="选择排序"><a class="header" href="#选择排序">选择排序</a></h3>
<p>选择排序的思想其实和冒泡排序有点类似，选择排序可以看成冒泡排序的优化。</p>
<ul>
<li>首先，找到数组中最大（小）的那个元素;</li>
<li>其次，将它和数组的第一个元素交换位置（如果第一个元素就是最大（小）元素那么它就和自己交换）;</li>
<li>再次，在剩下的元素中找到最大（小）的元素，将它与数组的第二个元素交换位置。如此往复，直到将整个数组排序；</li>
<li>这种方法叫做选择排序，因为它在不断地选择剩余元素之中的最大（小）者。</li>
</ul>
<h3 id="插入排序"><a class="header" href="#插入排序">插入排序</a></h3>
<ul>
<li>对于未排序数据，在已排序序列中从后往前扫描，找到对应位置并插入。</li>
<li>为了给要插入的元素腾出空间，我们需要将插入位置之后的已排序元素在都向右移动一位。插入排序所需的时间取决于输入中元素的初始顺序。例如，对一个很大且其中的元素已经有序（或接近有序）的数组进行排序将会比对随机书序的数组或是逆序数组进行排序要快很多。总的来说，插入排序对于部分有序的数组十分高效，也很适合小规模数组。</li>
</ul>
<h3 id="快速排序"><a class="header" href="#快速排序">快速排序</a></h3>
<ul>
<li>
<p>快速排序是对冒泡排序的一种改进，也是采用分治法的一个典型的应用。</p>
</li>
<li>
<p>首先任意选取一个数据（比如数组中的第一个数）作为关键数据，我们称为基准数，然后将所有比它小的数都放到它前面，所有比它大的数都放到它后面，这个过程称为一趟快速排序，也称为分区操作。</p>
</li>
<li>
<p>通过一趟快速排序将要排序的数据分隔成独立的两部分，其中一部分的所有数据都比另外一部分的所有数据都要小，然后再按此方法对这两部分数据分别进行快速排序，整个排序过程可以递归进行，以此达到整个数据变成有序序列。</p>
<h5 id="快速排序中的基准数"><a class="header" href="#快速排序中的基准数">快速排序中的基准数</a></h5>
</li>
<li>
<p>基准的选取：最优的情况是基准值刚好取在无序区的中间，这样能够最大效率地让两边排序，同时最大地减少递归划分的次数，但是一般很难做到最优。基准的选取一般有三种方式，选取数组的第一个元素，选取数组的最后一个元素，以及选取第一个、最后一个以及中间的元素的中位数（如4 5 6 7，第一个4，最后一个7，中间的为5，这三个数的中位数为5，所以选择5作为基准）。</p>
</li>
<li>
<p>Dual-Pivot快排：两个基准数的快速排序算法，其实就是用两个基准数，把整个数组分成三份来进行快速排序，在这种新的算法下面，比经典快排从实验来看节省了10%的时间。
<strong>为了提升性能，有时我们在分隔后独立的两部分的个数小于某个数（比如15）的情况下，会采用其他排序算法，比如插入排序。</strong></p>
</li>
</ul>
<h3 id="希尔排序"><a class="header" href="#希尔排序">希尔排序</a></h3>
<ul>
<li>
<p>一种基于插入排序的快速的排序算法。简单插入排序对于大规模乱序数组很慢，因为元素只能一点一点地从数组的一端移动到另一端。</p>
</li>
<li>
<p>希尔排序为了加快速度简单地改进了插入排序，也称为缩小增量排序，同时该算法是冲破O(n<sup>2</sup>)的第一批算法之一。</p>
</li>
<li>
<p>希尔排序是把记录按下标的一定增量分组，对每组使用直接插入排序算法排序；然后缩小增量继续分组排序，随着增量逐渐减少，每组包含的关键字越来越多，当增量减至1时，整个文件恰被分成一组，再次排序，完成整个数组的排序。这个不断缩小的增量，就构成了一个增量序列。</p>
<h5 id="希尔排序中的增量序列"><a class="header" href="#希尔排序中的增量序列">希尔排序中的增量序列</a></h5>
</li>
<li>
<p>从理论上说，只要一个数组是递减的，并且最后一个值是1，都可以作为增量序列使用，有没有一个步长序列，使得排序过程中所需的比较和移动次数相对较少，并且无论待排序列记录有多少，算法的时间复杂度都能渐近最佳？但是目前从数学上来说，无法证明某个序列是“最好的”。</p>
</li>
<li>
<p>常用的增量序列</p>
<ul>
<li>希尔增量序列：{N/2,(N/2)/2,...,1}，其中N为原始数组的长度，这是最常用的序列，但却不是最好的。</li>
<li>Hibbard序列：{2<sup>k</sup>-1,..,3,1}。</li>
<li>Sedgewick序列：{...,109,41,19,5,1} 表达式为 9<em>4<sup>i</sup>-9</em>2<sup>i</sup>+1或者4<sup>i</sup>-3*2<sup>i</sup>+1。</li>
</ul>
</li>
</ul>
<h3 id="归并排序"><a class="header" href="#归并排序">归并排序</a></h3>
<ul>
<li>对于给定的一组数据，利用递归与分治技术将数据序列划分成为越来越小的半子表，在对半子表排序后，再用递归方法将排好序的半子表合并成为越来越大的有序序列。</li>
<li>为了提升性能，有时我们在半子表的个数小于某个数（比如15）的情况下，对半子表的排序采用其他排序算法，比如插入排序。</li>
<li>若将两个有序表合并成一个有序表，称为2-路归并，与之对应的还有多路归并。</li>
</ul>
<h3 id="堆排序"><a class="header" href="#堆排序">堆排序</a></h3>
<ul>
<li>许多应用程序都需要处理有序的元素，但不一定要求他们全部有序，或者不一定要一次就将他们排序，很多时候，我们每次只需要操作数据中的最大元素（最小元素），那么有一种基于二叉堆的数据结构可提供支持。</li>
<li>所谓二叉堆，是一个完全二叉树的结构，同时满足堆的性质：即子结点的键值或索引总是小于（或者大于）它的父结点。再一个二叉堆中，跟结点总是最大（或者最小）结点，这样堆我们称之为最大（小）堆。</li>
<li>堆排序算法就是抓住了这一特点，每次都取堆顶的元素，然后将剩余的元素重新调整为最大（最小）堆，以此类推，最终得到排序的序列。</li>
</ul>
<h3 id="计数排序"><a class="header" href="#计数排序">计数排序</a></h3>
<ul>
<li>计数排序、基数排序、桶排序三种排序算法都利用了桶的概念，但对桶的使用方法上有差异。</li>
<li>计数排序是一个排序时不比较元素大小的排序算法。</li>
<li>计数排序对一定范围内的整数排序时候的速度非常快，一般快于其他排序算法。但计数排序局限性比较大，只限于对整数进行排序，而且待排序元素值分布较连续、跨度小的情况。</li>
<li>如果一个数组里所有元素都是整数，而且都在 0-k以内。那对于数组里每个元素来说，如果能知道数组里有多少项小于或等于该元素，就能准确给出该元素在排序后的数组的位置。
<img src="https://github.com/chou401/pic-md/raw/master/img/image-20230201143216345.png" alt="image-20230201143216345" />
对于这个数组来说，元素5之前有8个元素小于等于5（含5本身），因此排序后5所在的位置肯定是7，只要构造一个（5+1)
大小的数组，里面存下所有对应A中每个元素之前的元素个数，就能在线性时间内完成排序。</li>
<li>实际应用中我们会同时找出数组中的max和min，主要是为了尽量节省空间。试想[1003,1001,1030,1050]这样的数据要排序，真的需要建立长度为1050+1的数组吗？我们只需要长度为1050-1003+1=48的数组（先不考虑额外+1的长度），就能囊括从最小到最大元素之间的所有元素了。</li>
<li>如果待排序数组的元素值跨度很大，比如[9999,1,2]，为三个元素排序要使用9999-1+1的空间，实在是浪费。所以计数排序适用于待排序元素值分布较连续、跨度小的情况。</li>
</ul>
<h3 id="桶排序"><a class="header" href="#桶排序">桶排序</a></h3>
<ul>
<li>
<p>桶排序是计数排序的升级版。</p>
</li>
<li>
<p>桶排序的工作原理：假设输入数据服从均匀分布，将数据分到有限数量的桶里，每个桶再分别排序（有可能再使用别的排序算法或是以递归方式继续使用桶排序）。</p>
<p><img src="https://github.com/chou401/pic-md/raw/master/img/image-20230201151434039.png" alt="image-20230201151434039" /></p>
</li>
<li>
<p>**在桶排序中保证元素均匀分不到每个桶尤为关键。**举个例子，有数组[0,9,4,5,8,7,6,3,2,1]要排序，它们都是10以下的数，如果还按照上面的范围[0,10)建立桶，全部的元素将进入同一个桶中，此时桶排序就失去了意义。实际情况我们很可能事先就不知道输入数据是什么，为了保证元素均匀分不到各个桶中，需要建立多少个桶，每个桶的范围是什么呢？</p>
<p>其实我们可以这样：简单点，首先限定桶的容量，再根据元素的个数来决定桶的个数。当然使用更复杂的方法也是可以的。</p>
</li>
<li>
<p>桶排序利用函数的映射关系，减少了几乎所有的比较工作。实际上，桶排序的f(k)值得计算，其作用就相当于快排中划分，已经把大量数据分隔成了基本有序的数据块(桶)。然后只需要对桶中的少量数据做先进的比较排序即可。</p>
</li>
</ul>
<h3 id="基数排序"><a class="header" href="#基数排序">基数排序</a></h3>
<ul>
<li>常见的数据元素一般是由若干位组成的，比如字符串由若干字符组成，整数由若干位0~9数字组成。基数排序按照从右往左的顺序，依次将每一位都当做一次关键字，然后按照该关键字对数组的元素入桶，每一轮入桶都基于上轮入桶的结果；完成所有位的入桶后，整个数组就达到有序状态。</li>
<li>比如对于数字2985，从右往左就是先以个位为关键字进行入桶，然后是十位、百位、千位，总共需要四轮。基数排序也是一种无需比较的排序算法。</li>
</ul>
<p><img src="https://github.com/chou401/pic-md/raw/master/img/image-20230201154905705.png" alt="image-20230201154905705" /></p>
<h2 id="位运算"><a class="header" href="#位运算">位运算</a></h2>
<ul>
<li>位运算基本概念：
<ul>
<li>十进制：逢十进一</li>
<li>二进制：逢二进一</li>
</ul>
</li>
<li>负数的表示
<ul>
<li>计算机中负数的表示，是以补码的形式呈现的。</li>
<li><img src="https://github.com/chou401/pic-md/raw/master/img/image-20230208153406112.png" alt="image-20230208153406112" /></li>
</ul>
</li>
<li>常用的位运算
<ul>
<li>按位与 &amp; (1&amp;1=1、0&amp;0=0、1&amp;0=0)</li>
<li>按位或 | (1|1=1、0|0=0、1|0=1)</li>
<li>按位非 ~ (-1=0、~0=1)</li>
<li>按位异或 ^ (1^1=0、1^0=1、0^0=0，很明显任何一个数和自己异或结果一定是0)</li>
<li>有符号右移 &gt;&gt; (若正数，高位补0，负数，高位补1)</li>
<li>有符号左移 &lt;&lt; (低位补0)</li>
<li>无符号右移 &gt;&gt;&gt; (不论正负，高位均补0)</li>
<li>无符号左移 &lt;&lt;&lt; (低位补0)</li>
</ul>
</li>
<li>运用场景
<ul>
<li>网络连接(SelectionKey.java)</li>
<li>HashMap (tableSizeFor)</li>
<li>...</li>
</ul>
</li>
<li>常见简单面试题
<ul>
<li>取模</li>
<li>判断奇偶数</li>
<li>实现数字翻倍或减半</li>
<li>交换两数</li>
</ul>
</li>
</ul>
<h2 id="字符串处理"><a class="header" href="#字符串处理">字符串处理</a></h2>
<ul>
<li>字符串匹配之BF（Bruce Force）算法</li>
<li>字符串匹配之BM（Boyer-Moore）算法
<ul>
<li>坏字符：坏字符的位置 - 模式串中的上一次出现位置</li>
<li>好后缀：好后缀的位置 - 模式串中的上一次出现位置</li>
</ul>
</li>
<li>字符串匹配之KMP（Knuth-Morris-Pratt）算法</li>
</ul>
<h2 id="动态规划"><a class="header" href="#动态规划">动态规划</a></h2>
<h3 id="动态规划定义"><a class="header" href="#动态规划定义">动态规划定义</a></h3>
<p>动态规划是运筹学的一个分支，是求解决策过程最优化的过程。</p>
<p>在现实生活中，有一类活动，由于它的特殊性，可将过程分成若干个互相联系的阶段，在它的每一阶段都需要作出决策，从而使整个过程达到最好的活动效果。因此各个阶段决策的选取不能任意确定，它依赖于当前面临的状态，又影响以后的发展。</p>
<p>所以如果一类活动过程可以分为若干个互相联系的阶段，在每一个阶段都需作出决策，每一个阶段都有若干个策略可供选择，一个阶段的策略确定以后，形成了本阶段的决策，常常影响到下一阶段的决策，从而就完全确定了一个过程的活动路线，则称它为$\textcolor{red}{多阶段决策问题}$。</p>
<p>当各个阶段决策确定后，就组成一个决策序列，因而也就确定了整个过程的一条活动路线。在多阶段决策问题中，决策依赖于当前状态，又随即引起状态的转义，一个决策序列就是在变化的状态中产生出来的，故有“动态”的含义，称这种解决多阶段决策最优化的过程为$\textcolor{red}{动态规划方法}$。</p>
<h3 id="动态规划的解题步骤"><a class="header" href="#动态规划的解题步骤">动态规划的解题步骤</a></h3>
<ol>
<li>
<p>确定状态转移公式，当前的状态是怎么由前面的状态变化而来的及其与之相关联的辅助的dp数组（dp table）以及下标的含义。这一步往往也是最难的，这一步想清楚了，整个动态规划的问题基本上可以说解决了一大半。一般来说，首先要确定dp数组中元素代表的意义，然后在这个意义之下，确定状态是在dp数组的元素之间如何变化的。</p>
</li>
<li>
<p>初始化dp数组。</p>
</li>
<li>
<p>根绝题目条件确定遍历顺序，并实现状态转移公式。</p>
<p>同时在实现的过程中，可以适当的输出dp数组的值，确定自己的代码实现思路无误。</p>
</li>
</ol>
<h3 id="什么样的问题适合用动态规划"><a class="header" href="#什么样的问题适合用动态规划">什么样的问题适合用动态规划？</a></h3>
<p>多阶段决策最优解模型。</p>
<ol>
<li>最优子结构。</li>
<li>无后效性。</li>
<li>重复子问题。</li>
</ol>
<h2 id="埃氏筛和欧拉筛"><a class="header" href="#埃氏筛和欧拉筛">埃氏筛和欧拉筛</a></h2>
<ul>
<li>自然数（非负整数）：从0开始：0,1,2,3,4....。</li>
<li>素数（质数）：指在大于1的自然数中，除了1和它本身以外不再有其它因数的自然数。</li>
<li>合数：指自然数中除了能被1和本身整除外，还能被其他数（0除外）整除的数。</li>
</ul>
<h3 id="埃氏筛"><a class="header" href="#埃氏筛">埃氏筛</a></h3>
<p>埃拉托色尼筛选法，简称埃氏筛法， 是针对自然数列中的自然数而实施的，用于求一定范围内的质数。也就是给定整数n，求小于n的所有质数（素数）。
埃拉托斯特尼筛法，简称埃氏筛或爱氏筛，是一种由希腊数学家埃拉托斯特尼所提出的一种简单检定素数的算法。要得到自然数n以内的全部素数，必须把不大于根号n的所有素数的倍数剔除，剩下的就是素数。</p>
<p><strong>基本思想</strong></p>
<p>从2开始，将每个质数的倍数都标记成合数，以达到筛选素数的目的。</p>
<p><strong>缺陷</strong></p>
<p>对于一个合数，有可能被筛多次。例如 30 = 2<em>15 = 3</em>10 = 5*6……（那么如何确保每个合数只被筛选一次呢？我们只要用它的最小<a href="https://so.csdn.net/so/search?q=%E8%B4%A8%E5%9B%A0%E5%AD%90&amp;spm=1001.2101.3001.7020">质因子</a>来筛选即可）。</p>
<p><strong>代码案例</strong></p>
<p>给出要筛数值的范围n，找出以内的素数。先用2去筛，即把2留下，把2的倍数剔除掉；再用下一个质数，也就是3筛，把3留下，把3的倍数剔除掉；接下去用下一个质数5筛，把5留下，把5的倍数剔除掉；不断重复下去……。</p>
<ol>
<li>首先将0、1排除：</li>
<li>创建从2到n的连续整数列表，[2,3,4,…,n]；</li>
<li>初始化 p = 2，因为2是最小的质数；</li>
<li>枚举所有p的倍数(2p,3p,4p,…)，标记为非质数（合数）；</li>
<li>找到下一个 没有标记 且 大于p 的数。如果没有，结束运算；如果有，将该值赋予p，重复步骤4;</li>
<li>运算结束后，剩下所有未标记的数都是找到的质数。</li>
</ol>
<pre><code class="language-java">public static int eratosthenes(int n) {
    boolean[] isPrime = new boolean[n];// false 代表素数
    int count = 0;
    for(int i = 2;i &lt; n; i++) {
        if(!isPrime[i]) {
            count++;
            for(int j = 2 * i;j &lt; n;j += i) { // j就是合数的标记位
                isPrime[j] = true;
            }
        }
    }
}
</code></pre>
<h3 id="欧拉筛线性筛"><a class="header" href="#欧拉筛线性筛">欧拉筛（线性筛）</a></h3>
<p><strong>前置知识</strong>
正整数的唯一分解定理，即：每个大于1的自然数均可写为质数的积，而且这些素因子按大小排列之后，写法仅有一种方式。</p>
<p>$\textcolor{red}{由唯一分解定理可知，任意一个自然数i必然可以分解为 i = a*b （a为i的最小质因子）}$。</p>
<p>$\textcolor{red}{这里非常重要， 为什么我必须要规定 a为c的最小质因子呢？}$</p>
<pre><code class="language-java">public static int eratosthenes(int n) {
    // 用来存放质数
    int[] set = new int[n + 1];
    // 用来标记合数
    boolean[] bol = new boolean[n + 1];

    int count = 0;
    for (int i = 2; i &lt; n; i++) {
        // 如果 i 是素数 存放在 set 里
        if (!bol[i]){
            // count 统计的目前 质数的个数 正好可以用这个 count 将 质数顺序的存放在 set 集合中
            set[count] = i;
            count++;
        }

        /*
         根据 合数的定义(一个合数肯定是若干素数的乘积) 所以素数的倍数一定是合数
         所以 用 这个素数, 乘以现在已知的其他素数, 那么得到的会是一个个合数 在 bol 中标记
          */
        for (int j = 0; j &lt; count; j++) {
            // 排除掉 超过 n 的合数
            if (i * set[j] &gt; n) break;
            // 为合数在 bol 中做标记
            bol[i*set[j]] = true;
            if (i%set[j] == 0 ) break;
        }

    }
}
</code></pre>
<p>这里prime[j] 就代表质数数组 2，3，5，7…。
不难发现，每一轮循环 ，对于每一个prime[j] （质数），他只用了 i 值 一次，这里也是和埃氏筛法 不同的地方（埃氏筛法是 把每一个素数的 倍数在一个循环内标记完，标记出来的就不是素数）， 而欧拉筛法每次只标记每个质数的i倍，标记出来的就不是素数，这是欧拉筛法的大体方向。</p>
<p>细细思考，这两种方法似乎是一样的 ， 有点类似与 a * b 和 b * a 的感觉。</p>
<p>但是真的是这样吗？</p>
<p>大家都知道， 埃氏筛法会有重复标记，这是不可避免的，因为这个算法一下子标记了一个质数的 2，3，4，5，6…n倍，而就在这 2，3，4，5，6…n 这些数中，还可能分解出更小的质数，而这个更小的质数，在执行它的循环时，肯定标记过 从 2到n中的数，而到这次循环时又标记了一次，这种重复计算 极大的降低了效率，而且没有了优化的空间。</p>
<p>比如 12 = 2*6 在 埃氏筛中， 第一轮 质数2 就已经把 12 给筛走了 但是12 = 3 *4 ，第二轮 质数 3 又筛选了一次。</p>
<p>而欧拉筛呢 ，他是第一轮循环 把 记录的所有质数 的 2 倍给 筛出来， 筛出来的就不是素数，第二轮把记录的所有的质数 的 3倍筛出来，筛出来的就不是素数，第三轮把记录的所有质数的4倍筛出来，筛出来的就不是素数…。
如果仅仅按照这个思路， 欧拉筛和埃氏筛一模一样，就是a * b 和b * a 的关系 。</p>
<p>所以欧拉筛的 精华来了。</p>
<p>if(i % prime[j]==0) break</p>
<p>先告诉你它的作用，防止重复筛选。那为什么呢？</p>
<p>我们来看我们一开始说的内容。
由唯一分解定理可知，任意一个自然数i必然可以 i = a*b （ a为c的最小质因子这里非常重要，为什么我必须要规定 a为c的最小质因子呢？
可能 i 还可以被写成 i = c *d 的形式 ，但我们只要 a * b。
我们举个例子</p>
<p>12 = 2 * 6
12 = 3 * 4
当对12 进行筛选的时候 ，在 12 % 2 ==0 那么直接跳出循环，3没有机会再对12进行标记。</p>
<h2 id="双指针算法"><a class="header" href="#双指针算法">双指针算法</a></h2>
<p>双指针指的是在遍历对象的过程中，不是普通的使用单个指针进行访问，而是使用两个相同方向（快慢指针）或者相反方向（对撞指针）的指针进行扫描，从而达到相应的目的。最常见的双指针算法有两种：一种是，再一个序列里边，用两个指针维护一段区间；另一种是，在两个序列里边，一个指针指向其中一个序列，另外一个指针指向另一个序列，来维护某种次序。</p>
<p>双指针算法的核心思想（作用）：优化。</p>
<p>在利用双指针算法解题时，考虑原问题如何用暴力算法解出，观察是否可构成单调性，若可以，就可采用双指针算法对暴力算法进行优化，当我们采用朴素的方法即暴力枚举每一种可能的情况，时间复杂度为O(n<sup>2</sup>)，而当我们使用双指针算法通过某种性质就可以将上述的O(n<sup>2</sup>)的操作优化到O(n)。</p>
<p><strong>暴力算法和双指针算法区别</strong></p>
<p>由于具有某种单调性，朴素算法往往能优化为双指针算法。</p>
<p>区别：</p>
<ul>
<li>朴素算法每次在第二层遍历的时候，是会从新开始（j会回溯到初始位置）,然后再遍历下去。（假设i是终点，j是起点）。</li>
<li>双指针算法：由于具有某种单调性，每次在第二层遍历的时候，不需要回溯到初始位置（单调性），而是在满足要求的位置继续走下去或者更新掉。</li>
</ul>
<pre><code class="language-java">public static int removeDuplicates(int[] nums) {
    if(nums.length == 0) {
        return 0;
    }
    int i = 0;
    for(int j = 1;j &lt; nums.length; j++){
        if(nums[j] != nums[i]) {
            i++;
            nums[i] = nums[j];
        }
    }
    return i + 1;
}
</code></pre>
<h2 id="二分法"><a class="header" href="#二分法">二分法</a></h2>
<p>二分法通常又叫二分查找，一般用于查找一个有序数组中的某个值的位置或者给定的特定值的插入位置。</p>
<p>相比把整个数组遍历一次的O(n)复杂度，二分查找可以把复杂度降低到O(logn)。</p>
<p>二分法一定是建立在元素有序的前提下（或数据具有二段性），所以看到题目中出现有序数组等词时，并且要求我们查找某个值或者给一个值求插入位置，或者判断其中是否存在某个值或者利用二分思路求最大最小值等。</p>
<p>二分法思路很简单，无非就是每次根据中值判断，然后缩减区间到原来的一半，二分法最容易出错的地方在于边界和细节处理。</p>
<p>二分法的边界模板分为两种：</p>
<ul>
<li>一种是左闭右闭的区间写法[left，right]；while(left &lt;= right) left 的改变为left=mid+1，right的改变为right=mid-1</li>
<li>一种是左闭右开的区间写法[left，right)；while(left &lt; right) left的改变为left=mid+1，right的改变为right=mid</li>
</ul>
<p>x的平方根肯定在0到x之间，使用二分查找定位该数字，该数字的平方一定是最接近x的，m平方值如果大于x，则往左边找，如果小于等于x则往右边找。找到0和x的最中间的数m，如果m * m &gt; x，则m取x/2到x的中间数字，直到m * m &lt; x，m则为平方根的整数部分。</p>
<p>如果m * m &lt; =x，则取0到x/2的中间值，直到两边的界限重合，找到最大的整数，则为x平方根的整数部分。时间复杂度：O(logn)。</p>
<pre><code class="language-java">public static int binarySearch(int x) {
    int index = -1,l = 0,r = x;
    while(l &lt;= r) {
        int mid = l + (r - l)/2;
        if(mid * mid &lt;= x) {
            index = mid;
            l = mid + 1;
        } else {
            r = mid - 1;
        }
    }
    return index;
}
</code></pre>
<h2 id="牛顿迭代"><a class="header" href="#牛顿迭代">牛顿迭代</a></h2>
<p>牛顿迭代法是一种求方程f(x)=0近似解的一种方法。</p>
<p>假设我们现在得到的近似解是xi，然后我们画出在(xi，f(xi))点与曲线相切的直线，该直线与x轴相交会得到一个xi+1。根据导数与直线斜率的关系，我们可以得到：f'(xi)=(f(xi))/(xi-xi+1)。整理后得到如下递推式：xi+1=xi-f(xi)/f'(xi)。根据本递推式我们可以知道如果曲线平滑，随着迭代次数的增加，xi将愈发接近方程的解。牛顿迭代法的收敛率是平方级的，即每次迭代精度会翻倍。然而在方程有多个解时可能最后收敛的结果只会确定少数的解。</p>
<p>应用牛顿-拉弗森方法，要注意以下问题：</p>
<ul>
<li>函数在整个定义域内最好是二阶可导的</li>
<li>起始点对求根计算影响重大，可以增加一些别的判断手段进行试错</li>
</ul>
<p>假设平方根是i，则i和x/i必然都是x的因子，而x/i必然等于i，推导出i + x/i = 2 * i，得出i = (i + x/i) / 2。</p>
<p>由此得出解法，i可以任选一个值，只要上述公式成立，i必然就是x的平方根，如果不成立， (i + x/i) / 2 得出的值进行递归，直至得出正确解。</p>
<pre><code class="language-java">public int newton(int x) {
    if(x == 0) {
        return 0;
    }
    return (int)sqrt(x,x);
}
public double sqrt(double i, int x) {
    double res = (i + x/i)/2;
    if(res == i) {
        return i;
    } else {
        return sqrt(res, x);
    }
}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="阻塞队列"><a class="header" href="#阻塞队列">阻塞队列</a></h1>
<p>先进先出（FIFO）的数据结构，与普通队列不同的是，他支持两个附加操作，即阻塞添加和阻塞删除方法。</p>
<ul>
<li>阻塞添加：当阻塞队列是满时，往队列里添加元素的操作将被阻塞。</li>
<li>阻塞删除：当阻塞队列是空时，从队列中获取元素/删除元素的操作将被阻塞。</li>
</ul>
<p>在多线程中，阻塞的意思是，在某些情况下会 挂起线程，一旦条件成熟，被阻塞的线程就会被自动唤醒。</p>
<p>好处：</p>
<ul>
<li>阻塞队列不用手动控制什么时候该被阻塞，什么时候该被唤醒，简化了操作。</li>
</ul>
<h2 id="blockingqueue"><a class="header" href="#blockingqueue">BlockingQueue</a></h2>
<p>根据插入和取出两种类型的操作，具体分为下面一些类型：</p>
<div class="table-wrapper"><table><thead><tr><th style="text-align: center">方法类型</th><th style="text-align: center">抛出异常</th><th style="text-align: center">返回布尔</th><th style="text-align: center">阻塞</th><th style="text-align: center">超时</th></tr></thead><tbody>
<tr><td style="text-align: center">插入</td><td style="text-align: center">add(E e)</td><td style="text-align: center">offer(E e)</td><td style="text-align: center">put(E e)</td><td style="text-align: center">offer(E e, Time, TimeUnit)</td></tr>
<tr><td style="text-align: center">取出</td><td style="text-align: center">remove()</td><td style="text-align: center">poll()</td><td style="text-align: center">take()</td><td style="text-align: center">poll(Time, TimeUnit)</td></tr>
<tr><td style="text-align: center">对首</td><td style="text-align: center">element()</td><td style="text-align: center">peek()</td><td style="text-align: center">无</td><td style="text-align: center">无</td></tr>
</tbody></table>
</div>
<ul>
<li>抛出异常是指当队列满时，再次插入会抛出异常（如果队列未满，插入返回值为true）。</li>
<li>返回布尔是指当队列满时，再次插入会返回false。</li>
<li>阻塞是指当队列满时，再次插入会被阻塞，直到队列取出一个元素，才能插入。</li>
<li>超市是指当一个时限过后，才会插入或者取出。</li>
</ul>
<blockquote>
<p>生产</p>
<p>add、offer、put这三个方法都是往队列尾部添加元素，区别如下：</p>
<ul>
<li>add：不会阻塞，添加成功时返回true，不响应中断，当队列已满导致添加失败时抛出IllegalStateException。</li>
<li>offer：不会阻塞，添加成功时返回true，因队列已满导致添加失败时返回false，不响应中断。</li>
<li>put：会阻塞，会响应中断。</li>
</ul>
<p>消费</p>
<p>take、poll方法能获取队列头部第一个元素，区别如下：</p>
<ul>
<li>take：会响应中断，会一直阻塞直到取得元素或当前线程中断。</li>
<li>poll：会响应中断，会阻塞，阻塞时间参照方法里参数timeout.timeUnit，当阻塞时间到了还没取得元素会返回null。</li>
</ul>
</blockquote>
<h2 id="arrayblockingqueue"><a class="header" href="#arrayblockingqueue">ArrayBlockingQueue</a></h2>
<ul>
<li>
<p>数据结构：静态数组，容量固定必须指定长度，没有扩容机制，没有元素的下标位置null占位。</p>
</li>
<li>
<p>锁：ReentrantLock 存取时同一把锁，操作的是同一个数组对象。</p>
</li>
<li>
<p>阻塞：</p>
<ul>
<li>
<p>notEmpty，出队：队列count为0，无元素可取时，阻塞在该对象上。</p>
</li>
<li>
<p>notFull，入队：队列count为数组的length，放不进元素时，阻塞在该对象上。</p>
</li>
</ul>
</li>
<li>
<p>入队：从对首开始添加元素，记录putIndex（到队尾时置为0），唤醒notEmpty。</p>
</li>
<li>
<p>出队：从对首开始取元素，记录takeIndex，唤醒notFull。</p>
</li>
<li>
<p>先进先出，读写互相排斥。</p>
</li>
</ul>
<p>由<strong>数组</strong>构成的<strong>有界</strong>阻塞队列，通过<strong>ReentrantLock</strong>和<strong>Condition</strong>条件队列来实现阻塞，一些成员变量如下：</p>
<pre><code class="language-java">    //存储数据
    final Object[] items;

    //返回获取数据的索引，主要用于take、poll、peek、remove方法
    int takeIndex;

    //返回添加数据的索引，主要用于 put、offer、add 方法
    int putIndex;

    // 队列元素的个数
    int count;

    //可重入锁
    final ReentrantLock lock;

    //条件对象，用于通知take方法队列的线程
    private final Condition notEmpty;

    //条件对象，用于通知put方法队列的线程
    private final Condition notFull;

	//迭代器
    transient Itrs itrs = null;


</code></pre>
<p><strong>添加元素原理</strong></p>
<p>添加方法有add，offer，put。</p>
<pre><code class="language-java">//add方法
public boolean add(E e) {
    if (offer(e))
        return true;
    else
        throw new IllegalStateException(&quot;Queue full&quot;);
}

//offer方法
public boolean offer(E e) {
    //判断是否为null
     checkNotNull(e);
     final ReentrantLock lock = this.lock;
     lock.lock();
     try {
         //判断队列是否满
         if (count == items.length)
             return false;
         else {
             //添加元素到队列
             enqueue(e);
             return true;
         }
     } finally {
         lock.unlock();
     }
 }

//元素入队操作
private void enqueue(E x) {
    //获取当前数组
    final Object[] items = this.items;
    //通过putIndex索引对数组进行赋值
    items[putIndex] = x;
    //索引自增，如果已是最后一个位置，重新设置 putIndex = 0;
    if (++putIndex == items.length)
        putIndex = 0;
    //队列中元素数量加1
    count++;
    //唤醒调用take()方法的线程，执行元素获取操作。
    notEmpty.signal();
}
</code></pre>
<p>add方法本质调用的是offer方法，而在offer的最关键处，也就是enqueue入队操作。</p>
<ol>
<li>reentrantLock保证的线程的互斥性，即统一时间只能有一个线程操作。如果队列已满，返回true，add方法则是抛出异常；如果队列未满，则开始入队操作；</li>
<li>在入队操作时，他会通过一个全局变量putIndex作为索引，指引着新来元素的位置。在这里有个小细节，就是判断putIndex是否与队列长度相等，如果队列已满，而且队列的操作时先进先出，索引下一次来插入元素的位置肯定是对头，也就是索引0的位置；</li>
<li>队内已经有元素了，然后开始唤醒take操作来消费元素。signal() 其实是 notify() 的升级版。</li>
</ol>
<p>在添加的操作中，put方法，他是会导致线程阻塞的。</p>
<pre><code class="language-java">//put方法，阻塞时可中断
public void put(E e) throws InterruptedException {
 checkNotNull(e);
  final ReentrantLock lock = this.lock;
  lock.lockInterruptibly();//该方法可中断
  try {
      //当队列元素个数与数组长度相等时，无法添加元素
      while (count == items.length)
          //将当前调用线程挂起，添加到notFull条件队列中等待唤醒
          notFull.await();
      enqueue(e);//如果队列没有满直接添加。。
  } finally {
      lock.unlock();
  }
}
</code></pre>
<p>他是通过condition的await方法来实现阻塞的，但由于又添加了lockInterruptibly标识，说明其阻塞可被打断。</p>
<p><strong>获取元素/删除元素原理</strong></p>
<p>方法有remove，poll，take。</p>
<pre><code class="language-java">public E poll() {
    //reentrantLock互斥锁
    final ReentrantLock lock = this.lock;
    lock.lock();
    try {
        //如果队列为0,返回null，反之进入移除队列
        return (count == 0) ? null : dequeue();
    } finally {
        lock.unlock();
    }
}
//移除队列
private E dequeue() {
    //获取当前队列数据
    final Object[] items = this.items;
    @SuppressWarnings(&quot;unchecked&quot;)
    //获取当前队头数据
    E x = (E) items[takeIndex];
    //将队头数据置为null
    items[takeIndex] = null;
    //如果队头索引自增与数组长度相等，则将其索引设置为第一位
    if (++takeIndex == items.length)
        takeIndex = 0;
    count--;
    if (itrs != null)
        //更新迭代器中的元素数据
        itrs.elementDequeued();
    //唤醒put/offer/add等方法
    notFull.signal();
    return x;
}
</code></pre>
<p>poll方法是通过删除队头数据来进行移除元素，唤醒与沉睡机制采用reentrantLock 的 condition 机制。</p>
<pre><code class="language-java">public E take() throws InterruptedException {
    final ReentrantLock lock = this.lock;
      lock.lockInterruptibly();//中断
      try {
          //队列没有元素，阻塞移除方法的线程
          while (count == 0)
              notEmpty.await();
          //有元素进行元素移除操作
          return dequeue();
      } finally {
          lock.unlock();
      }
}
</code></pre>
<p>take方法跟 poll方法一样，也是通过dequeue() 方法进行移除元素，但不同的是，他会进行一个线程阻塞，也就是运用condition的 awati()方法，同时这个阻塞是可被打断的，关键词lockInterruptibly。</p>
<p>remove() 方法相对来说比较复杂，他跟以上两个方法的不同点在于remove可以根据索引来删除元素，而另两个则是通过删除队列的头元素。</p>
<pre><code class="language-java">public boolean remove(Object o) {
    //确保传入元素不为null
    if (o == null) return false;
    //获取队列当前数据
    final Object[] items = this.items;
    final ReentrantLock lock = this.lock;
    lock.lock();
    try {
        if (count &gt; 0) {
            final int putIndex = this.putIndex;
            int i = takeIndex;
            //找出O元素的索引值
            do {
                if (o.equals(items[i])) {//如果匹配到，删除元素，i为o的索引
                    removeAt(i);
                    return true;
                }
                //只有一个元素时，重置索引值
                if (++i == items.length)
                    i = 0;
            } while (i != putIndex);
        }
        return false;
    } finally {
        lock.unlock();
    }
}
</code></pre>
<p>removeAt() 方法。</p>
<pre><code class="language-java">void removeAt(final int removeIndex) {
    final Object[] items = this.items;
    //判断当前元素是否是头部索引值
    if (removeIndex == takeIndex) {
        items[takeIndex] = null;
        if (++takeIndex == items.length)
            takeIndex = 0;
        count--;
        if (itrs != null)
            itrs.elementDequeued();
    } else {
       //如果不是，通过移动元素位置，将要删除的元素置为队尾删除
        final int putIndex = this.putIndex;
        for (int i = removeIndex;;) {
            //确保当前队列大小大于1
            int next = i + 1;
            if (next == items.length)
                next = 0;
            //如果不是队尾元素，进行元素移动
            if (next != putIndex) {
                items[i] = items[next];
                i = next;
            } else {
                //如果是队尾，元素移动完毕，直接将队尾为null，即删除
                items[i] = null;
                this.putIndex = i;
                break;
            }
        }
        count--;
        if (itrs != null)
            itrs.removedAt(removeIndex);
    }
    notFull.signal();
}
</code></pre>
<h2 id="linkedblockingqueue"><a class="header" href="#linkedblockingqueue">LinkedBlockingQueue</a></h2>
<p>由<strong>链表</strong>构成的<strong>有界</strong>阻塞队列，需要注意的是虽然是有界的，但是其默认大小是Integer.MAX_VALUE，高达21亿，一般情况下内存早爆了（在线程池中ThreadPoolExecutor有体现）。</p>
<ul>
<li>
<p>数据结构：链表Node，可以指定容量，默认为Integer.MAX_VALUE，内部类Node存储元素。</p>
</li>
<li>
<p>锁分离：存取互不排斥，操作的是不同的Node对象。</p>
<ul>
<li>
<p>takeLock：取Node节点保证前驱后继不会乱。</p>
</li>
<li>
<p>putLock：存Node节点保证前驱后继不会乱。</p>
</li>
</ul>
</li>
<li>
<p>阻塞：</p>
<ul>
<li>
<p>notEmpty，出队：队列count为0，无元素可取时，阻塞在该对象上。</p>
</li>
<li>
<p>notFull，入队：队列count为数组的length，放不进元素时，阻塞在该对象上。</p>
</li>
</ul>
</li>
<li>
<p>入队：队尾入队，记录last节点。</p>
</li>
<li>
<p>出队：队首出队，记录head节点。</p>
</li>
<li>
<p>删除元素时两个锁一起加。</p>
</li>
<li>
<p>先进先出。</p>
</li>
</ul>
<h2 id="priorityblockingqueue"><a class="header" href="#priorityblockingqueue">PriorityBlockingQueue</a></h2>
<p>支持优先级排序的无界阻塞队列。</p>
<ul>
<li>数据结构：数组 + 平衡二叉树堆，可以指定初始容量，会自动扩容，最大容量为Integer.MAX_VALUE。</li>
<li>锁：ReenLock存取东一把锁。</li>
<li>阻塞：notEmpty，出队，队列为空是阻塞。</li>
<li>入队：
<ul>
<li>不阻塞，永远返回成功，无界。</li>
<li>根绝比较器进行堆化，根据二叉堆进行排序，自下而上。</li>
</ul>
</li>
<li>出队：
<ul>
<li>弹出堆顶元素。</li>
<li>堆尾元素放到堆顶。</li>
<li>自上而下堆化。</li>
<li>为空则阻塞。</li>
</ul>
</li>
</ul>
<h2 id="delayqueue"><a class="header" href="#delayqueue">DelayQueue</a></h2>
<p>支持优先级的延迟无界阻塞队列。</p>
<h2 id="synchronousqueue"><a class="header" href="#synchronousqueue">SynchronousQueue</a></h2>
<p>单个元素的阻塞队列，队列中只有一个元素，如果想插入多个，必须等队列元素取出后，才能插入，只能有一个“坑位”，用一个插一个。</p>
<ul>
<li>
<p>存取调用同一个方法：transfer。</p>
<ul>
<li>
<p>put、offer为生产者，携带数据e，为Data模式，设置到QNode属性中。</p>
</li>
<li>
<p>take、poll为消费者，不携带数据，为Request模式，设置到QNode属性中。</p>
</li>
</ul>
</li>
<li>
<p>数据结构：链表Node。</p>
</li>
<li>
<p>锁：cas + 自旋。</p>
</li>
<li>
<p>阻塞：LockSupport。</p>
</li>
<li>
<p>判断队尾节点或者栈顶节点Node与入队模式是否相同：</p>
<ul>
<li>
<p>相同则构造节点Node入队，并阻塞当前线程，元素e和相乘赋值给Node属性。</p>
</li>
<li>
<p>不同则将元素e（部位null）返回给取数据线程，配对线程被唤醒，出队。</p>
</li>
</ul>
</li>
<li>
<p>公平模式：TransferQueue，队尾匹配，队头出队，先进先出。</p>
</li>
<li>
<p>非公平模式：TransferStack，栈顶匹配，栈顶出栈，后进先出。</p>
</li>
</ul>
<h2 id="linkedtransferqueue"><a class="header" href="#linkedtransferqueue">LinkedTransferQueue</a></h2>
<p>由链表构成的无界阻塞队列。</p>
<ul>
<li>数据结构：链表Node。</li>
<li>锁：cas + 自旋。</li>
<li>阻塞：LockSupport。</li>
<li>可以自己控制放元素需要阻塞线程，比如使用四个添加元素的方法就不会阻塞线程，只入队元素，使用transfer()会阻塞线程。</li>
<li>取元素与SynchronousQueue基本一样，都会阻塞等待有新的元素进入被匹配到。</li>
</ul>
<h2 id="linkedblockingdeque"><a class="header" href="#linkedblockingdeque">LinkedBlockingDeque</a></h2>
<p>由链表构成的双向阻塞队列。</p>
<h2 id="linkedblockingqueue和arrayblockingqueue区别"><a class="header" href="#linkedblockingqueue和arrayblockingqueue区别">LinkedBlockingQueue和ArrayBlockingQueue区别</a></h2>
<ol>
<li>
<p>队列大小不同：</p>
<ul>
<li>ArrayBlockingQueue在初始化的时候，必须指定队列的大小。</li>
<li>LinkedBlockingQueue在初始化的时候，如果没有指定大小，则会默认Integer.MAX_VALUE，是一个很大的值，这样就会导致数据再一个不可控的范围，一旦添加速度大于移除的速度时，可能会有内存泄露的风险。</li>
</ul>
</li>
<li>
<p>底层实现不同：
ArrayBlockingQueue的底层是一个数组，而LinkedBlockingQueue底层是一个链表结构。官方文档介绍中，LinkedBlockingQueue的吞吐性是高于ArrayBlockingQueue；但是在添加或移除元素，LinkedBlockingQueue则会生成一个额外的Node对象，对GC可能存在影响。</p>
<ul>
<li>
<blockquote>
<p>至于为什么说LinkedBlockingQueue的吞吐性高于ArrayBlockingQueue：</p>
</blockquote>
</li>
</ul>
<blockquote>
<p>吞吐性强是因为有两个锁，Array里面使用的是一个锁，不管put还是take行为，都可能被这个锁卡住，而Linked里put和take是两个锁，put只会被put行为卡住，而不会被take卡住，因此吞吐性能自然强于Array。而“less
predictable performance” 这个也是显而易见的，Array采用的是固定内存，而Linked采用的是动态内存，无论是分配内存还是释放内存（甚至GC）动态内存的性能自然都会比固定内存要差。</p>
</blockquote>
</li>
<li>
<p>锁机制不一样：</p>
<p>ArrayBlockingQueue使用的一个锁控制，LinkedBlockingQueue使用两个锁控制，一个putLock，另一个takeLock，但是锁的本质都是ReentrantLock。</p>
</li>
</ol>
<p>LinkedBlockingQueue是一个基于链表实现的阻塞queue，它的性能ArrayBlockingQueue，但是差于ConcurrentLinkedQueue；并且它非常适于生产者消费者的环境中，比Executors.newFixedThreadPool()。
就是基于这个队列的，使用LinkedBlockingQueue时一定要设置容量，不然会有内存溢出的风险。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="completablefuture"><a class="header" href="#completablefuture">CompletableFuture</a></h1>
<h2 id="supplyasync"><a class="header" href="#supplyasync">supplyAsync</a></h2>
<p>用来开启异步任务。</p>
<pre><code class="language-java">public static void main(String[] args) {
    SmallTool.print(&quot;小白进入餐厅&quot;);
    SmallTool.print(&quot;小白点了菜&quot;);
    CompletableFuture&lt;String&gt; cf = CompletableFuture.supplyAsync(() -&gt; {
        SmallTool.print(&quot;厨师炒菜&quot;);
        SmallTool.sleep(200);
        SmallTool.print(&quot;厨师打饭&quot;);
        SmallTool.sleep(100);
        return &quot;菜 做好了&quot;;
    });

    SmallTool.print(&quot;小白在打游戏&quot;);
    // join() 会等待任务执行结束，然后返回任务的结果
    SmallTool.print(String.format(&quot;%s,小白开吃&quot;, cf.join()));
}
</code></pre>
<h2 id="thencompose"><a class="header" href="#thencompose">thenCompose</a></h2>
<p>把前面任务的结果交给下一个异步任务。</p>
<pre><code class="language-java">public static void main(String[] args) {
    SmallTool.print(&quot;小白进入餐厅&quot;);
    SmallTool.print(&quot;小白点了菜 + 米饭&quot;);
    CompletableFuture&lt;String&gt; cf = CompletableFuture.supplyAsync(() -&gt; {
        SmallTool.print(&quot;厨师炒菜&quot;);
        SmallTool.sleep(200);
        return &quot;菜&quot;;
    }).thenCompose(dish -&gt; CompletableFuture.supplyAsync(() -&gt; {
        SmallTool.print(&quot;服务员打饭&quot;);
        SmallTool.sleep(100);
        return dish + &quot; + 米饭&quot;;
    }));

    SmallTool.print(&quot;小白在打游戏&quot;);
    // join() 会等待任务执行结束，然后返回任务的结果
    SmallTool.print(String.format(&quot;%s,小白开吃&quot;, cf.join()));
}
</code></pre>
<h2 id="thenconbine"><a class="header" href="#thenconbine">thenConbine</a></h2>
<p>等待两个任务都执行完，得到两个结果，再把两个加工成一个结果。</p>
<pre><code class="language-java">public static void main(String[] args) {
    SmallTool.print(&quot;小白进入餐厅&quot;);
    SmallTool.print(&quot;小白点了菜 + 米饭&quot;);
    CompletableFuture&lt;String&gt; cf = CompletableFuture.supplyAsync(() -&gt; {
        SmallTool.print(&quot;厨师炒菜&quot;);
        SmallTool.sleep(200);
        return &quot;菜&quot;;
    }).thenCombine(CompletableFuture.supplyAsync(() -&gt; {
        SmallTool.print(&quot;服务员蒸饭&quot;);
        SmallTool.sleep(300);
        return &quot;米饭&quot;;
    }), (dish, rice) -&gt; {
        SmallTool.print(&quot;服务员打饭&quot;);
        SmallTool.sleep(100);
        return String.format(&quot;%s + %s 好了&quot;, dish, rice);
    });

    SmallTool.print(&quot;小白在打游戏&quot;);
    SmallTool.print(String.format(&quot;%s,小白开吃&quot;, cf.join()));
}
</code></pre>
<h2 id="applytoeither"><a class="header" href="#applytoeither">applyToEither</a></h2>
<p>上个任务和这个任务一起运行，哪个先运行完成，就把哪个任务结果交个function。</p>
<pre><code class="language-java">public static void main(String[] args) {
    SmallTool.print(&quot;张三走出餐厅，来到公交站&quot;);
    SmallTool.print(&quot;等待 700路 或者 800路 公交到来&quot;);
    CompletableFuture&lt;String&gt; bus = CompletableFuture.supplyAsync(() -&gt; {
        SmallTool.print(&quot;700路公交正在赶来&quot;);
        SmallTool.sleep(300);
        return &quot;700路到了&quot;;
    }).applyToEither(CompletableFuture.supplyAsync(() -&gt; {
        SmallTool.print(&quot;800路公交正在赶来&quot;);
        SmallTool.sleep(200);
        return &quot;800路到了&quot;;
    }), firstComeBus -&gt; firstComeBus);

    SmallTool.print(String.format(&quot;%s,小白坐车回家&quot;, bus.join()));
}
</code></pre>
<h2 id="thenapply"><a class="header" href="#thenapply">thenApply</a></h2>
<p>把前面异步任务的结果，交给后面的function，一个线程操作。</p>
<pre><code class="language-java">public static void main(String[] args) {
    SmallTool.print(&quot;小白吃好了&quot;);
    SmallTool.print(&quot;小白 结账、要求开发票&quot;);
    CompletableFuture&lt;String&gt; invoice = CompletableFuture.supplyAsync(() -&gt; {
        SmallTool.print(&quot;服务员收款 500元&quot;);
        SmallTool.sleep(200);
        return &quot;500&quot;;
    }).thenApply(money -&gt; {
        SmallTool.print(String.format(&quot;服务员开发票 面额 %s元&quot;, money));
        SmallTool.sleep(200);
        return String.format(&quot;%s元发票&quot;, money);
    });

    SmallTool.print(&quot;小白 街道朋友的电话，想一起打游戏&quot;);
    SmallTool.print(String.format(&quot;小白拿到%s,准备回家&quot;, invoice.join()));
}
</code></pre>
<h2 id="thenapplyasync"><a class="header" href="#thenapplyasync">thenApplyAsync</a></h2>
<p>把前面异步任务的结果，交给后面的function，两个线程操作，若线程一样（线程复用）。</p>
<pre><code class="language-java">public static void main(String[] args) {
    SmallTool.print(&quot;小白吃好了&quot;);
    SmallTool.print(&quot;小白 结账、要求开发票&quot;);
    CompletableFuture&lt;String&gt; invoice = CompletableFuture.supplyAsync(() -&gt; {
        SmallTool.print(&quot;服务员收款 500元&quot;);
        SmallTool.sleep(300);
        return &quot;500&quot;;
    }).thenApplyAsync(money -&gt; {
        SmallTool.print(String.format(&quot;服务员开发票 面额 %s元&quot;, money));
        SmallTool.sleep(200);
        return String.format(&quot;%s元发票&quot;, money);
    });

    SmallTool.print(&quot;小白 街道朋友的电话，想一起打游戏&quot;);
    SmallTool.print(String.format(&quot;小白拿到%s,准备回家&quot;, invoice.join()));
}
</code></pre>
<h2 id="exceptionally"><a class="header" href="#exceptionally">exceptionally</a></h2>
<p>处理异常情况，链路上面的任何一个任务抛出异常，都会调用。</p>
<pre><code class="language-java">public static void main(String[] args) {
    SmallTool.print(&quot;张三走出餐厅，来到公交站&quot;);
    SmallTool.print(&quot;等待 700路 或者 800路 公交到来&quot;);
    CompletableFuture&lt;String&gt; bus = CompletableFuture.supplyAsync(() -&gt; {
        SmallTool.print(&quot;700路公交正在赶来&quot;);
        SmallTool.sleep(100);
        return &quot;700路到了&quot;;
    }).applyToEither(CompletableFuture.supplyAsync(() -&gt; {
        SmallTool.print(&quot;800路公交正在赶来&quot;);
        SmallTool.sleep(200);
        return &quot;800路到了&quot;;
    }), firstComeBus -&gt; {
        SmallTool.print(firstComeBus);
        if (firstComeBus.startsWith(&quot;700&quot;)) {
            throw new RuntimeException(&quot;撞树了。。。&quot;);
        }
        return firstComeBus;
    }).exceptionally(e -&gt; {
        SmallTool.print(e.getMessage());
        SmallTool.print(&quot;小白叫出租车&quot;);
        return &quot;出租车 叫到了&quot;;
    });

    SmallTool.print(String.format(&quot;%s,小白坐车回家&quot;, bus.join()));
}
</code></pre>
<h1 id=""><a class="header" href="#"></a></h1>
<div style="break-before: page; page-break-before: always;"></div><h2 id="前提安装docker"><a class="header" href="#前提安装docker">前提安装DOCKER</a></h2>
<h2 id="安装配置工具"><a class="header" href="#安装配置工具">安装配置工具</a></h2>
<blockquote>
<p>yum install -y yum-utils </p>
</blockquote>
<h2 id="配置源"><a class="header" href="#配置源">配置源</a></h2>
<blockquote>
<p>sudo yum-config-manager <br />
--add-repo <br />
https://download.docker.com/linux/centos/docker-ce.repo
sudo yum-config-manager <br />
--add-repo <br />
http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo</p>
</blockquote>
<h2 id="因为更新了源所以要更新yum缓存"><a class="header" href="#因为更新了源所以要更新yum缓存">因为更新了源所以要更新yum缓存</a></h2>
<blockquote>
<p>yum makecache fast</p>
</blockquote>
<h2 id="安装docker"><a class="header" href="#安装docker">安装DOCKER</a></h2>
<blockquote>
<p>yum install -y docker-ce docker-ce-cli containerd.io</p>
</blockquote>
<h2 id="配置docker镜像源为国内镜像"><a class="header" href="#配置docker镜像源为国内镜像">配置Docker镜像源为国内镜像</a></h2>
<blockquote>
<p>vim /etc/docker/daemon.json</p>
</blockquote>
<h2 id="写入文件内容"><a class="header" href="#写入文件内容">写入文件内容</a></h2>
<blockquote>
<p>{
&quot;registry-mirrors&quot;: [
&quot;https://registry.docker-cn.com&quot;,
&quot;http://hub-mirror.c.163.com&quot;,
&quot;https://docker.mirrors.ustc.edu.cn&quot;,
&quot;https://kfwkfulq.mirror.aliyuncs.com&quot;
],
&quot;max-concurrent-downloads&quot;: 10,
&quot;log-driver&quot;: &quot;json-file&quot;,
&quot;log-level&quot;: &quot;warn&quot;,
&quot;log-opts&quot;: {
&quot;max-size&quot;: &quot;10m&quot;,
&quot;max-file&quot;: &quot;3&quot;
},
&quot;data-root&quot;: &quot;/var/lib/docker&quot;
}</p>
</blockquote>
<h2 id="检查docker是否安装成功"><a class="header" href="#检查docker是否安装成功">检查docker是否安装成功</a></h2>
<blockquote>
<p>docker info</p>
</blockquote>
<h2 id="启动docker"><a class="header" href="#启动docker">启动docker</a></h2>
<blockquote>
<p>systemctl start docker</p>
</blockquote>
<h2 id="重启docker"><a class="header" href="#重启docker">重启docker</a></h2>
<blockquote>
<p>systemctl restart docker</p>
</blockquote>
<h2 id="设置docker开机自启"><a class="header" href="#设置docker开机自启">设置docker开机自启</a></h2>
<blockquote>
<p>systemctl enable docker</p>
</blockquote>
<h2 id="禁用docker开机自启"><a class="header" href="#禁用docker开机自启">禁用docker开机自启</a></h2>
<blockquote>
<p>systemctl disable docker</p>
</blockquote>
<h2 id="停止docker"><a class="header" href="#停止docker">停止docker</a></h2>
<blockquote>
<p>systemctl stop docker</p>
</blockquote>
<h2 id="查看docker-info中具体key的信息"><a class="header" href="#查看docker-info中具体key的信息">查看docker info中具体Key的信息</a></h2>
<blockquote>
<p>docker info | grep 'Docker Root Dir:'</p>
</blockquote>
<h2 id="浏览镜像文件"><a class="header" href="#浏览镜像文件">浏览镜像文件</a></h2>
<blockquote>
<p>docker images</p>
</blockquote>
<h2 id="查看镜像详情"><a class="header" href="#查看镜像详情">查看镜像详情</a></h2>
<blockquote>
<p>docker inspect 镜像名称或ID</p>
</blockquote>
<h2 id="查看镜像历史"><a class="header" href="#查看镜像历史">查看镜像历史</a></h2>
<blockquote>
<p>docker history 镜像名称或ID</p>
</blockquote>
<h2 id="导出镜像文件"><a class="header" href="#导出镜像文件">导出镜像文件</a></h2>
<blockquote>
<p>docker save 镜像名称或ID | gzip &gt; XXX.tar.gz</p>
</blockquote>
<h2 id="删除镜像文件"><a class="header" href="#删除镜像文件">删除镜像文件</a></h2>
<blockquote>
<p>docker image rm 镜像名称或ID</p>
</blockquote>
<h2 id="导入镜像文件"><a class="header" href="#导入镜像文件">导入镜像文件</a></h2>
<blockquote>
<p>docker load &lt; XXX.tar.gz</p>
</blockquote>
<h2 id="运行镜像文件"><a class="header" href="#运行镜像文件">运行镜像文件</a></h2>
<blockquote>
<p>docker run 镜像名</p>
</blockquote>
<h2 id="下载镜像"><a class="header" href="#下载镜像">下载镜像</a></h2>
<blockquote>
<p>docker pull 镜像名</p>
</blockquote>
<h2 id="创建并启动容器"><a class="header" href="#创建并启动容器">创建并启动容器</a></h2>
<blockquote>
<p>docker run -it xxx bash
注释:
xxx 代表镜像名或者imageId的前几位</p>
</blockquote>
<h2 id="查看容器"><a class="header" href="#查看容器">查看容器</a></h2>
<blockquote>
<p>docker ps -a</p>
</blockquote>
<h2 id="查看容器日志"><a class="header" href="#查看容器日志">查看容器日志</a></h2>
<blockquote>
<p>docker container logs 容器名称或ID</p>
</blockquote>
<h2 id="停止容器"><a class="header" href="#停止容器">停止容器</a></h2>
<blockquote>
<p>dicker container stop 容器名称或ID</p>
</blockquote>
<h2 id="重启容器"><a class="header" href="#重启容器">重启容器</a></h2>
<blockquote>
<p>dicker container restart 容器名称或ID</p>
</blockquote>
<h2 id="进入容器"><a class="header" href="#进入容器">进入容器</a></h2>
<blockquote>
<p>docker exec -it 容器名称或ID bash</p>
</blockquote>
<h2 id="删除容器需要先停止容器-如果容器正在运行则会出现问题"><a class="header" href="#删除容器需要先停止容器-如果容器正在运行则会出现问题">删除容器(需要先停止容器, 如果容器正在运行则会出现问题)</a></h2>
<blockquote>
<p>docker container rm 容器名称或ID</p>
</blockquote>
<h2 id="删除正在运行中的容器"><a class="header" href="#删除正在运行中的容器">删除正在运行中的容器</a></h2>
<blockquote>
<p>docker container rm -f 容器名称或ID</p>
</blockquote>
<h2 id="清理所有处于终止状态的容器"><a class="header" href="#清理所有处于终止状态的容器">清理所有处于终止状态的容器</a></h2>
<blockquote>
<p>docker container prune</p>
</blockquote>
<h2 id="安装dockercompose"><a class="header" href="#安装dockercompose">安装dockerCompose</a></h2>
<h2 id="下载"><a class="header" href="#下载">下载</a></h2>
<blockquote>
<p>curl -L &quot;https://github.com/docker/compose/releases/download/1.29.2/docker-compose-$(uname -s)-$(uname -m)&quot; -o /usr/local/bin/docker-compose</p>
<p>curl -L  &quot;http://ithltt.com/files/docker-compose-linux-x86_64&quot; -o /usr/local/bin/docker-compose</p>
</blockquote>
<h2 id="授权"><a class="header" href="#授权">授权</a></h2>
<blockquote>
<p>chmod +x /usr/local/bin/docker-compose</p>
</blockquote>
<h2 id="查看版本"><a class="header" href="#查看版本">查看版本</a></h2>
<blockquote>
<p>docker-compose --version</p>
</blockquote>
<h2 id="查看已经下载的镜像信息"><a class="header" href="#查看已经下载的镜像信息">查看已经下载的镜像信息</a></h2>
<blockquote>
<p>docker images</p>
</blockquote>
<h2 id="删除已经下载的镜像"><a class="header" href="#删除已经下载的镜像">删除已经下载的镜像</a></h2>
<blockquote>
<p>dicker rmi IMAGE_ID(镜像ID)</p>
</blockquote>
<h2 id="查看正在使用的容器"><a class="header" href="#查看正在使用的容器">查看正在使用的容器</a></h2>
<blockquote>
<p>docker ps -a</p>
</blockquote>
<h2 id="删除容器"><a class="header" href="#删除容器">删除容器</a></h2>
<blockquote>
<p>docker rm ID(容器ID)</p>
</blockquote>
<h2 id="导出已经下载的镜像"><a class="header" href="#导出已经下载的镜像">导出已经下载的镜像</a></h2>
<blockquote>
<p>docker save -o /root/xxx.image(导出的镜像路径和名称) ID(镜像ID)</p>
</blockquote>
<h2 id="导入镜像"><a class="header" href="#导入镜像">导入镜像</a></h2>
<blockquote>
<p>docker load -i xxx.image(镜像路径和名称)</p>
</blockquote>
<h2 id="为镜像指定名称和版本"><a class="header" href="#为镜像指定名称和版本">为镜像指定名称和版本</a></h2>
<blockquote>
<p>docker tag ID(镜像ID) name:version(指定的镜像名称:版本号) </p>
</blockquote>
<h2 id="使用镜像创建一个容器"><a class="header" href="#使用镜像创建一个容器">使用镜像创建一个容器</a></h2>
<blockquote>
<p>docker run -d -p 主机端口:容器端口 --name 容器名称 镜像名称:版本/镜像ID</p>
</blockquote>
<h2 id="复制文件到容器中"><a class="header" href="#复制文件到容器中">复制文件到容器中</a></h2>
<blockquote>
<p>docker cp /home/demo 容器ID:容器目录</p>
</blockquote>
<h2 id="查看容器日志-1"><a class="header" href="#查看容器日志-1">查看容器日志</a></h2>
<blockquote>
<p>docker logs -f 容器ID</p>
</blockquote>
<h2 id="进入容器内部-exit退出容器"><a class="header" href="#进入容器内部-exit退出容器">进入容器内部 exit退出容器</a></h2>
<blockquote>
<p>docker exec -it 容器ID bash</p>
</blockquote>
<h2 id="停止容器-1"><a class="header" href="#停止容器-1">停止容器</a></h2>
<blockquote>
<p>docker stop 容器ID</p>
</blockquote>
<h2 id="停止所有容器"><a class="header" href="#停止所有容器">停止所有容器</a></h2>
<blockquote>
<p>docker stop $(docker ps -qa)</p>
</blockquote>
<h2 id="删除指定容器"><a class="header" href="#删除指定容器">删除指定容器</a></h2>
<blockquote>
<p>docker rm 容器ID</p>
</blockquote>
<h2 id="删除所有容器"><a class="header" href="#删除所有容器">删除所有容器</a></h2>
<blockquote>
<p>docker rm $(docker ps -qa)</p>
</blockquote>
<h2 id="启动指定容器"><a class="header" href="#启动指定容器">启动指定容器</a></h2>
<blockquote>
<p>docker start 容器ID</p>
</blockquote>
<h2 id="数据库"><a class="header" href="#数据库">数据库</a></h2>
<blockquote>
<p>docker run -d -p 3306:3306 -e MYSQL_ROOT_PASSWORD=123456 --name Mysql 镜像ID</p>
</blockquote>
<h2 id="共享目录数据卷创建-v01-数据卷名称"><a class="header" href="#共享目录数据卷创建-v01-数据卷名称">共享目录(数据卷)创建 V01: 数据卷名称</a></h2>
<blockquote>
<p>docker volume create V01</p>
</blockquote>
<h2 id="查看数据卷"><a class="header" href="#查看数据卷">查看数据卷</a></h2>
<blockquote>
<p>docker volume inspect V01</p>
</blockquote>
<h2 id="查看所有数据卷"><a class="header" href="#查看所有数据卷">查看所有数据卷</a></h2>
<blockquote>
<p>docker volume ls</p>
</blockquote>
<h2 id="删除数据卷"><a class="header" href="#删除数据卷">删除数据卷</a></h2>
<blockquote>
<p>docker volume rm 数据卷名称</p>
</blockquote>
<h2 id="使用数据卷"><a class="header" href="#使用数据卷">使用数据卷</a></h2>
<blockquote>
<p>docker run -v 数据卷名称:容器内部路径 镜像ID
docker run -v 路径:容器内部路径 镜像ID
例:
docker run -d -p 8080:8080 -v V01:/usr/local/tomcat/webapps/ --name tomcat 镜像ID</p>
</blockquote>
<h2 id="使用自定义镜像"><a class="header" href="#使用自定义镜像">使用自定义镜像</a></h2>
<blockquote>
<p>docker build -f /home/Dockearfile</p>
</blockquote>
<h2 id="使用自定义镜像dockerfile-生成镜像-注意镜像名不能有大写字母"><a class="header" href="#使用自定义镜像dockerfile-生成镜像-注意镜像名不能有大写字母">使用自定义镜像DockerFile 生成镜像 (注意镜像名不能有大写字母)</a></h2>
<blockquote>
<p>docker build -t 镜像名:版本号 .
docker build -t 镜像名:版本号 - &lt; /path/DockerFile(文件绝对路径, 脚本中不能使用相对路径!!)</p>
</blockquote>
<h4 id="本地构建-helloworldapp-镜像文件"><a class="header" href="#本地构建-helloworldapp-镜像文件">本地构建 helloworldapp 镜像文件</a></h4>
<blockquote>
<p>docker build -t helloworldapp .</p>
</blockquote>
<h4 id="本地运行-helloworldapp-镜像8088端口映射容器中3721端口"><a class="header" href="#本地运行-helloworldapp-镜像8088端口映射容器中3721端口">本地运行 helloworldapp 镜像，8088端口映射容器中3721端口</a></h4>
<blockquote>
<p>docker run -d -p 8088:3721 --name myapp helloworldapp</p>
</blockquote>
<h4 id="登录到acrazure容器库中"><a class="header" href="#登录到acrazure容器库中">登录到ACR（azure容器库）中</a></h4>
<blockquote>
<p>docker login <acrtest01>.azurecr.cn --username <testuser01></p>
</blockquote>
<h4 id="与acr关联本地镜像文件"><a class="header" href="#与acr关联本地镜像文件">与ACR关联本地镜像文件</a></h4>
<blockquote>
<p>docker tag helloworldapp:v1 <acrtest01>.azurecr.cn/helloworldapp:v1</p>
</blockquote>
<h4 id="push-镜像文件到acr中"><a class="header" href="#push-镜像文件到acr中">PUSH 镜像文件到ACR中</a></h4>
<blockquote>
<p>docker push <acrtest01>.azurecr.cn/helloworldapp:v1</p>
</blockquote>
<h2 id="指定基础镜像"><a class="header" href="#指定基础镜像">指定基础镜像</a></h2>
<blockquote>
<p>格式 第一行必须是FROM(不包括注释)
FROM <image>
FROM <image>:<tag>
FROM <image>@<digest>
实例:
FROM mysql:5.6</p>
</blockquote>
<h2 id="maintainer-维护者信息"><a class="header" href="#maintainer-维护者信息">MAINTAINER: 维护者信息</a></h2>
<blockquote>
<p>格式: 
MAINTAINER <name>
实例:
MAINTAINER wangsh3@yonyou.com</p>
</blockquote>
<h2 id="构建时候执行的命令"><a class="header" href="#构建时候执行的命令">构建时候执行的命令</a></h2>
<blockquote>
<p>RUN <COMMAND></p>
</blockquote>
<h3 id="copy-复制文件到容器中"><a class="header" href="#copy-复制文件到容器中">COPY: 复制文件到容器中</a></h3>
<h3 id="add-将本地文件添加到容器中-tar类型文件会自动解压网络压缩资源不会被解压-可以访问网络资源类似wget"><a class="header" href="#add-将本地文件添加到容器中-tar类型文件会自动解压网络压缩资源不会被解压-可以访问网络资源类似wget">ADD 将本地文件添加到容器中, tar类型文件会自动解压(网络压缩资源不会被解压), 可以访问网络资源,类似wget</a></h3>
<blockquote>
<p>ADD <SRC> ... <dest></p>
</blockquote>
<h3 id="entrypoint-配置容器使其可执行化-配合cmd可省去application只添加参数可以外部传递参数"><a class="header" href="#entrypoint-配置容器使其可执行化-配合cmd可省去application只添加参数可以外部传递参数">ENTRYPOINT: 配置容器,使其可执行化. 配合CMD可省去&quot;application&quot;,只添加参数（可以外部传递参数）</a></h3>
<blockquote>
<p>ENTRYPOINT <a href="%E4%BC%98%E5%85%88%E6%89%A7%E8%A1%8C%E5%8F%AF%E6%89%A7%E8%A1%8C%E6%96%87%E4%BB%B6">&quot;executable&quot;,&quot;parm1&quot;,&quot;parm2&quot;</a>
ENTRYPOINT command parm1 parm2(执行Shell内部命令)</p>
</blockquote>
<h2 id="构建容器后调用-容器启动时进行调用"><a class="header" href="#构建容器后调用-容器启动时进行调用">构建容器后调用 容器启动时进行调用</a></h2>
<blockquote>
<p>CMD <a href="%E4%BC%98%E5%85%88%E6%89%A7%E8%A1%8C%E5%8F%AF%E6%89%A7%E8%A1%8C%E6%96%87%E4%BB%B6">&quot;executable&quot;,&quot;parm1&quot;,&quot;parm2&quot;</a>
CMD [&quot;parm1&quot;,&quot;parm2&quot;](设置了ENTRYPOINT, 直接调用ENTRYPOINT添加参数)
CMD command parm1 parm2(执行Shell内部命令)</p>
</blockquote>
<h2 id="lab用于为镜像添加元数据-可以"><a class="header" href="#lab用于为镜像添加元数据-可以">LAB:用于为镜像添加元数据 可以</a></h2>
<blockquote>
<p>LABEL <Key>=<Value> <Key>=<Value> <Key>=<Value>
实例: 
LABEL Version=&quot;1.0&quot; Description=&quot;描述&quot; by=&quot;糖糖&quot;</p>
</blockquote>
<h2 id="env-设置环境变量"><a class="header" href="#env-设置环境变量">ENV: 设置环境变量</a></h2>
<blockquote>
<p>ENV <key> <Value>
ENV <key>=<Value></p>
</blockquote>
<h2 id="expose-指定外界交互的端口"><a class="header" href="#expose-指定外界交互的端口">EXPOSE: 指定外界交互的端口</a></h2>
<blockquote>
<p>EXPOSE <port> [<port>...]</p>
</blockquote>
<h2 id="volume--指定持久化目录"><a class="header" href="#volume--指定持久化目录">VOLUME : 指定持久化目录</a></h2>
<blockquote>
<p>VOLUME [&quot;/path/dir&quot;, &quot;/path/dir1&quot;]</p>
</blockquote>
<h2 id="workdir--工作目录-类似cd命令"><a class="header" href="#workdir--工作目录-类似cd命令">WORKDIR : 工作目录, 类似cd命令</a></h2>
<blockquote>
<p>WORKDIR /home/dir</p>
</blockquote>
<h2 id="user--指定运行容器的用户"><a class="header" href="#user--指定运行容器的用户">USER : 指定运行容器的用户</a></h2>
<blockquote>
<p>USER user:group</p>
</blockquote>
<h2 id="arg-指定传递给构建运行时的变量"><a class="header" href="#arg-指定传递给构建运行时的变量">ARG 指定传递给构建运行时的变量</a></h2>
<blockquote>
<p>ARG <name>[=<default value>]</p>
</blockquote>
<h2 id="-1"><a class="header" href="#-1"></a></h2>
<h2 id="示例dockerfile"><a class="header" href="#示例dockerfile">示例DockerFile</a></h2>
<h2 id="base-images"><a class="header" href="#base-images">Base images</a></h2>
<blockquote>
<p>FROM centos</p>
</blockquote>
<h2 id="maintainer-维护者信息-1"><a class="header" href="#maintainer-维护者信息-1">MAINTAINER 维护者信息</a></h2>
<blockquote>
<p>MAINTAINER Tangtang</p>
</blockquote>
<h2 id="add-将文件拷贝到容器中并自动解压"><a class="header" href="#add-将文件拷贝到容器中并自动解压">ADD 将文件拷贝到容器中并自动解压</a></h2>
<h2 id="下载nginx-并解压"><a class="header" href="#下载nginx-并解压">下载Nginx 并解压</a></h2>
<blockquote>
<p>ADD http://nginx.org/download/nginx-1.23.3.tar.gz /usr/local/</p>
</blockquote>
<h2 id="下载企业linux支持库因为该网站无法直接下载"><a class="header" href="#下载企业linux支持库因为该网站无法直接下载">下载企业linux支持库(因为该网站无法直接下载)</a></h2>
<blockquote>
<h2 id="httpsmirrorstunatsinghuaeducnepel7x86_64packageseepel-release-7-14noarchrpm"><a class="header" href="#httpsmirrorstunatsinghuaeducnepel7x86_64packageseepel-release-7-14noarchrpm">https://mirrors.tuna.tsinghua.edu.cn/epel/7/x86_64/Packages/e/epel-release-7-14.noarch.rpm</a></h2>
<p>ADD http://10.180.1.177/linux/package/rpm/epel-release-7-14.noarch.rpm /usr/local/</p>
</blockquote>
<h2 id="run-执行以下命令"><a class="header" href="#run-执行以下命令">RUN 执行以下命令</a></h2>
<h2 id="安装支持库"><a class="header" href="#安装支持库">安装支持库</a></h2>
<blockquote>
<p>RUN rpm -ivh /usr/local/epel-release-7-14.noarch.rpm </p>
</blockquote>
<h2 id="手动解压文件"><a class="header" href="#手动解压文件">手动解压文件</a></h2>
<blockquote>
<p>RUN tar zxvf /usr/local/nginx-1.23.3.tar.gz -C /usr/local/</p>
</blockquote>
<h2 id="调整url列表"><a class="header" href="#调整url列表">调整URL列表</a></h2>
<blockquote>
<p>RUN sed -i 's/mirrorlist/##mirrorlist/g' /etc/yum.repos.d/CentOS-*
RUN sed -i 's|##baseurl=http://mirror.centos.org|baseurl=http://vault.centos.org|g' /etc/yum.repos.d/CentOS-*</p>
</blockquote>
<h2 id="重新生成缓存"><a class="header" href="#重新生成缓存">重新生成缓存</a></h2>
<blockquote>
<p>RUN yum makecache</p>
</blockquote>
<h2 id="安装编译器"><a class="header" href="#安装编译器">安装编译器</a></h2>
<blockquote>
<p>RUN yum install -y wget lftp gcc gcc-c++ make openssl-devel pcre-devel pcre vim &amp;&amp; yum clean all </p>
</blockquote>
<h2 id="创建运行用户和组"><a class="header" href="#创建运行用户和组">创建运行用户和组</a></h2>
<blockquote>
<p>RUN groupadd Tang
RUN useradd -s /sbin/nologin -M Tang -g Tang</p>
</blockquote>
<h2 id="workdir-切换到nginx目录"><a class="header" href="#workdir-切换到nginx目录">WORKDIR 切换到Nginx目录</a></h2>
<blockquote>
<p>WORKDIR /usr/local/nginx-1.23.3/</p>
</blockquote>
<h2 id="编译配置"><a class="header" href="#编译配置">编译配置</a></h2>
<blockquote>
<p>RUN /usr/local/nginx-1.23.3/configure --prefix=/usr/local/nginx/ --user=Tang --group=Tang --with-http_ssl_module --with-pcre &amp;&amp; make &amp;&amp; make install</p>
</blockquote>
<h2 id="env-设置环境变量-1"><a class="header" href="#env-设置环境变量-1">ENV 设置环境变量</a></h2>
<blockquote>
<p>ENV PATH /usr/local/nginx/sbin:$PATH</p>
</blockquote>
<h2 id="映射端口"><a class="header" href="#映射端口">映射端口</a></h2>
<blockquote>
<p>EXPOSE 80</p>
</blockquote>
<h2 id="启动服务-前台启动服务"><a class="header" href="#启动服务-前台启动服务">启动服务 前台启动服务</a></h2>
<blockquote>
<p>CMD [&quot;/usr/local/nginx/sbin/nginx&quot;, &quot;-g&quot;, &quot;daemon off;&quot;]</p>
</blockquote>
<h1 id="-2"><a class="header" href="#-2"></a></h1>
<h1 id="使用docker-compose批量管理容器"><a class="header" href="#使用docker-compose批量管理容器">使用docker-compose批量管理容器</a></h1>
<p>docker-compose.yml</p>
<p>文件内容如下</p>
<blockquote>
<p>version: '3.8'
services: 
mysql: </p>
</blockquote>
<pre><code>            # 在docker启动时启动服务
</code></pre>
<blockquote>
<p>restart: always</p>
</blockquote>
<pre><code>            # 使用的镜像
</code></pre>
<blockquote>
<p>image: mysql:5.7.5-m15</p>
</blockquote>
<pre><code>            # 容器名称
</code></pre>
<blockquote>
<p>container_name: Mysql</p>
</blockquote>
<pre><code>            # 端口映射
</code></pre>
<blockquote>
<p>ports:</p>
<pre><code>            -       3306:3306
</code></pre>
</blockquote>
<pre><code>            # 环境参数
</code></pre>
<blockquote>
<p>environment:</p>
</blockquote>
<pre><code>                    # 数据库密码
</code></pre>
<blockquote>
<p>MYSQL_ROOT_PASSWORD: 123456</p>
</blockquote>
<pre><code>                    # 指定时区
</code></pre>
<blockquote>
<p>TZ: Asia/Shanghai
volumes:</p>
</blockquote>
<pre><code>                    # 数据卷映射(容器内存在/var/lib/mysql/所以如果不指定根目录无法启动mysql容器)
</code></pre>
<blockquote>
<p>/docker_mysql/:/var/lib/mysql/
tomcat:</p>
</blockquote>
<pre><code>            # 在docker启动时启动服务
</code></pre>
<blockquote>
<p>restart: always</p>
</blockquote>
<pre><code>            # 使用的镜像
</code></pre>
<blockquote>
<p>image: tomcat:8.5.51</p>
</blockquote>
<pre><code>            # 容器名称
</code></pre>
<blockquote>
<p>container_name: Tomcat</p>
</blockquote>
<pre><code>            # 端口映射
</code></pre>
<blockquote>
<p>ports:</p>
<p>8070:8080
environment: </p>
</blockquote>
<h1 id="指定时区"><a class="header" href="#指定时区">指定时区</a></h1>
<blockquote>
<p>TZ: Asia/Shanghai
volumes:</p>
</blockquote>
<h1 id="数据卷映射"><a class="header" href="#数据卷映射">数据卷映射</a></h1>
<blockquote>
<p>/docker_tomcat/webapps:/usr/local/tomcat/webapps</p>
<p>/docker_tomcat/logs:/usr/local/tomcat/logs
nginx: </p>
</blockquote>
<pre><code>            # 在docker启动时启动服务
</code></pre>
<blockquote>
<p>restart: always</p>
</blockquote>
<pre><code>            # 使用本地自建镜像
</code></pre>
<blockquote>
<p>build: </p>
</blockquote>
<pre><code>                    # 构建镜像的配置文件的目录
</code></pre>
<blockquote>
<p>context: /root/nginxDocker/</p>
</blockquote>
<pre><code>                    # 构建镜像的配置文件的名称
</code></pre>
<blockquote>
<p>dockerfile: Dockerfile_nginx</p>
</blockquote>
<pre><code>            # 使用的镜像
</code></pre>
<blockquote>
<p>image: nginx:1.23.3</p>
</blockquote>
<pre><code>            # local_images: nginx:1.23.3
            # 容器名称
</code></pre>
<blockquote>
<p>container_name: Nginx</p>
</blockquote>
<pre><code>            # 端口映射
</code></pre>
<blockquote>
<p>ports:</p>
<p>82:80
environment: </p>
</blockquote>
<h1 id="指定时区-1"><a class="header" href="#指定时区-1">指定时区</a></h1>
<blockquote>
<p>TZ: Asia/Shanghai
volumes:</p>
</blockquote>
<h1 id="数据卷映射-1"><a class="header" href="#数据卷映射-1">数据卷映射</a></h1>
<blockquote>
<p>/docker_nginx/logs:/usr/local/nginx/logs</p>
</blockquote>
<h1 id="微服务镜像"><a class="header" href="#微服务镜像">微服务镜像			</a></h1>
<blockquote>
<p>FROM openjdk:8-jdk-alpine
ARG JAR_FILE
COPY ${JAR_FILE} app.jar
EXPOSE 10086
ENTRYPOINT [&quot;java&quot;,&quot;-jar&quot;,&quot;/app.jar&quot;]</p>
</blockquote>
<h1 id="编译镜像"><a class="header" href="#编译镜像">编译镜像</a></h1>
<blockquote>
<p>docker build --build-arg JAR_FILE=xxx.jar -t ServiceName:Version</p>
</blockquote>
<h1 id="启动镜像"><a class="header" href="#启动镜像">启动镜像</a></h1>
<blockquote>
<p>docker run -di -p 10086:10086 ServiceName:Version</p>
</blockquote>
<div style="break-before: page; page-break-before: always;"></div><h1 id="gc"><a class="header" href="#gc">GC</a></h1>
<h2 id="如何判断一个对象是否存活"><a class="header" href="#如何判断一个对象是否存活">如何判断一个对象是否存活</a></h2>
<h3 id="引用计数法"><a class="header" href="#引用计数法">引用计数法</a></h3>
<p>引用计数，就是记录每个对象被引用的次数，每次新建对象、赋值引用和删除引用的同时更新计数器，如果计数器值为0则直接回收内存。很明显，引用计数最大的优势就是暂停时间短。</p>
<p>优点：</p>
<ul>
<li>
<p>可即刻回收垃圾。</p>
</li>
<li>
<p>最大暂停时间短。</p>
</li>
<li>
<p>没有必要沿指针查找。</p>
</li>
</ul>
<p>缺点：</p>
<ul>
<li>
<p>计数器的增减处理繁重。</p>
</li>
<li>
<p>计数器需要占用很多位。</p>
</li>
<li>
<p>实现繁琐复杂，每个赋值操作都得替换成引用更新操作。</p>
</li>
<li>
<p>循环引用无法回收（<strong>最大的缺点</strong>）。</p>
</li>
</ul>
<h3 id="可达性分析法"><a class="header" href="#可达性分析法">可达性分析法</a></h3>
<p>从一个被称为 GC Roots 的对象向下搜索，如果一个对象到 GC Roots 没有任何引用链相连接时，说明此对象不可用，在java中可以作为
GC Roots 的对象有以下几种：</p>
<ul>
<li>
<p>虚拟机栈中引用的对象。</p>
</li>
<li>
<p>方法区类静态属性引用的变量。</p>
</li>
<li>
<p>方法区常量池引用的对象。</p>
</li>
<li>
<p>本地方法栈 JNI 引用的对象。</p>
</li>
</ul>
<h2 id="垃圾回收算法"><a class="header" href="#垃圾回收算法">垃圾回收算法</a></h2>
<h3 id="标记-清除mark-sweep"><a class="header" href="#标记-清除mark-sweep">标记-清除（Mark-Sweep）</a></h3>
<ul>
<li>
<p>标记阶段：从跟集合出发，将所有活动对象及其子对象打上标记。</p>
</li>
<li>
<p>清除阶段：遍历堆，将非活动对象（未打上标记）的连接到空闲链表上。</p>
</li>
</ul>
<p>缺点：</p>
<ul>
<li>
<p>碎片化，会导致吴舒小分块散落在堆的各处。</p>
</li>
<li>
<p>分配速度不理想，每次分配都需要遍历空闲列表找到足够大的分块。</p>
</li>
<li>
<p>与写时复制技术不兼容，因为每次都要在活动对象上打上标记。</p>
</li>
</ul>
<h3 id="拷贝复制copying"><a class="header" href="#拷贝复制copying">拷贝（复制）（Copying）</a></h3>
<p>为了解决碎片化的问题。原理是将内存分为两块，每次申请内存时都使用其中一块，当内存不够时，将这一块内存中所有存活的复制到另一块上，然后再把已使用的内存整个清理掉。复制算法解决了空间碎片的问题，但是，因为每次在申请内存时，都只能使用一半的内存空间，内存利用率严重不足。</p>
<p>JVM 中新生代采用的就是复制算法。针对内存利用率不足做了一下优化：</p>
<ul>
<li>
<p>IBM公司的专门研究表明，新生代中的对象 98% 是“朝生夕死”的，意思是说，在新生代中，经过一次 GC 之后能够存活下来的对象仅有 2%左右。所以并不需要按照1:1的比例划分出两块内存空间。而是将内存划分出三块，一块较大的 Eden 区，和两块较小的 Survivor 区。其中Eden 区占 80% 的内存，两块 Survivor 各占 10% 的内存。在创建新的对象时，只使用 Eden 区和其中的一块 Survivor 区，当进行 GC时，把 Eden 区和 Survivor 区存活的对象全部复制到另一块 Survivor 区中，然后清理掉 Eden 区和刚刚用过的 Survivor 区。</p>
<p>这种内存的划分方式就解决了内存利用率的问题，每次在创建对象时，可用的内存为 90%(80% + 10%) 当前内存容量。</p>
</li>
</ul>
<p>优点：</p>
<ul>
<li>
<p>优秀的吞吐量，只需要关心活动对象。</p>
</li>
<li>
<p>可实现高速分配，因为分块是连续的，不需要使用空闲链表。</p>
</li>
<li>
<p>不会发生碎片化。</p>
</li>
<li>
<p>与缓存兼容。</p>
</li>
</ul>
<p>缺点：</p>
<ul>
<li>
<p>堆利用率低。</p>
</li>
<li>
<p>递归调用函数，负质子对象需要递归调用复制函数，消耗栈。</p>
</li>
</ul>
<h3 id="标记-压缩整理mark-compact"><a class="header" href="#标记-压缩整理mark-compact">标记-压缩/整理（Mark-Compact）</a></h3>
<p>复制算法在 GC 之后存活对象较少的情况下效率比较高，但如果存活对象比较多时，会执行较多的复制操作，效率就会下降。而老年代的对象在 GC 之后的存活率就比较高，所以就有人提出了“标记-整理算法”。</p>
<p>“标记-整理”算法的“标记”过程与“标记-清除”算法的标记过程一致，但标记之后不会直接清理，而是将所有存活对象都移动到内存的一端，移动结束后直接清理掉剩余部分。</p>
<p>优点：</p>
<ul>
<li>有效利用了堆，不会出现内存碎片，也不会像复制算法那样只能利用堆的一部分。</li>
</ul>
<p>缺点：</p>
<ul>
<li>压缩过程的开销，需要多次搜索堆。</li>
</ul>
<h3 id="分代"><a class="header" href="#分代">分代</a></h3>
<p><strong>出发点</strong>：大部分对象生成后马上就变成垃圾，很少有对象能活很久。</p>
<ul>
<li>
<p>新生代 = 生成空间 + 2 * 幸存区 <strong>复制算法</strong></p>
</li>
<li>
<p>老年代 <strong>标记-清除算法</strong></p>
</li>
</ul>
<p>对象在生成空间创建，当生成空间满之后进行 minor gc，将活动对象复制到第一个幸存区，并增加其“年龄”age，当这个幸存区满之后再将此次生成空间和这个幸存区的活动对象复制到另一个幸存区，如此反复，当活动对象的 age 达到一定次数（默认是15，可以通过参数 ==-XX:MaxTenuringThreshold== 来设定）后将其移动到老年代； 当老年代满的时候就用标记-清除或标记-压缩算法进行major gc 吞吐量得到改善，分代回收花费的时间是 GC 复制算法的四分之一；但是如果部分程序新生成对象存活很久的话分代回收会适得其反。</p>
<p><strong>具体流程</strong></p>
<ol>
<li>对象优先在Eden分配。当 eden 区没有足够空间进行分配时，虚拟机将发起一次 Minor GC。</li>
<li>在 Eden 区执行了第一次 GC 之后，存活的对象会被移动到 form 分区。</li>
<li>Eden 区再次 GC，这时会采用复制算法，将 Eden 和 from 区一起清理，存活的对象会被复制到 to 区。</li>
<li>当后续Eden又发生Minor GC的时候，会对Eden和 to 区进行垃圾回收，存活的对象复制到 from 区，并将Eden 和 to 区清空。</li>
<li>部分对象会在 from 和 to 区中来回的复制，如此的交换15次（由JVM参数 Max Tenuring Threshold 决定，默认是15），最终如果还是存活，就存入老年代。</li>
<li>Survivor 区内存不足会发生<strong>担保分配</strong>，超过指定大小的对象可以直接进入老年代(此时如果老年代的内存大小，小于对象的大小，可能会发生一次Full GC)。</li>
<li>老年代满了而<strong>无法容纳更多的对象</strong>，Minor GC 之后通常就会进行Full GC，Full GC 清理整个内存堆 – <strong>包括年轻代和老年代</strong>。</li>
</ol>
<p><strong>注意事项</strong></p>
<ul>
<li>
<p><strong>新生代</strong>：对于一般创建的对象都会进入。</p>
</li>
<li>
<p><strong>老年代</strong>：对于大对象为了避免为大对象分配内存时由于分配担保机制带来的复制而降低效率，或者经过N次（一般默认15次）的垃圾回收依然存活下来的对象，从新生代移动到老年代。</p>
</li>
<li>
<p><strong>Minor GC、Major GC、Full GC的关系</strong>
1. Minor GC 又称为新生代 GC：指的是发生在新生代的垃圾回收。因为Java对象大多都具备朝生夕灭的特性，因此Minor GC（采用的是复制算法）非常频繁，一般回收速度也比较快。
2. Major GC 又被称为老年代 GC ，一般的老年代 GC 总是由于每次 Minor GC 引起的，所以Major GC 发生的时候也是 Full GC，可以看作他两个等效。</p>
</li>
<li>
<p><strong>空间分配担保原则</strong></p>
<p>如果 Young GC 时新生代有大量对象存活下来，而 survivor 区放不下，这时必须转移到老年代中，但这时发现老年代也放不下这些对象了，那怎么处理？其实JVM有一个老年代空间分配担保机制来保证对象能够进入老年代。</p>
<p>在执行每次 Young GC 之前，JVM 会先检查老年代最大可用连续空间是否大于新生代所有对象的总大小，因为在极端情况下，可能新生代 Young GC 后，所有对象都存活下来了，而 survivor 区又放不下，那可能所有对象都要进入老年代了。这个时候如果老年代的可用连续空间大于新生代所有对象的总大小的，那就可以放心进行 Young GC，但是如果老年代的内存大小小于新生代对象总大小的，那就可能老年代空间不够放入新生代所有存活对象，这个时候 JVM就会先检查 ==-XX:HandlePromotionFailure== 参数是否允许担保失败，如果允许，就会判断老年代最大可用连续空间是否大于历次晋升到老年代对象的平均大小（就是每次从新生代到老年代的对象的平均大小），如果大于，将尝试进行一次Young GC ，尽管这次 Young GC 是有风险的，如果小于，或者 ==-XX:HandlePromotionFailure== 参数不允许担保失败，这时就要进行一次Full GC。</p>
</li>
<li>
<p><strong>在允许担保失败并尝试进行 Young GC 后，可能会出现三种情况</strong></p>
<ol>
<li>Young GC 后，存活对象小于 survivor 大小，此时存活对象进入 survivor 区中。</li>
<li>Young GC 后，存活对象大于 survivor 大小，但是小于老年代可用空间大小，此时直接进入老年代。</li>
<li>Young GC 后，存活对象大于 survivor 大小，也大于老年代可用空间大小，老年代也放不下这些对象了，此时就会发生“Handle Promotion Failure”，就触发了 Full GC。如果 Full GC 后，老年代还是没有足够的空间，此时就会发生 OOM 内存溢出了。</li>
</ol>
</li>
</ul>
<h2 id="三色标记算法"><a class="header" href="#三色标记算法">三色标记算法</a></h2>
<h3 id="概述"><a class="header" href="#概述">概述</a></h3>
<p>主流的垃圾收集器基本上都是基于【可达性分析】算法来判定对象是否存活的。根据对象是否被垃圾收集器扫描过而用白、灰、黑三种颜色来标记对象的状态的一种方法。在可达性分析中，CMS、G1、ZGC都采用三色标记算法（<strong>并发</strong>）。</p>
<ul>
<li>
<p><strong>白色</strong></p>
<p>对象尚未被垃圾收集器访问过。显然在可达性分析刚刚开始阶段，所有的对象都是白色的，若在分析结束之后对象仍然为白色，则表示这些对象为不可达对象，对这些对象进行回收。</p>
</li>
<li>
<p><strong>灰色</strong></p>
<p>对象已经被垃圾收集器访问过，但是这个对象至少存在一个引用（属性）还没有被扫描过。</p>
</li>
<li>
<p><strong>黑色</strong></p>
<p>对象已经被垃圾收集器访问过，且这个对象的所有引用都已经被扫描过。黑色表示这个对象扫描之后依然存活，是可达性对象，如果有其他对象引用指向了黑色对象，无需重新扫描，黑色对象不可能不经过灰色对象直接指向某个白色对象。</p>
</li>
</ul>
<p><img src="https://github.com/chou401/pic-md/raw/master/img/image-20230424154311461.png" alt="image-20230424154311461" /></p>
<h3 id="标记的过程"><a class="header" href="#标记的过程">标记的过程</a></h3>
<ul>
<li>
<p>初始状态</p>
<p>初始阶段只有GC Roots 是黑色的，其他对象都是白色的，如果没有被黑色对象引用那么最终都会被当做垃圾对象回收。</p>
<p><img src="https://github.com/chou401/pic-md/raw/master/img/image-20230424164613104.png" alt="image-20230424164613104" /></p>
</li>
<li>
<p><strong>开始扫描</strong></p>
<p>A和B均为扫描过的对象并且其引用也已经被垃圾回收器扫描过所以此时A、B对象均变为了黑色，而刚扫描到对象C，由于C的D和E还没有扫描到，所以C暂时为灰色。</p>
<p><img src="https://github.com/chou401/pic-md/raw/master/img/image-20230424164543590.png" alt="image-20230424164543590" /></p>
</li>
<li>
<p><strong>扫描结束</strong></p>
<p>此时扫描完成，黑色对象就是存活的对象，即可达对象，白色对象G为不可达对象，在垃圾回收时会被回收掉。</p>
<p><img src="https://github.com/chou401/pic-md/raw/master/img/image-20230424164809038.png" alt="image-20230424164809038" /></p>
<p>这个过程正确执行的前提是没有其他线程改变对象间的引用关系，然而，并发标记的过程中，用户线程仍在运行，因此就会产生漏标和错标的情况。</p>
</li>
</ul>
<h3 id="缺点"><a class="header" href="#缺点">缺点</a></h3>
<h4 id="多标"><a class="header" href="#多标">多标</a></h4>
<p><img src="https://github.com/chou401/pic-md/raw/master/img/image-20230424165421241.png" alt="image-20230424165421241" /></p>
<pre><code class="language-java">C.E = null
</code></pre>
<p>假如GC线程已经扫描到了E对象，此时E对象为灰色，这个时候用户线程将C的引用E断开，那么GC就会认为E对象是可达对象，而不会对E进行垃圾回收，但实际上E是个垃圾对象，这个时候就会产生多标的问题，多标问题其实还可以接受，E作为浮动垃圾，那么等到下次垃圾回收的时候回收掉。</p>
<p>另外，针对并发标记开始后的新对象，通常的做法是直接全部当做黑色，本轮不会进行清除。这部分对象期间可能会变成垃圾，这也算是浮动垃圾的一部分。</p>
<p>实际上，这个问题依然可以通过【写屏障】来解决，只要在C写E的时候加入写屏障，记录下E被切断的记录，重新标记时可以再把他们标为白色即可。</p>
<h4 id="漏标"><a class="header" href="#漏标">漏标</a></h4>
<p><img src="https://github.com/chou401/pic-md/raw/master/img/image-20230424170559888.png" alt="image-20230424170559888" /></p>
<pre><code class="language-java">var E = C.E;
C.E = null; // 灰色C 断开引用 白色E
B.E = E; // 黑色B 引用 白色E
</code></pre>
<p>假如用户线程先断开了C到E的引用，那么E对象就认为是不可达对象，而此时B对象又引用了E对象，但是三色标记又不会重新从B点开始标记到E，那么E就会被认为是垃圾对象，但实际上E是有引用的，那么此时对E进行垃圾回收，之后就一定会产生错误。</p>
<h3 id="漏标解决方案"><a class="header" href="#漏标解决方案">漏标解决方案</a></h3>
<p>漏标<strong>只有在满足下面两种情况</strong>下才会发生，那么要想解决并发扫描时漏标的问题只需要破坏任何一个条件即可。</p>
<p><img src="https://github.com/chou401/pic-md/raw/master/img/image-20230424171617866.png" alt="image-20230424171617866" /></p>
<h4 id="增量更新"><a class="header" href="#增量更新">增量更新</a></h4>
<p>增量更新（Incremental Update）是站在<strong>新增引用对象</strong>的角度来解决问题。当黑色对象插入新的指向白色对象的引用关系时，就将这个新插入的引用记录下来，等并发扫描结束之后，再将这些记录过的引用关系中的黑色对象作为跟对象，再重新扫描一遍。比如漏标问题中，一旦B对象直接指向了E对象，那么在并发扫描之后，就会把B对象作为灰色对象，再重新扫描一遍。这样虽然避免了漏标问题，但是重新标记会导致STW的时间变长。</p>
<h4 id="原始快照"><a class="header" href="#原始快照">原始快照</a></h4>
<p>原始快照（Snapshot At The Beginning, SATB）是站在<strong>减少引用的对象</strong>的角度来解决问题。当灰色对象要删除指向白色对象的引用关系时，就将这个要删除的引用记录下来，在并发扫描结束后，再将这些记录过的引用关系中的灰色对象作为跟对象，再重新扫描一遍。例如漏标问题中，C断开了E的引用关系时会保存一个快照，然后等扫描结束之后，会把C当作跟再重新扫描一遍，例如B没有引用E，那么E对象会认为是不可达对象，这样E就成了浮动垃圾，只能等下次垃圾回收时再回收。</p>
<p>无论是对引用关系记录的插入还是删除，虚拟机的记录操作都是通过写屏障实现的，在HotSpot 虚拟机中，<strong>CMS是基于增量更新来做并发标记的，G1、Shenandoah则是用STAB来实现的。</strong></p>
<h4 id="读写屏障"><a class="header" href="#读写屏障">读写屏障</a></h4>
<blockquote>
<p>这个屏障指的不是并发编程里的屏障，这里的屏障可以理解成就是在读写操作前后插入一段代码，用于记录一些信息、保存某些数据等，概念类似于AOP。</p>
</blockquote>
<p>从代码角度看：</p>
<pre><code class="language-java">var E = C.E; // 1.读
C.E = null;  // 2.写
B.E = E;     // 3.写
</code></pre>
<ol>
<li><strong>读取</strong>对象C的成员变量E的引用值，即对象E。</li>
<li>对象C 往其成员变量 E，<strong>写入</strong> null。</li>
<li>对象B 往其成员变量 E，<strong>写入</strong>对象 E。</li>
</ol>
<p><strong>写屏障（Store Barrier）</strong></p>
<p>给某个对象的成员变量赋值时，代码大概如此：</p>
<pre><code class="language-c">/**
* @param field 某对象的成员变量，如 D.fieldG
* @param new_value 新值，如 null
*/
void oop_field_store(oop* field, oop new_value) { 
    *field = new_value; // 赋值操作
} 
</code></pre>
<p>所谓的写屏障，其实就是指在赋值操作前后，加入一些处理（可以参考AOP的概念）：</p>
<pre><code class="language-c">void oop_field_store(oop* field, oop new_value) {  
    pre_write_barrier(field); // 写屏障-写前操作
    *field = new_value; 
    post_write_barrier(field, value);  // 写屏障-写后操作
}
</code></pre>
<p><strong>写屏障 + STAB</strong></p>
<p>当对象 C 的成员变量的引用发生变化时（C.E = null），我们可以利用写屏障，将C原来的成员变量的引用对象 E 记录下来：</p>
<pre><code class="language-c">void pre_write_barrier(oop* field) {
    oop old_value = *field; // 获取旧值
    remark_set.add(old_value); // 记录 原来的引用对象
}
</code></pre>
<p><strong>当原来成员变量的引用发生变化之前，记录下原来的引用对象</strong>。这种做法的思路是：尝试保留开始时的对象图，即原始快照，当某个时刻的GC Roots 确定后，当时的对象图就已经确定了。比如当时B是引用着E的，那后续的标记也应该是按照这个时刻的对象图走（B引用着E）。如果期间发生了变化，则可以记录起来，保证标记依然按照原本的视图来。</p>
<p>扫描所有GC Roots 这个操作通常是需要STW，否则有可能永远都扫不完，因为并发期间可能增加新的GC Roots 。</p>
<p>优化：如果不是处于垃圾回收的并发标记阶段，或者已经被标记过了，其实是没必要再记录了，所以可以加个简单的判断：</p>
<pre><code class="language-c">void pre_write_barrier(oop* field) {
  // 处于GC并发标记阶段 且 该对象没有被标记（访问）过
  if($gc_phase == GC_CONCURRENT_MARK &amp;&amp; !isMarkd(field)) { 
      oop old_value = *field; // 获取旧值
      remark_set.add(old_value); // 记录  原来的引用对象
  }
}
</code></pre>
<p><strong>写屏障 + 增量更新</strong></p>
<p>当对象B的成员变量的引用发生变化时（B.E = E），可以利用写屏障，将B新的成员变量引用对象E记录下来：</p>
<pre><code class="language-c">void post_write_barrier(oop* field, oop new_value) {  
  if($gc_phase == GC_CONCURRENT_MARK &amp;&amp; !isMarkd(field)) {
      remark_set.add(new_value); // 记录新引用的对象
  }
}
</code></pre>
<p><strong>当有新引用插入进来时，记录下新的引用对象</strong>。思路：不要求保留原始快照，而是针对新增的引用，将其记录下来等待遍历，即增量更新。</p>
<p><strong>读屏障（Load Barrier）</strong></p>
<p>读屏障是直接针对：var E = C.E，当读取成员变量时，一律记录下来：</p>
<pre><code class="language-java">oop oop_field_load(oop* field) {
    pre_load_barrier(field); // 读屏障-读取前操作
    return *field;
}

void pre_load_barrier(oop* field, oop old_value) {  
  if($gc_phase == GC_CONCURRENT_MARK &amp;&amp; !isMarkd(field)) {
      oop old_value = *field;
      remark_set.add(old_value); // 记录读取到的对象
  }
}
</code></pre>
<p>这种做法是保守的，但也是安全的。【黑色对象重新引用白色对象】，重新引用的前提是：得获取到该白色对象，此时已经读屏障就发挥作用了。</p>
<p>对于读写屏障，以 Java HotSpot VM 为例，其并发标记时对漏标的处理方案如下：</p>
<ul>
<li><strong>CMS：写屏障 + 增量更新</strong></li>
<li><strong>G1、Shenandoah：写屏障 + SATB</strong></li>
<li><strong>ZGC：读屏障</strong></li>
</ul>
<p>读写屏障还有其他功能，比如写屏障可以用来记录跨代/区引用的变化，读屏障可以用于支持移动对象的并发执行等。</p>
<p>CMS中使用的增量更新，再重新标记阶段，除了需要遍历写屏障的记录，还需要重新扫描遍历GC Roots（标记过的无需再遍历），这是由于CMS对于astore_x等指令不添加写屏障的原因。</p>
<p><strong>为什么G1用SATB？CMS用增量更新？</strong></p>
<p>SATB（原始快照）相对增量更新效率比较高（当然SATB可能会造成更多的浮动垃圾），因为不需要在重新标记阶段再次深度扫描被删除引用对象，而CMS 对增量引用对象会做深度扫描，G1因为很多对象都处于不同的 Region，CMS就一块老年代区域，重新深度扫描对象的话，G1的代价会比CMS高，所以G1选择STAB不深度扫描对象，只是简单标记，等到下一轮再深度扫描。</p>
<h2 id="垃圾收集器"><a class="header" href="#垃圾收集器">垃圾收集器</a></h2>
<p><img src="https://github.com/chou401/pic-md/raw/master/img/image-20230424105126389.png" alt="image-20230424105126389" /></p>
<p><strong>GC 为什么要暂停用户线程？</strong></p>
<p>首先，如果不暂停用户线程，就意味着期间会不断有垃圾产生，永远也清理不干净。</p>
<p>其次，用户线程的运行必然会导致对象的引用关系发生改变，这就会导致两种情况：多标和漏标。</p>
<ol>
<li>
<p><strong>多标</strong></p>
<p>原本不是垃圾，但是GC的过程中，用户线程将其引用关系修改，导致GC Roots不可达，成为了垃圾。这种情况还好一点，无非就是产生了一些浮动垃圾，下次GC再清理就好了。</p>
</li>
<li>
<p><strong>漏标</strong></p>
<p>原来是垃圾，但是GC的过程中，用户线程将引用重新指向了它，这时如果GC一旦将其回收，将会导致程序运行错误。</p>
</li>
</ol>
<h3 id="串行垃圾收集器"><a class="header" href="#串行垃圾收集器">串行垃圾收集器</a></h3>
<p>为单线程环境设计且只使用一个线程进行垃圾回收，会暂停所有的用户线程，所以不适合服务器环境。</p>
<ul>
<li>
<p><strong>堆内存中新生代垃圾回收器（Serial）</strong></p>
<p>串行收集器是最古老，最稳定以及效率高的收集器，只使用一个线程去回收，但其在进项垃圾收集过程中可能会产生较长的停顿（Stop-The-World）状态。虽然在收集垃圾的过程找那个需要暂停所有其他的工作线程，但是它简单高效，对于限定单个CPU环境来说，没有线程交互的开销，可以获得最高的单线程垃圾收集效率，因此Serial 垃圾收集器依然是Java虚拟机运行在 Client 模式下默认的新生代垃圾收集器。</p>
</li>
<li>
<p><strong>堆内存中老年代垃圾回收器（Serial Old）</strong></p>
<p>Serial Old 是 Serial 垃圾收集器老年代版本，它同样是单线程的收集器，使用标记-压缩算法，这个收集器也主要是运行在 Client
默认的老年代垃圾收集器，在老年代中，也充当 CMS 收集器的后备垃圾收集方案（$\textcolor{red}{GC 单线程}$）。</p>
</li>
</ul>
<h3 id="并行垃圾收集器"><a class="header" href="#并行垃圾收集器">并行垃圾收集器</a></h3>
<p>多个垃圾回收器并行工作，此时用户线程是暂时的，适用于科学计算/大数据处理等弱交互场景。</p>
<ul>
<li>
<p><strong>堆内存中新生代垃圾回收器（ParNew、Parallel Scavenge）</strong></p>
<p>ParNew 收集器其实就是 Serial 收集器新生代的并行多线程版本，最常见的应用场景是配合老年代 CMS GC 工作，其余的行为和
Serial 收集器完全一样，ParNew 垃圾收集器在垃圾收集过程中同样也要暂停所有其他的工作线程（$\textcolor{red}{GC 多线程}$）。$\textcolor{CornflowerBlue}{JVM 配置：-XX:+UseParNewGC 使用ParNew收集器}$</p>
<p>Parallel Scavenge 收集器类似 ParNew 也是一个新生代垃圾收集器，使用拷贝算法，也是一个并行的多线程的垃圾收集器，俗称吞吐量优先收集器（$\textcolor{red}{GC
多线程}$）。</p>
<p>$\textcolor{CornflowerBlue}{JVM配置：-XX:+UseParallelGC 使用Parallel Scavenge收集器}$</p>
</li>
<li>
<p><strong>堆内存中老年代垃圾回收器（Parallel Old）</strong></p>
<p>Parallel Old 收集器是Parallel Scavenge 的老年代版本，使用多线程的标记-压缩算法，Parallel Old 收集器在 JDK1.6 才开始提供在 JDK1.6 之前，新生代使用Parallel Scavenge 收集器只能搭配老年代的 Serial Old 收集器，只能保证新生代的吞吐量优先，无法保证整体吞吐量。</p>
<p>JDK1.8 后考虑新生代 Parallel Scavenge 和老年代 Parallel Old 收集器的搭配策略。</p>
<p>$\textcolor{CornflowerBlue}{JVM配置：-XX:+UseParallelOldGC 使用Parallel Old收集器}$</p>
</li>
</ul>
<h3 id="cms并发垃圾收集器"><a class="header" href="#cms并发垃圾收集器">CMS（并发）垃圾收集器</a></h3>
<p>CMS（Concurrent Mark Sweep:并发标记清除）是一款里程碑式的垃圾收集器，因为在它之前，GC线程和用户线程是无法同时工作的，即使是 Parallel Scavenge，也不过是GC时开启多个线程并行回收而已，GC的整个过程依然要暂停用户线程，即Stop The World。这带来的后果就是Java程序运行一段时间就会卡顿一会，降低应用的响应速度，这对于运行在服务端的程序是不会被接收的。</p>
<p>CMS 是一种以<strong>获取最短回收停顿时间为目标</strong>的收集器。CMS 非常适合堆内存大、CPU核数多的服务器端应用，也是G1出现之前大型应用的首选收集器。<strong>用户线程和垃圾收集线程同时执行（不一定是并行，可能交替执行），不需要停顿用户线程</strong>，适用对响应时间有要求的场景，主要在老年代回收。</p>
<p>$\textcolor{CornflowerBlue}{JVM配置：-XX:+UseConcMarkSweepGC 使用CMS收集器}$</p>
<h4 id="垃圾收集流程"><a class="header" href="#垃圾收集流程">垃圾收集流程</a></h4>
<p><img src="https://github.com/chou401/pic-md/raw/master/img/image-20230424111120289.png" alt="image-20230424111120289" /></p>
<p><strong>大概分为四个主要步骤</strong></p>
<p><img src="https://github.com/chou401/pic-md/raw/master/img/image-20230424111223763.png" alt="image-20230424111223763" /></p>
<ul>
<li>
<p><strong>初始标记（Initial Mark）</strong></p>
<p>只是标记一下GC Roots 能关联的对象，速度很快。<strong>仍然需要暂停所有工作线程</strong>。不过这个过程非常快，而且<strong>初始标记的耗时不会因为堆空间的变大而变慢</strong>，是可控的，因此可以忽略这个过程导致的短暂停顿。</p>
</li>
<li>
<p><strong>并发标记（Concurrent Mark）</strong></p>
<p>进项 GC Roots 跟踪过程，和用户线程一起执行，不需要暂停工作线程，主要标记过程、标记全部对象。将初始标记的对象进行深度遍历，以这些对象为根，遍历整个对象图，这个过程耗时较长，而且<strong>标记的时间会随着堆空间的变大而变大</strong>。不会触发STW，用户线程仍然可以工作，程序依然可以响应，只是程序的性能会受到一点影响。因为GC线程会占用一定的CPU和系统资源，对处理器比较敏感。CMS默认开启的GC线程数是：（CPU核心数+3）/ 4，当CPU核心数超过4个时，GC线程会占用不到25%的CPU资源，如果CPU数不足4个，GC线程对程序的影响就会非常大，导致程序的性能大幅降低。</p>
</li>
<li>
<p><strong>重新标记（Remark）</strong></p>
<p>由于并发标记时，用户线程仍在运行，这意味着并发标记期间，用户线程有可能改变了对象间的引用关系，可能会发生两种情况：一种是原本不能被回收的对象，现在可以被回收了，另一种是原本可以被回收的对象，现在不能被回收了。针对这两种情况，CMS需要<strong>暂停所有用户线程</strong>，进行一次重新标记。</p>
</li>
<li>
<p><strong>并发清除（Concurrent Sweep）</strong></p>
<p>清楚 GC Roots 不可达对象，和用户线程一起工作，不需要暂停工作线程，基于标记结果，直接清除对象。这个过程耗时也比较长，且清理的开销会随着堆空间的变大而变大，和并发标记一样，清理时GC线程依然要占用一定的CPU和系统资源，会导致程序的性能降低。</p>
</li>
</ul>
<h4 id="缺点-1"><a class="header" href="#缺点-1">缺点</a></h4>
<p>尽管CMS是一款里程碑式的垃圾收集器，开启了GC线程和用户线程同时工作的先河，但是不管是哪个JDK版本，CMS从来都不是默认的垃圾收集器。</p>
<p><img src="https://github.com/chou401/pic-md/raw/master/img/image-20230424144233399.png" alt="image-20230424144233399" /></p>
<ul>
<li>
<p><strong>对处理器敏感</strong></p>
<p>并发标记、并发清理阶段，虽然CMS不会触发STW，但是标记和清理需要GC线程介入处理，GC线程会占用一定的CPU资源，进而导致程序的性能下降，程序响应速度变慢。CPU核心数多的话还稍微好一点，CPU资源紧张的情况下，GC线程对程序的性能影响比较大。</p>
</li>
<li>
<p><strong>浮动垃圾</strong></p>
<p>并发清理阶段，由于用户线程仍在运行，在次期间用户线程制造的垃圾就被称为“浮动垃圾”，浮动垃圾本次GC无法清理，只能留到下次GC再清理。</p>
</li>
<li>
<p><strong>并发失败</strong></p>
<p>由于浮动垃圾的存在，因此CMD必须预留一部分空间来装载这些新产生的垃圾。CMS不能像Serial Old收集器那样，等到Old区填满了再来清理。在JDK5时，CMS会在老年代使用了68%的空间时激活，预留了32%的空间来装载浮动垃圾，这是一个比较偏保守的配置。如果实际引用中，老年代增长的不是太快，可以通过 ==-XX：CMSInitiatingOccupancyFraction== 参数适当调高这个值。到了 JDK6，触发的阈值就被提升至92%，只预留了8%的空间来装载浮动垃圾。</p>
<p>如果CMS预留的内存无法容纳浮动垃圾，那么就会导致并发失败，这时JVM不得不触发预备方案，启用Serial Old 收集器来回收Old区，这时停顿时间就变得更长了。</p>
</li>
<li>
<p><strong>内存碎片</strong></p>
<p>由于CMS采用的是[标记清除]算法，这就意味着清理完成厚会在堆中产生大量的内存碎片。内存碎片过多会带来很多麻烦，其一就是很难为大对象分配内存。导致的后果就是：堆空间明明还有很多，但就是找不到一块连续的内存区域为大对象分配内存，而不得不触发一次Full GC，这样GC的停顿时间又会变得更长。</p>
<p>针对这种情况，CMS提供了一种备选方案，通过==-XX：CMSFullGCsBeforeCompaction== 参数设置，当CMS由于内存碎片导致出发了N次 Full GC 后，下次进入Full GC 前先整理内存碎片，不过这个参数在 JDK9 被弃用了。</p>
</li>
</ul>
<h3 id="g1垃圾收集器"><a class="header" href="#g1垃圾收集器">G1垃圾收集器</a></h3>
<h4 id="概述-1"><a class="header" href="#概述-1">概述</a></h4>
<p>G1（Garbage-First）垃圾回收器是在JDK7引入的一个新的垃圾收集器。在JDK9时被选定为默认收集收集器。</p>
<p>G1 最大的特点是引入分区的思路，弱化了分代的概念，合理利用垃圾收集各个周期的资源，解决了其他收集器的众多缺陷。</p>
<p>G1垃圾回收器将堆内存分割成不同的区域，然后并发的对其进行垃圾回收，G1 收集器的设计目标是取代 CMS 收集器。G1 和 CMS 相比，有以下不同：</p>
<ul>
<li>
<p>G1 能充分利用多CPU、多核环境硬件优势，尽量缩短 STW。部分其他收集器原本需要停顿 Java 线程执行的 GC 动作，G1 收集器仍然可以通过并发的方式让Java程序继续运行。</p>
</li>
<li>
<p>与 CMS 的 “标记-清除”算法不同，G1 从整体来看是基于“<strong>标记-压缩</strong>”算法实现的收集器，从局部来看是基于“复制”算法。因此其回收得到的空间是连续的。这避免了 CMS 回收器因为不连续空间所造成的问题，例如：需要更大的堆空间，更多的 floating garbage。连续空间意味着 G1 垃圾收集器可以不必采用空闲链表的内存分配方式，而可以直接采用 bump-the-pointer （撞针） 的方式。</p>
</li>
<li>
<p>G1 的内存与 CMS 要求的内存模型有极大的不同。G1 将内存划分一个个固定大小的region，每个region既可以是年轻代，也可以是老年代的。<strong>内存的回收是以region作为基本单位的</strong>。</p>
</li>
<li>
<p>G1 还要一个极其重要的特性：<strong>软实时</strong>（soft real-time）。所谓的实时垃圾回收，是指在要求的时间内完成垃圾回收。软实时则是指，用户可以指定垃圾回收时间的现时，G1 会努力在这个时限内完成垃圾回收，但是 G1 并不担保每次都能在这个时限内完成垃圾回收。通过设定一个合理的目标，可以让达到90%以上的垃圾回收时间都在这个时限内。</p>
<p>用户可以指定期望停顿时间（可通过配置 XX:MaxGCPauseMills=n最大停顿时间）。期<strong>望停顿时间模型是能够支持指定在一个长度为M毫秒的时间片段内，消耗在垃圾收集上的时间大概率不超过N毫秒这样的目标。</strong></p>
</li>
<li>
<p>G1可以面向堆内存任何部分来组成回收集（Collection Set，CSet）进行回收，衡量标准不再是它属于哪个分代，而是哪块内存中存放的垃圾数量最多，回收收益最大。</p>
</li>
<li>
<p>G1 虽然也是分代收集器，但整个内存分区不存在物理上的年轻代和老年代的区别，也不需要完全独立的 Survivor 堆做复制准备，G1只有逻辑上的分代概念，或者说每个分区都可以随 G1 的运作在不同代之间前后切换。</p>
<p>$\textcolor{CornflowerBlue}{JVM配置：-XX:+UseG1GC 使用G1收集器}$</p>
</li>
</ul>
<h4 id="内存模型"><a class="header" href="#内存模型">内存模型</a></h4>
<p><img src="https://github.com/chou401/pic-md/raw/master/img/image-20230425145527908.png" alt="image-20230425145527908" /></p>
<p>G1收集器采用一种不同的方式来管理内存：</p>
<p><img src="https://github.com/chou401/pic-md/raw/master/img/image-20230414181654804.png" alt="image-20230414181654804" /></p>
<p>**堆内存被划分为多个大小相等的heap区，每个heap区都是逻辑上连续的一段内存（virtual memory)，其中一部分区域被当成收集器相同的角色（eden，survivor，old），但每个角色的区域个数都不是固定的。**这在内存使用上提供了更多的灵活性。</p>
<h5 id="分区-region"><a class="header" href="#分区-region">分区 Region</a></h5>
<p>G1 采用了分区（Region）的思路，将整个堆内存区域分成<strong>大小相同</strong>的子区（Region），在JVM 启动时会自动设置这些子区域的大小，在堆的使用上，G1并不要求对象的存储一定要在物理上连续，只要逻辑上连续即可，每个分区也不会固定地为某个代服务，可以按需在年轻代和老年代之间切换。启动时可以通过参数设置 ==-XX:G1HeapRegionSize=n== 可指定分区大小（1MB~32MB，且必须是2的幂），默认将整堆划分为2048个分区。也即能够支持的最大内存为：32MB*2048 = 65536MB ≈ 64G内存。</p>
<p>这些 Region 的一部分包含新生代，新生代的垃圾收集依然采用暂停所有应用线程的方式，将存活的对象拷贝到老年代或者 Survivor空间。这些 Region 的一部分包含老年代，G1 收集器通过将对象从一个区域复制到另一个区域，完成了清理工作。这就意味着，在正常的处理过程中，G1完成了堆的压缩（至少是部分堆的压缩），这样就不会有CMS 的内存碎片问题了。</p>
<h5 id="卡片-card"><a class="header" href="#卡片-card">卡片 Card</a></h5>
<p>在每个分区内部又被分成了若干个大小为512Byte卡片（Card），标识堆内存最小可用粒度。所有分区的卡片，将会记录在全局卡片表（Global Card Table）中，分配的对象会占用物理上连续的若干个卡片，当查找分区内对象的引用时，便可通过卡片来查找该引用对象（见 RSet）。每次对内存的回收，都是对指定分区的卡片进行处理。</p>
<p>G1 对内存的使用以分区（Region）为单位，而对对象的分配则以卡片（Card）为单位。</p>
<p><img src="https://github.com/chou401/pic-md/raw/master/img/image-20230425160046585.png" alt="image-20230425160046585" /></p>
<h5 id="巨型对象-humongous-region"><a class="header" href="#巨型对象-humongous-region">巨型对象 Humongous Region</a></h5>
<p><strong>Region中还有一类特殊的Humongous区域,专门用来存储大对象。G1认为只要大小超过了一个Region容量一半的对象即可判定为大对象</strong>，而对于那些超过整个Region容量的超级大对象，将会被存放在N个连续的Humongous Region之中，G1的大多数行为都把Humongous Region作为老年代的一部分来进行看待。G1 内部做了一个优化，一旦发现没有引用指向巨型对象，则可直接在年轻代收集周期中被回收。</p>
<p>巨型对象会独占一个或多个连续分区，其中第一个分区被标记为开始巨型（StartsHumongous），相邻连续分区被标记为连续巨型（ContinuesHumongous）。由于需要一片连续的内存空间需要扫描整堆，因此确定巨型对象开始位置的成本比较高，如果可以，应用程序应避免生成巨型对象。</p>
<h5 id="已记忆集合-remember-setrset"><a class="header" href="#已记忆集合-remember-setrset">已记忆集合 Remember Set（RSet)</a></h5>
<p>除了 Card Table 数组之外，每个 Region 还会有一个 RSet 数据结构。RSet 主要用来记录哪个 Region 的哪个 Card 上的对象引用了本 Region 中的对象。Remebered Set “<strong>记住谁引用了我，以后我垃圾回收的时候，我好找它去</strong> ！”。</p>
<p>实际实现中，RSet 默认是一个 HashMap，Map的key是引用的 Region，value 是一个 List，List 中存储引用Region 中的引用 Card 列表。Region、Card Table 以及 RSet 的示意图：</p>
<p><img src="https://github.com/chou401/pic-md/raw/master/img/image-20230425162127860.png" alt="image-20230425162127860" /></p>
<p>上图中，RegionA 和 RegionB 中分别有对象引用 RegionC 中的对象，在 RegionC 对应的 RSet 就会记录这样的引用关系。这时候只需要扫描那两张Card 里的对象就可以了。这是一种<strong>典型的空间换时间</strong>的方法，避免了整个堆的扫描，提高效率。该 RSet 中有两个 KV 对，第一个 KV 的key是 RegionA，value 是一个列表，列表中有两个元素 3 和 65534，分别代表 RegionA 中引用对象在对应 Card Table 中的下标。第二个 KV 对的 key 是RegionB，value 中列表只有一个元素 1565，代表 RegionB 中引用对象在对应 Card Table 中的下标。</p>
<h5 id="收集集合cset"><a class="header" href="#收集集合cset">收集集合（CSet）</a></h5>
<p>CSet 收集示意图：</p>
<p><img src="https://github.com/chou401/pic-md/raw/master/img/image-20230425172916290.png" alt="image-20230425172916290" /></p>
<p>收集集合（Collection Set）代表每次GC暂停时回收的一系列目标分区。在任意一次收集暂停中，CSet 所有分区都会被释放，内部存活的对象都会被转移到分配的空闲分区中。因此无论是年轻代收集，还是混合收集，工作的机制都是一致的。年轻代收集 CSet 只容纳年轻代分区，而混合收集会通过启发式算法，在老年代候选回收分区中，筛选出回收收益最高的分区添加到 CSet 中。</p>
<p>候选老年代分区的 CSet 准入条件，可以通过活跃度阈值 ==-XX:G1MixedGCLiveThresholdPercent==（默认85%）进行设置，即只有存活对象低于85%的 Region 才可能被回收，从而拦截那些回收开销巨大的对象；同时，每次混合收集可以包含候选老年代分区，可根据 CSet 对堆的总大小占比 ==-XX:G1OldCSetRegionThresholdPercent==（默认10%）设置数量上限，即老年代一次最大收集总内存的10%。</p>
<p>由上述可知，G1 的收集都是根据 CSet 进行操作的，年轻代收集与混合收集没有明显的不同，最大的区别在于两种收集的触发条件。</p>
<h4 id="g1垃圾收集分类"><a class="header" href="#g1垃圾收集分类">G1垃圾收集分类</a></h4>
<p>G1的垃圾收集分为 ==Young GC==、==Mixed GC== 和 ==Full GC==。</p>
<h5 id="young-gc"><a class="header" href="#young-gc">Young GC</a></h5>
<p>G1 与之前垃圾收集器的 Young GC 有所不同，并不是当新生代的 Eden 区放满了就进行垃圾回收，G1 会计算当前 Eden 区回收大概需要多久的时间，如果回收时间远小于参数 ==-XX:MaxGCPauseMills== 设定的值，那么 G1 就会增加年轻代的 Region（可以从老年代或Humongous区划分 Region 给新生代），继续给新对象存放；直到下一次 Eden 区放满，G1 计算回收时间接近参数 ==-XX:MaxGCPauseMills== 设定的值，那么就会触发 <strong>Young GC</strong> 。</p>
<h5 id="mixed-gc"><a class="header" href="#mixed-gc">Mixed GC</a></h5>
<p>如果老年代的堆空间内存占用达到了参数 ==-XX:InitiatingHeapOccupancyPercent== 设定的值就会触发 ==Mixed GC==，回收所有的新生代和部分老年代（根据用户设置的 GC 停顿时间来确定老年代垃圾收集的先后顺序）以及 Humongous 区。正常情况下 G1 的垃圾收集是先做 ==Mixed GC==，主要是使用复制算法，需要把每个 Region 中存活的对象复制到另一个空闲的 Region，如果在复制过程中发现没有足够的空 Region 放复制的对象，那么就会触发一次 ==Full GC==。</p>
<h5 id="full-gc"><a class="header" href="#full-gc">Full GC</a></h5>
<p>停止系统程序，然后采用单线程进行标记、清理和压缩整理，以便空闲出来一批 Region 供下一次 ==Mixed GC== 使用，这个过程是非常耗时的。</p>
<p><strong>G1 是如何满足目标暂停时间的？</strong></p>
<p>前提：G1 的JVM内存模型在物理上分区Region，逻辑上分代。</p>
<ol>
<li>在年轻代收集（Young GC）期间，G1 GC 调整年轻代（Eden 和 Survivor）的大小以来匹配软实时（soft real-time）的目标。</li>
<li>在混合收集（Mixed GC）期间，G1 GC 根据混合垃圾收集的目标数量、堆中每个区域中活动对象的百分比以及总体可接收的堆浪费百分比来调整收集的旧区域的数量，以满足目标暂停时间目标。</li>
</ol>
<h4 id="收集过程"><a class="header" href="#收集过程">收集过程</a></h4>
<p>G1 在进行垃圾收集的时候，会根据每个 Region 预计垃圾收集所需时间与预计回收内存大小的占比来选择对哪些区域进行回收，也就是不再有 ==Minor GC/Young GC== 和 ==Major GC/Full GC== 的概念，而是采用一种 ==Mixed GC== 的方式，即混合回收的 GC 方式。</p>
<h5 id="年轻代收集"><a class="header" href="#年轻代收集">年轻代收集</a></h5>
<p>G1 的 Young GC 和 CMS 的 Young GC ，其标记-复制全过程 STW。</p>
<p><img src="https://github.com/chou401/pic-md/raw/master/img/image-20230426112834867.png" alt="image-20230426112834867" /></p>
<h5 id="混合收集"><a class="header" href="#混合收集">混合收集</a></h5>
<p>年轻代收集不断活动后，老年代的空间也会被逐渐填充。当老年代占用空间超过整堆比阈值 ==-XX:InitiatingHeapOccupancyPercent==（默认45%）时，G1 就会启动一次混合垃圾收集周期，即==Mixed GC== 。</p>
<p>该算法并不是一个老年代，除了回收整个年轻代，还会回收一部分老年代。需要注意：是一部分老年代，而不是全部老年代，可以选择哪些老年代进行收集，从而可以对垃圾回收的耗时时间进行控制。</p>
<p>G1 没有Full GC概念，需要 Full GC 时，调用 serialOldGC 进行全堆扫描（包括 Eden、Survivor、o、perm）。</p>
<p>为了满足暂停目标，G1 可能不能一口气将所有的候选分区收集掉，因此G1 可能会产生连续多次的混合收集要应用线程交替执行，每次STW 的混合收集与年轻代收集过程相类似。</p>
<p><img src="https://github.com/chou401/pic-md/raw/master/img/image-20230426140913494.png" alt="image-20230426140913494" /></p>
<p>GC 步骤分两步：</p>
<ol>
<li>全局并发标记（Global Concurrent Marking）</li>
<li>拷贝存活对象（Evacuation）</li>
</ol>
<p><strong>全局并发标记：</strong></p>
<ul>
<li>
<p>**初始标记（Initial Mark，STW）：**从 GC Roots 出发标记全部直接子节点的过程，这个阶段会执行一次年轻代 GC，会产生全局停顿。由于 GC Roots 数量不多，通常该阶段耗时比较短。</p>
</li>
<li>
<p><strong>跟区域扫描（Root Region Scan）：</strong></p>
<ul>
<li>G1 GC 在初始标记的存活区扫描对老年代的引用，并标记该被引用的对象。</li>
<li>该阶段与应用程序（非 STW）同时运行，并且只有完成该阶段后，才能开始下一次 STW 年轻代垃圾回收。</li>
</ul>
</li>
<li>
<p>**并发标记（Concurrent Marking）：**从 GC Roots 开始对堆中对象进行可达性分析，找出可访问的（存活的）对象。该阶段是并发的，即应用线程和 GC 线程可以同时活动。<strong>可以被 STW 年轻代垃圾回收中断</strong>。并发标记耗时相对长很多，但因为不是 STW，所以沃恩不太关心阶段耗时的长短。</p>
</li>
<li>
<p>**重新标记（Remark，STW）：**修正并发标记期间，因程序运行而导致标记发生变化的那一部分对象。该阶段是 STW 的。</p>
</li>
<li>
<p>**清除垃圾（Cleanup，STW）：**清点和重置标记状态，该阶段会 STW，<strong>这个阶段不会清理垃圾对象</strong>，也不会执行存活对象的复制，等待 evacuation 阶段来回收。</p>
</li>
</ul>
<p><strong>拷贝存活对象（并发清理）：</strong></p>
<p>该阶段把一部分 Region 里的存活对象拷贝到另一部分 Region 中，从而实现垃圾的回收清理。复制算法的转移阶段需要分配新内存和复制对象的成员变量。<strong>转移阶段是 STW 的</strong>，其中内存分配通常耗时非常短，但对象成员变量的复制耗时有可能较长，这是因为复制耗时与存活对象数量和对象复杂度成正比。对象越复杂，复制耗时越长。</p>
<p>四个 STW 过程中，出事标记因为只标记 GC Roots，耗时较短。重新标记因为对象较少，耗时也比较短。清理阶段因为内存分区数量少，耗时也较短。转移阶段要处理所有存活对象，耗时会较长。因此，G1 停顿时间的瓶颈主要是标记-复制中的转移阶段 STW。为什么转移阶段不能喝标记阶段一样并发执行？<strong>主要是 G1 未能解决转移过程中准确定位对象地址的问题。</strong></p>
<h4 id="g1-相关参数"><a class="header" href="#g1-相关参数">G1 相关参数</a></h4>
<div class="table-wrapper"><table><thead><tr><th style="text-align: center">参数</th><th style="text-align: center">说明</th></tr></thead><tbody>
<tr><td style="text-align: center">-XX:+UseG1GC</td><td style="text-align: center">开启使用G1垃圾收集器</td></tr>
<tr><td style="text-align: center">-XX:ParallelGCThreads</td><td style="text-align: center">指定GC工作的线程数量</td></tr>
<tr><td style="text-align: center">-XX:G1HeapRegionSize</td><td style="text-align: center">指定分区大小(1MB~32MB，且必须是2的N次幂)，默认将整堆划分为2048个分区</td></tr>
<tr><td style="text-align: center">-XX:MaxGCPauseMillis</td><td style="text-align: center">目标暂停(STW)时间(默认200ms)</td></tr>
<tr><td style="text-align: center">-XX:G1NewSizePercent</td><td style="text-align: center">新生代内存初始空间(默认整堆5%，<strong>值配置整数，比如5</strong>，默认就是百分比)</td></tr>
<tr><td style="text-align: center">-XX:G1MaxNewSizePercent</td><td style="text-align: center">新生代内存最大空间(最大60%，值配置整数)</td></tr>
<tr><td style="text-align: center">-XX:TargetSurvivorRatio</td><td style="text-align: center">Survivor区的填充容量(默认50%)，Survivor区域里的一批对象(年龄1+年龄2+年龄n的多个年龄对象)总和超过了Survivor区域的50%，此时就会把年龄n(含)以上的对象都放入老年代</td></tr>
<tr><td style="text-align: center">-XX:MaxTenuringThreshold</td><td style="text-align: center">最大年龄阈值(默认15)</td></tr>
<tr><td style="text-align: center">-XX:InitiatingHeapOccupancyPercent</td><td style="text-align: center">老年代占用空间达到整堆内存阈值(默认45%)，则执行新生代和老年代的混合收集(MixedGC)，比如堆默认有2048个region，如果有接近1000个region都是老年代的region，则可能就要触发MixedGC了</td></tr>
<tr><td style="text-align: center">-XX:G1MixedGCLiveThresholdPercent</td><td style="text-align: center">默认85%，Region中的存活对象低于这个值时才会回收该Region，如果超过这个值，存活对象过多，回收的的意义不大</td></tr>
<tr><td style="text-align: center">-XX:G1MixedGCCountTarget</td><td style="text-align: center">在一次回收过程中指定做几次筛选回收(默认8次)，在最后一个筛选回收阶段可以回收一会，然后暂停回收，恢复系统运行，一会再开始回收，这样可以让系统不至于单次停顿时间过长。</td></tr>
<tr><td style="text-align: center">-XX:G1HeapWastePercent</td><td style="text-align: center">默认5%，GC过程中空出来的Region是否充足阈值，在混合回收的时候，对Region回收都是基于复制算法进行的，都是把要回收的Region里的存活对象放入其他Region，然后这个Region中的垃圾对象全部清理掉，这样的话在回收过程就会不断空出来新的Region，一旦空闲出来的Region数量达到了堆内存的5%，此时就会立即停止混合回收，意味着本次混合回收就结束了</td></tr>
</tbody></table>
</div>
<h4 id="优化"><a class="header" href="#优化">优化</a></h4>
<p>假设参数 ==-XX:MaxGCPauseMills== 设置的值很大，导致系统运行很久，年轻代可能都占用了堆内存的60%了，此时才触发年轻代 GC。那么存活下来的对象可能就会很多，此时就会导致 Survivor 区域放不下那么多的对象，就会进入老年代中。或者是年轻代 GC 过后，存活下来的对象过多，导致进入 Survivor 区域后出发了动态年龄判断规则，达到了 Survivor 区域的50%，也会快速导致一些对象进入老年代中。</p>
<p>所以核心还是在于调节 ==-XX:MaxGCPauseMills== 这个参数的值，在保证他的年轻代 GC 别太频繁的同时，还得考虑每次 GC 过后的存活对象有多少，避免存活对象太多快速进入老年代，频繁触发 ==Mixed GC==。</p>
<p>什么场景适合使用 G1？</p>
<ul>
<li>50%以上的堆被存活对象占用</li>
<li>对象分配和晋升的速度变化非常大</li>
<li>垃圾回收时间特别长，超过1秒</li>
<li>8GB以上的堆内存（建议值）</li>
<li>停顿时间是500ms以内</li>
</ul>
<h4 id="安全点与安全区域"><a class="header" href="#安全点与安全区域">安全点与安全区域</a></h4>
<p>JVM 的所有垃圾收集器在做垃圾收集时，以 G1 的 ==Mixed GC== 为例，初始标记、并发标记等每一步都需要到达一个安全点或安全区域时才能开始执行。</p>
<p>安全点就是指代码中一些特定的位置，当线程运行到这些位置时它的状态是确定的，这样 JVM 就可以安全的进行一些操作，比如 GC 等，所以 GC 不是想什么时候做就立即触发的，是需要等待所有线程运行到安全点后才能触发。</p>
<p>这些特定的安全点文职主要有以下几种：</p>
<ul>
<li>方法返回之前</li>
<li>调用某个方法之后</li>
<li>抛出异常的位置</li>
<li>循环的末尾</li>
</ul>
<p>大体实现思想是当垃圾收集需要中断线程的时候，不直接对线程操作，仅仅简单地设置一个标志位，各个线程执行过程时会不停地主动去轮询这个标志，一旦发现中断标志位镇时就自己在最近的安全点上主动中断挂起。轮询标志的地方和安全点是重合的。==Safe Point== 是对正在执行的线程设定的。如果一个线程处于 Sleep 或中断状态，它就不能响应 JVM 的中断请求，再运行到 ==Safe Point== 上。因此 JVM 引入了 ==Safe Region== 。==Safe Region== 是指在一段代码片段中，引用关系不会发生变化。在这个区域内的任何地方开始 GC 都是安全的。</p>
<h4 id="注意事项"><a class="header" href="#注意事项">注意事项</a></h4>
<ul>
<li>避免通过 -Xmn 或其他相关选项（如==-XX:NewRate==）显式设置年轻代的大小，因为年轻代的大小被固定后会导致 G1 的目标暂停机制失效。</li>
<li>当设置目标暂停时间 MaxGCPauseMillis 时，需要评估 G1 GC 的延迟和应用吞吐量之间的取舍，当该值设置较小时，标明你愿意承担垃圾收集开销的增加，从而会导致应用程序吞吐量的降低。</li>
<li>Mixed GC 的调优
<ul>
<li>==-XX:InitiatingHeapOccupancyPercent==： 控制并发标记开始的内存占比阈值。</li>
<li>==-XX:G1HeapWastePercent==： 设置G1中愿意浪费的堆的百分比，如果可回收Region的占比小于该值，G1不会启动Mixed GC，默认值10%，主要用来控制Mixed GC的触发时机。</li>
<li>==-XX:G1MixedGCLiveThresholdPercent==：设置老年代Region进入CSet的活跃对象占比阈值，避免活跃对象占比过高的Region进入CSet。</li>
<li>==-XX:G1MixedGCCountTarget== 和 ==-XX:G1OldCSetRegionThresholdPercent==: 主要是为了控制单次Mixed GC中Region的个数，CSet中Region的个数越多，GC过程中暂停时间越长。</li>
</ul>
</li>
</ul>
<h4 id="典型问题"><a class="header" href="#典型问题">典型问题</a></h4>
<h5 id="疏散失败evacuation-failure"><a class="header" href="#疏散失败evacuation-failure">疏散失败（Evacuation Failure）</a></h5>
<p>当没有更多的空闲Region被提升到老年代或者复制到Survivor时，并且由于堆已经达到最大值，堆不能扩展，从而发生 Evacuation Failure，这时 G1 的 GC 已经无能为力，只能使用通过 Serial Old GC 进行 Full GC 来收集整个Java堆空间，这个过程就是转移失败。</p>
<p><strong>解决方案</strong></p>
<ul>
<li>如果有大量“空间耗尽（to-space exhausted）”或“空间溢出（to-space overflow）” GC 事件，则增加 ==-XX:G1ReservePercent== 以增加“to-space” 的预留内存量，默认值是Java堆的10%。注意：G1 GC 将此值限制在50%以内。</li>
<li>通过减少 ==-XX: InitiatingHeapOccupancyPercent== 的值来更早地启动并发标记周期，来及时回收不包含活跃对象的区域，同时促使 Mixed GC 更快发生。</li>
<li>增加选项 ==-XX:ConcGCThreads== 的值以增加并行标记线程的数量，减少并行标记阶段的耗时。</li>
</ul>
<h5 id="大对象分配humongous-allocation"><a class="header" href="#大对象分配humongous-allocation">大对象分配（Humongous Allocation）</a></h5>
<p>出现大对象分配导致的内存耗尽问题，一般老年代剩余的 Region 中已经不能够找到一组连续的区域分配给新的巨型对象。</p>
<p><strong>解决方案</strong></p>
<ul>
<li>通过 ==-XX: G1HeapRegionSize== 选项增加内存区域 Region 的大小，提升 Region 对象的判断标准，以减少巨大对象的数量。</li>
<li>增加堆Java的大小使得有更多的空间来存放巨型对象。</li>
<li>通过 ==-XX:G1MaxNewSizePercent== 降低年轻代 Region 的占比，给老年代预留更多的空间，从而给巨型对象提供更多的内存空间。</li>
</ul>
<p>一般在疏散暂停（Evacuation Pause）和大对象分配（Humongous Allocation）会比较容易出现“空间耗尽（to-space exhausted）”或“空间溢出（to-space overflow）”的GC 事件，导致出现转移失败，进而引发 Full GC 从而导致GC的暂停时间超过 G1 设置的目标暂停时间。所以要尽量避免出现转移失败。</p>
<h5 id="young-gc-花费时间太长"><a class="header" href="#young-gc-花费时间太长">Young GC 花费时间太长</a></h5>
<p>通常 Young GC 的耗时与年轻代的大小成正比，具体地说，是需要复制的集合中的活跃对象的数量。</p>
<p>如果 Young GC 中 CSet 的疏散阶段（Evacuate Collection Set phase）需要很长时间，尤其是其中的对象复制-转移，可以通过降低 ==-XX:G1NewSizePercent== 的值，降低年轻代的最小尺寸，从而降低停顿时间。</p>
<p>还可以使用 ==-XX:G1MaxNewSizePercent== 降低年轻代的最大占比，从而减少 Young GC 暂停期间需要处理的对象数量。</p>
<h5 id="mixed-gc-耗时太长"><a class="header" href="#mixed-gc-耗时太长">Mixed GC 耗时太长</a></h5>
<ul>
<li>通过降低 ==-XX:InitiatingHeapOccupancyPercent== 的值，来调低并发标记阶段开始的阈值，让并发标记阶段更早触发，只有并发标记完成才能开始执行 Mixed GC。</li>
<li>通过调节 ==-XX:G1MixedGCCountTarget== 和 ==-XX:G1OldCSetRegionThresholdPercent== 参数，降低单次回收的Region 数量，减少暂停时间。</li>
<li>通过调节 ==-XX:G1MixedGCLiveThresholdPercent== 的值，避免活跃对象占比过高的Region进入 CSet。因为活的对象越多，Region中可回收的空间就越少，暂停时间就越长，GC 效果就越不明显。</li>
<li>通过调节 ==-XX:G1HeapWastePercent== 的值，设置愿意浪费的堆的百分比，只有垃圾占比大于此参数，才会发生 Mixed GC，该值越小，会越早触发 Mixed GC。</li>
</ul>
<h4 id="总结"><a class="header" href="#总结">总结</a></h4>
<p>G1 是一款非常优秀的垃圾收集器，不仅适合堆内存大的应用，同时也简化了调优的工作。通过主要的参数初始和最大堆空间、以及最大容忍的 GC 暂停目标，就能得到不错的性能。</p>
<ul>
<li>G1 的设计原则是<strong>首先收集尽可能多的垃圾</strong>（Garbage First）。因此，G1 并不会等内存耗尽的时候开始垃圾收集，而是在内部采用了启发式算法，在老年代找出具有高收集收益的分区进行收集。同时G1 可以根据用户设置的暂停时间目标自动调整年轻代和总堆大小，暂停目标越短，年轻代空间越小、总空间就越大；</li>
<li>G1 采用内存分区（Region）的思路，将内存划分为一个个相等大小的内存分区，回收时则以分区为单位进行回收，存活的对象复制到另一个空闲分区中。由于都是以相等大小的分区为单位进行操作，因此 G1 天然就是一种压缩方案（局部压缩）；</li>
<li>G1 虽然也是分代收集器，但整个内存分区不存在物理上的年轻代与老年代的区别，也不需要完全独立的 Survivor 堆做复制准备。G1 只有逻辑上的分代概念，或者说每个分区都可能随 G1 的运行在不同代之间前后切换；</li>
<li>G1 的收集都是 STW 的，但年轻代和老年代的收集界限比较模糊，采用了混合（Mixed）收集的方式，即每次收集既可能只收集年轻代分区（年轻代收集），也可能在收集年轻代的同时，包含部分老年代分区（混合收集），这样即使堆内存很大时，也可以限制收集范围，从而降低停顿。</li>
</ul>
<h3 id="zgc垃圾收集器"><a class="header" href="#zgc垃圾收集器">ZGC垃圾收集器</a></h3>
<p>从G1 垃圾收集器开始，后面的垃圾收集器都不再将堆按照新生代和老年代作为整体进行回收，都采用了局部收集的设计思想。可能是由于G1作为第一代局部收集的垃圾收集器，所以它继续保留了新生代和老年代的概念。</p>
<p>ZGC设计目标：</p>
<ul>
<li>停顿时间不超过10ms。</li>
<li>停顿时间不会随堆的大小，或者活跃对象的大小而增加。</li>
<li>支持8MB~4TB级别的堆。</li>
</ul>
<p>从设计目标来看，我们知道ZGC适用于大内存低延迟服务的内存管理和回收。</p>
<p>与CMS中的ParNew和G1类似，ZGC也采用标记-复制算法，不过ZGC对该算法做了重大改进：ZGC在标记、转移和重定位阶段几乎都是并发的，这是ZGC实现停顿时间小于10ms目标的最关键原因。</p>
<p><img src="https://github.com/chou401/pic-md/raw/master/img/image-20230417102646070.png" alt="image-20230417102646070" /></p>
<p>ZGC只有三个STW：初始标记、再标记、初始转移。其中，初始标记和初始转移分别都只需要扫描所有GC Roots，其处理时间和GC Roots的数量成正比，一般情况耗时比较短；再标记阶段STW时间很短，最多1ms，超过1ms则再次进入并发标记阶段，即，ZGC几乎所有的暂停都只依赖于GC Roots集合大小，停顿时间不会随着堆的大小或者活跃对象的大小而增加。与ZGC对比，G1的转移阶段完全STW的，且停顿时间随存活对象的大小增加而增加。</p>
<h4 id="内存布局"><a class="header" href="#内存布局">内存布局</a></h4>
<p>ZGC（Z Garbage Collector）完全抛弃了按代收集理论，它与G1一样将内存划分成各个小的区域，但与G1有所不同的是，ZGC的各个内存区域称为页面（Page或ZPage），而且页面也不是全部大小相等。ZGC按照页面大小将页面分为三类：小页面、中页面和大页面。</p>
<p>在x64的硬件平台上，ZGC的页面大小为：</p>
<ul>
<li>
<p>小页面：容量固定为2MB，用来存放小于256KB的小对象。</p>
</li>
<li>
<p>中页面：容量固定为32MB，用来存放大于等于256KB但小于4MB的对象。</p>
</li>
<li>
<p>大页面：容量不固定，可以动态变化，但必须为2MB的整数倍，用来存放大小大于等于4MB的对象。每个大页面只会存放一个大对象，也就是虽然它叫大页面，但它的容量可能还没中页面大，最小容量4MB。</p>
<p><img src="https://github.com/chou401/pic-md/raw/master/img/image-20230414172817666.png" alt="image-20230414172817666" /></p>
</li>
</ul>
<p>ZGC对于大页面的回收策略是不同的，简单说就是小页面优先回收，中页面和大页面则尽量不回收。</p>
<h4 id="支持numa"><a class="header" href="#支持numa">支持NUMA</a></h4>
<p>在过去，对于X86架构的计算机，内存控制器还没有整合进CPU，所有对内存的访问都需要通过北桥芯片来完成。X86系统中的所有内存都可以通过CPU进行同等访问。任何CPU访问任何内存的速度是一致的，不必考虑不同内存地址之间的差异，这称为“统一内存访问”（Uniform Memory Access，UMA）。UMA系统的架构示意图如图所示：</p>
<p><img src="https://github.com/chou401/pic-md/raw/master/img/image-20230414175606068.png" alt="image-20230414175606068" /></p>
<p>在UMA中，各处理器与内存单元通过互联总线进行连接，各个CPU之间没有主从关系。之后的X86平台经历了一场从“拼频率”到“拼核心数”的转变，越来越多的核心被尽可能的塞进了同一块芯片上，各个核心对于内存带宽的争抢访问称为瓶颈，所以人们希望能够把CPU和内存集成在一个单元上（称Socket），这就是非统一内存访问（Non-Uniform Memory Access，NUMA）。在NUMA下，CPU访问本地存储器的速度比访问非本地存储器快一些。</p>
<p><img src="https://github.com/chou401/pic-md/raw/master/img/image-20230414175933503.png" alt="image-20230414175933503" /></p>
<p>ZGC是支持NUMA的，在进行小页面分配时优先从本地内存分配，当不能分配时才会从远端的内存分配。对于中页面和大页面的分配，ZGC并没有要求从本地内存分配，而是直接交给操作系统，由操作系统找到一块能满足ZGC页面的空间。ZGC这样设计的目的在于，对于小页面，存放的都是小对象，从本地内存分配速度很快，且不会造成内存使用的不平衡，而中页面和大页面因为需要空间大，如果也优先从本地内存分配，极易造成内存使用不均衡，反而影响性能。</p>
<h4 id="着色指针"><a class="header" href="#着色指针">着色指针</a></h4>
<p>ZGC收集器有一个标志性的设计就是它采用染色指针技术（Colored Pointer，也可以称为Tag Pointer或Version Pointer）。在之前如果想要在对象上存储一些额外的、只供垃圾收集器或虚拟机本身使用的数据，通常都会在对象头中添加额外的字段，比如对象的哈希码、分代年龄、锁状态等。</p>
<p>对于垃圾收集器而言，可能关注更多的是对象的引用指针，比如三色标记，这些标记本质上就只和对象的引用有关，而与对象本身无关，也就是某个对象只有它的引用关系能决定它存活与否，对象上的其他属性无法影响它的存活判断。</p>
<p>HotSpot集中收集器的标记实现方案，有得把标记直接记录在对象头（Serial），有得把标记记录在与对象完全独立的数据结构上（如G1采用BitMap的结构来记录标记信息，BitMap相当于堆内存大小的1/64）。而ZGC的染色指针是最最直接的，直接把标记信息记在引用对象的指针上，这时，与其说可达性分析是遍历对象来标记对象，还不如说是遍历<strong>引用图标</strong>来标记<strong>引用</strong>。</p>
<p>染色指针是一种直接将少量额外的信息存储到指针上的技术。在ZGC之前的虚拟机中，可以采用指针压缩技术，将35位以内的对象引用地址压缩到32位，而ZGC的染色质真就是要借助指针的bit位来存储额外信息。</p>
<p><img src="https://github.com/chou401/pic-md/raw/master/img/image-20230417111630085.png" alt="image-20230417111630085" /></p>
<p><img src="https://github.com/chou401/pic-md/raw/master/img/image-20230417113559100.png" alt="image-20230417113559100" /></p>
<p>ZGC必须要在64bit的机器上才能运行，其中使用低42位来表示对空间，然后借用几个高位来记录GC中的状态信息，分别为M0、M1、Remapped和一个预留字段，因为对象的引用地址大于35bit，所以在ZGC中是无法使用压缩指针的。</p>
<p>当应用程序创建对象时，首先在堆空间申请一个虚拟地址，但该虚拟地址并不会映射到真正的物理地址。ZGC同时会为该对象在M0、M1、Remapped地址空间分别申请一个虚拟地址，且这三个虚拟地址对应同一个物理地址，但这三个空间在同一时间有且只有一个空间有效。ZGC之所以设置三个虚拟地址空间，是因为它使用“空间换时间”思想，去降低GC停顿时间。“空间换时间”中的空间是虚拟空间，而不是真正的物理空间。</p>
<p>与上述地址空间划分相对应，ZGC实际仅使用64位地址空间的第0-41位，而第42-45位存储元数据，第47-63位固定位0。</p>
<p><img src="https://github.com/chou401/pic-md/raw/master/img/image-20230417114248169.png" alt="image-20230417114248169" /></p>
<p>每个对象有一个64位指针，这64位被分为：</p>
<ul>
<li><strong>18位</strong>：预留给以后使用；</li>
<li><strong>1位</strong>：Finalizable标识，此位与并发引用处理有关，它标识这个对象只能通过finalizable才能访问（finalizable：object基类的一个空方法，如果被重写则会在GC之前调用该方法，该方法会且只会被调用一次）；</li>
<li><strong>1位</strong>：Remapped标识，设置此位的值后，对象未指向relocation set中（relocation set表示需要GC的Region集合）；</li>
<li><strong>1位</strong>：Marked1标识；</li>
<li><strong>1位</strong>：Marked0标识，和上面的Marked1都是标记对象用于辅助GC；</li>
<li><strong>42位</strong>：对象的地址（所以它可以支持2^42=4T内存）。</li>
</ul>
<p>ZGC将对象存活信息存储在42-45位中，这与传统的垃圾回收并将对象存活信息放在对象头中完全不同。</p>
<p>在GC的过程中，指针中用于存储额外信息的bit位是变化的，也就是说对象的引用地址一直是在变化的，这怎么可能是物理空间的地址呢，对程序来说，只要这个对象没有被移动，那么它的物理地址空间就一定是不变的，那么ZGC的对象引用地址一直在变，这里指的是对象的虚拟地址，JVM怎么知道真实的物理地址空间？</p>
<p>这里面就涉及到了虚拟地址空间与物理地址空间的映射，不同层次的虚拟内存到物理内存的转换关系可以在硬件层面、操作系统层面以及软件进程层面来实现，如何完成地址转换，是一对一、多对一还是一对多的映射，也可以根据实际需要来设计。</p>
<p>Linux/x86-64平台上的ZGC使用的是多重映射（Multi-Mapping），即将多个不同的虚拟内存地址映射到同一个物理内存地址上，这种多对一映射，意味着ZGC在虚拟地址中看到的地址空间要比实际的堆空间容量更大，因为在虚拟空间中，ZGC的对象占45bit，而在物理内存空间中，只有其中的41bit表示内存地址。</p>
<p>有个多重映射，ZGC在GC过程中，不论M0、M1和Remapped对应的bit位怎么变化，它们对应的具体对象的内存空间都是同一个。</p>
<p>Linux多视图映射，Linux中主要通过系统函数mmap完成视图映射。多个视图映射就是多次调用mmap函数，多次调用的返回结果就是不同的虚拟地址。</p>
<pre><code class="language-c">#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;unistd.h&gt;
#include &lt;sys/mman.h&gt;
#include &lt;sys/types.h&gt;
#include &lt;fcntl.h&gt;
#include &lt;sys/stat.h&gt;
#include &lt;stdint.h&gt;

int main()
{
    //创建一个共享内存的文件描述符
    int fd = shm_open(&quot;/example&quot;, O_RDWR | O_CREAT | O_EXCL, 0600);
    if (fd == -1) return 0;
    //防止资源泄露,需要删除。执行之后共享对象仍然存活,但是不能通过名字访问
    shm_unlink(&quot;/example&quot;);

    //将共享内存对象的大小设置为4字节
    size_t size = sizeof(uint32_t);
    ftruncate(fd, size);

    //3次调用mmap,把一个共享内存对象映射到3个虚拟地址上
    int prot = PROT_READ | PROT_WRITE;
    uint32_t *remapped = mmap(NULL, size, prot, MAP_SHARED, fd, 0);
    uint32_t *m0 = mmap(NULL, size, prot, MAP_SHARED, fd, 0);
    uint32_t *m1 = mmap(NULL, size, prot, MAP_SHARED, fd, 0);


    //关闭文件描述符
    close(fd);

    //测试,通过一个虚拟地址设置数据,3个虚拟地址得到相同的数据
    *remapped = 0xdeafbeef;
    printf(&quot;48bit of remapped is: %p, value of 32bit is: 0x%x\n&quot;, remapped, *remapped);
    printf(&quot;48bit of m0 is: %p, value of 32bit is: 0x%x\n&quot;, m0, *m0);
    printf(&quot;48bit of m1 is: %p, value of 32bit is: 0x%x\n&quot;, m1, *m1);


    return 0;
}
</code></pre>
<p><strong>三大优势</strong>：</p>
<ul>
<li>一旦某个Region的存活对象被移走后，这个Region立即就能够释放和重用掉，而不必等待整个堆中所有指向该Region的引用都被修改后才能清理，这使得理论上只要还有一个空闲Region，ZGC就能完成收集。</li>
<li>着色指针可以大幅减少在垃圾收集过程中内存屏障的使用数量，ZGC只使用了读屏障。</li>
<li>着色指针具备强大的扩展性，因为还要18位未使用，它可以作为一种可扩展的存储结构用来记录更多与对象标记、重定位过程相关的数据，以便日后进一步提高性能。</li>
</ul>
<h4 id="读屏障"><a class="header" href="#读屏障">读屏障</a></h4>
<p>并发标记阶段会进行对象的重定位以及删除对应的转发表，在ZGC中是通过读屏障实现的。</p>
<p>读屏障就是JVM向应用程序代码中插入一小段代码的技术，当应用程序线程需要从堆中读取对象引用时，就会执行这段代码。</p>
<pre><code class="language-java">Object o = obj.FieldA; // 从堆中读取引用，需要加入屏障
Object p = o; // 无需加入屏障，因为不是从堆中读取引用
o.dosomething(); // 无需加入屏障，因为不是从堆中读取引用
int i =  obj.FieldB; // 无需加入屏障，因为不是对象引用
</code></pre>
<p>ZGC采用读屏障的方式来修正指针引用，由于ZGC采用的是复制整理的方式进行GC，很有可能在对象的位置改表之后指针位置尚未更新时程序调用了该对象，那么此时在程序需要并行的获取该对象的引用时，ZGC就会对该对象的指针进行读取，判断Remapped标识，如果标识为该对象位于背刺需要清理的Region区中，该对象则会有内存地址变化，会在指针中将新的引用地址替换原有对象的引用地址，然后再进行返回。如此，使用读屏障便解决了并发GC的对象读取问题。</p>
<h4 id="垃圾收集流程-1"><a class="header" href="#垃圾收集流程-1">垃圾收集流程</a></h4>
<p>ZGC一次垃圾回收周期中地址视图的切换过程：</p>
<p><strong>初始化</strong>：ZGC初始化之后，整个内存空间的地址被设置为Remapped。程序正常运行，在内存分配对象，满足一定条件后垃圾回收启动，此时进入阶段。</p>
<p><strong>并发标记阶段</strong>：第一次进入标记阶段时视图为M0，如果对象被GC标记线程或者应用线程访问过，那么就将对象的地址视图从Remapped调整为M0。所以在标记阶段结束之后，对象的地址要么是M0视图，要么是Remapped。如果对象的地址是M0视图，那么说明对象时活跃的；如果对象的地址是Remapped视图，说明对象是不活跃的。</p>
<p><strong>并发转移阶段</strong>：标记结束后就进入转移阶段，此时地址视图再次被设置为Remapped。如果对象被GC转移线程或者应用线程访问过，那么就将对象的地址视图从M0调整为Remapped。</p>
<p>其实，再标记阶段存在两个地址视图M0和M1，上面的过程显示只用了一个地址视图，之所以设计成两个，是为了区别前一次标记和当前标记。也即，第一次进入并发标记阶段后，地址视图调整为M1，而非M0。</p>
<p>着色指针和读屏障技术不仅应用在并发转移阶段，还应用在并发标记阶段：将对象设置为已标记，传统的垃圾回收器需要进行一次内存访问，并将对象存活信息放在对象头中；而在ZGC中，只需要设置指针地址的第42-45位即可，并且因为是寄存器访问，所以速度比访问内存更快。</p>
<p><img src="https://github.com/chou401/pic-md/raw/master/img/image-20230423160203752.png" alt="image-20230423160203752" /></p>
<ul>
<li>
<p><strong>标记</strong></p>
<p>从GC Roots出发，标记活跃对象，此时内存中存在或与对象和垃圾对象。</p>
<p>在标记阶段，与G1基本相同，唯一的不同在于，在初始标记的时候，G1只能单线程进行，而ZGC为了追求性能，使用多线程（多个GC线程）进行。</p>
<p>ZGC的再标记过程与G1的最终标记是一样，都是为了处理漏标对象，也是通过<strong>原始快照</strong>（STAB）算法解决，因为内存布局都是基于Region/Page。</p>
<p>染色指针，通过M0、M1和Remapped来标记指针的状态，其中M0和M1主要用于区分连续的两次GC，ZGC的整个GC过程涉及到两次连续的GC，并不是一次GC就把所有工作都做了。</p>
<p>我们给M0、M1和Remapped三种状态赋予不同的颜色，方便理解：</p>
<p><img src="https://github.com/chou401/pic-md/raw/master/img/image-20230423150650176.png" alt="image-20230423150650176" /></p>
<p>假设现在有四个对象，都在小页面（对象大小&lt;2MB）A中，因为此时还没有开始进行GC，所以所有引用的指针都处于Remapped状态：</p>
<p><img src="https://github.com/chou401/pic-md/raw/master/img/image-20230423153653755.png" alt="image-20230423153653755" /></p>
<p>经过初次标记阶段厚，对象A被GC Root 引用，对象D被任何对象引用，A对象引用的指针颜色发生变化：</p>
<p><img src="https://github.com/chou401/pic-md/raw/master/img/image-20230423154450713.png" alt="image-20230423154450713" /></p>
<p>然后进行并发标记，并发标记过程中，将所有存活对象的指针状态全部改为M0，由于D对象不可达，所以它的指针颜色还是蓝色，但在并发标记阶段，B对象又引用了一个新的对象E，因为是新的对象还没有被GC扫描过，所以指针颜色是蓝色：</p>
<p><img src="https://github.com/chou401/pic-md/raw/master/img/image-20230423154608727.png" alt="image-20230423154608727" /></p>
<p>而在重新标记阶段，根据原始快照（STAB）会从B对象继续开始扫描，然后把E对象的指针变为绿色：</p>
<p><img src="https://github.com/chou401/pic-md/raw/master/img/image-20230423154643033.png" alt="image-20230423154643033" /></p>
<p>至此标记阶段就完成了，剩下的对象指针为Remapped的都是垃圾对象，转移阶段进行回收。</p>
</li>
<li>
<p><strong>转移</strong></p>
<p>将活跃对象转移（复制）到新的内存上，原来的内存空间可回收，在并发转移阶段准备阶段，如果发现某个页全部都是垃圾对象，直接在该过程就把这些区域全部回收了。</p>
<p>在并发转移阶段，会分析最有价值的GC分页，这个过程类似于G1筛选回收阶段的澄碧于收益比分析。</p>
<p>在初始转移阶段，只会转移初始标记的存活对象，同时做对象的重定位，假设小页面A的对象都要转移到小页面B中，经过初始转移后，对象的位置及指针颜色如下：</p>
<p><img src="https://github.com/chou401/pic-md/raw/master/img/image-20230423163652891.png" alt="image-20230423163652891" /></p>
<p>因为A对象转移到新的页面时进行了重定位，所以A对象的指针状态变为了Remapped蓝色。但对B对象的引用指针还是绿色。</p>
<p>然后进行并发转移，把B、C、E对象也都转移到小页面B中：</p>
<p><img src="https://github.com/chou401/pic-md/raw/master/img/image-20230423165819998.png" alt="image-20230423165819998" /></p>
<p>在并发转移阶段，只会把B、C、E对象转移到新的小页面B中，并不会修改它们对应的引用指针，也就是B对C的引用还指向原来小页面中的旧地址，并没有对转移对象做重定位。</p>
<p>但对象既然转移了，那肯定需要根据之前旧的地址找到新的地址，所以每个页面都会维护一张<strong>转发表</strong>，这个转发表就记录了指针旧地址到新地址的映射。</p>
<p><strong>注：对象转移与转发表插入记录这是一个原子操作，要么都成功，要么都失败。</strong></p>
</li>
<li>
<p><strong>重定位</strong></p>
<p>因为活跃对象的地址发生了变化，所以所有指向对象老地址的指针需要调整到新的对象地址上。</p>
<p>在第一次GC的时候，只是用了M0，在第二次GC的时候，就会用到M1，这两个标志位就是为了区分两次不同的垃圾回收的。</p>
<p>在第一次GC完成和第二次GC开始的间隙，A对象又引用了一个新的对象F，如下图所示：</p>
<p><img src="C:/Users/Administrator/AppData/Roaming/Typora/typora-user-images/image-20230423165706646.png" alt="image-20230423165706646" /></p>
<p>因为是一个新创建的对象，所以指针状态为Remapped。</p>
<p>当第二次GC开始，由于上一次GC使用M0来表示存活对象，那么这一次就采用M1来标识存活对象，然后经过初始标记后，对象A的引用就变成了红色：</p>
<p><img src="https://github.com/chou401/pic-md/raw/master/img/image-20230423165640436.png" alt="image-20230423165640436" /></p>
<p>然后进行并发标记，在并发标记的过程中，因为F对象的指针为蓝色，就将其直接改为红色。当对象A扫描引用B时，发现它的指针颜色为绿色，状态为M0，它就会到原来的小页面A的转发表取到对象B的新地址进行重定位，然后再从转发表删除B指针的记录，重定位和删除转发表同样也是原子操作。C对象和E对象的操作一样，经过并发标记厚，新的对象布局如下：</p>
<p><img src="https://github.com/chou401/pic-md/raw/master/img/image-20230423170212287.png" alt="image-20230423170212287" /></p>
<p>然后依次类推，下一次GC做标记时，在使用M0来标记存活对象。</p>
<p>为什么要把重定向放到下一次GC的并发标记过程来做呢？</p>
<p>重定向需要遍历所有存活对象，而下一次GC并发标记的时候也需要遍历所有存活，直接利用并发标记过程中遍历对象顺带做重定位减少一次扫描全部存活对象的开销，这样可以非常显著地提高垃圾收集性能。</p>
</li>
</ul>
<h4 id="gc时机"><a class="header" href="#gc时机">GC时机</a></h4>
<ul>
<li>
<p><strong>预热规则</strong></p>
<p>服务刚启动时出现，一般不需要关注。日志中关键字是“Warmup”。</p>
<p>JVM启动预热，如果从来没有发生过GC，则在堆内存使用超过**10%、20%、30%**时，分别触发一次GC，以收集GC数据。</p>
</li>
<li>
<p><strong>基于分配速率的自适应算法</strong></p>
<p>最主要的GC触发方式（默认方式），其算法原理可简单描述为<strong>ZGC根据近期的对象分配速率以及GC时间，计算出当内存占用达到什么阈值时触发下一次GC</strong>。通过 ZAllocationSpikeTolerance 参数控制阈值大小，该参数默认2，数值越大，越早的触发GC。日志中关键字 <strong>Allocation Rate</strong>。</p>
</li>
<li>
<p><strong>基于固定时间间隔</strong></p>
<p>通过 ZCollectionInterval 控制，适合应对突增流量场景。</p>
<p>流量平稳变化时，自适应算法可能在堆使用率达到95%以上才触发GC。流量突增时，自适应算法触发的时机可能会过晚，导致部分线程阻塞。我们通过调整此参数解决流量突增场景的问题，比如定时任务、秒杀场景。</p>
</li>
<li>
<p><strong>主动触发</strong></p>
<p>类似于固定间隔规则，但时间间隔不固定，是ZGC自行算出来的时机，服务因为已经加了基于固定时间间隔的触发机制，所以通过 -ZProactive 参数将该功能关闭，以免GC频繁，影响服务可用性。</p>
</li>
<li>
<p><strong>阻塞内存分配请求触发</strong></p>
<p>当垃圾来不及回收，垃圾将堆占满时，会导致部分线程阻塞。我们应当避免出现这种触发方式。日志中关键字是 <strong>Allocation Stall</strong>。</p>
</li>
<li>
<p><strong>外部触发</strong></p>
<p>代码中显式调用 System.gc() 触发。日志中关键字是 <strong>System.gc()</strong>。</p>
</li>
<li>
<p><strong>元数据分配触发</strong></p>
<p>元数据区不足时导致，一般不需要关注。日志中关键字是 <strong>Metadata GC Threshold</strong>。</p>
</li>
</ul>
<h4 id="参数设置"><a class="header" href="#参数设置">参数设置</a></h4>
<p>ZGC优势不仅在于其超低的STW停顿，也在于其参数的简单，绝大部分生产场景都可以自适应。当然，极端情况下，还是有可能需要对ZGC个别参数做个调整，大致可以分为三类：</p>
<ul>
<li>
<p><strong>堆大小</strong></p>
<p>Xms。当分配速率过高，超过回收速率，造成堆内存不够时，会触发<strong>Allocation Stall</strong>，这类 Stall 会减缓当前的用户线程。因此，当我们在GC日志中看到 <strong>Allocation Stall</strong>，通常可以认为堆空间偏下或者 concurrent gc threads 数偏小。</p>
</li>
<li>
<p><strong>GC 触发时机</strong></p>
<p>ZAllocationSpikeTolerance，ZCollectionInterval。</p>
<p>ZAllocationSpikeTolerance 用来估算当前的堆内存分配速率，在当前剩余的堆内存下，ZAllocationSpikeTolerance 越大，估算的达到OOM的时间越快，ZGC就会更早地进行触发GC。ZCollectionInterval 用来指定GC发生的间隔，以秒为单位触发 GC。</p>
</li>
<li>
<p><strong>GC线程</strong></p>
<p>ParallelGCThreads，ConcGCThreads。ParallelGCThreads是设置STW任务的GC线程数目，默认为CPU个数的60%。</p>
<p>ConcGCThreads 是并发阶段GC线程的数目，默认为CPU个数的12.5%。增加GC线程数目，可以加快GC完成任务，减少各个阶段的时间，但也会增加CPU的抢占开销，可根据生产情况调整。</p>
</li>
</ul>
<h3 id="如何选择垃圾回收器"><a class="header" href="#如何选择垃圾回收器">如何选择垃圾回收器</a></h3>
<ul>
<li>
<p>单CPU或小内存，单机程序</p>
<blockquote>
<p>-XX:+UseSerialGC</p>
</blockquote>
</li>
<li>
<p>多CPU，需要最大吞吐量，如后台计算型应用</p>
<blockquote>
<p>-XX:+UseParallelGC或者</p>
<p>-XX:+UseParallelOldGC</p>
</blockquote>
</li>
<li>
<p>多CPU，追求低停顿时间，需快速响应如互联网应用</p>
<blockquote>
<p>-XX:+UseConcMarkSweepGC</p>
<p>-XX:+ParNewGC</p>
</blockquote>
</li>
</ul>
<h1 id="-3"><a class="header" href="#-3"></a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="java-中线程的状态"><a class="header" href="#java-中线程的状态">Java 中线程的状态</a></h1>
<p>5 种状态一般是针对传统的线程状态来说（操作系统层面）</p>
<p><img src="https://raw.githubusercontent.com/chou401/pic-md/master/image-20230823173134948.png" alt="image-20230823173134948" /></p>
<p>Java 中给线程准备了 6 种状态</p>
<p><img src="https://raw.githubusercontent.com/chou401/pic-md/master/image-20230823173427644.png" alt="image-20230823173427644" /></p>
<p><img src="https://raw.githubusercontent.com/chou401/pic-md/master/image-20230823173819528.png" alt="image-20230823173819528" /></p>
<p>NEW：Thread 对象被创建出来，但是还没有执行 start 方法</p>
<p>RUNNABLE：Thread 对象调用了 start 方法，就为 RUNNABLE 状态（CPU 调度/没有调度）</p>
<p>BLOCKED：synchronized 没有拿到同步锁，被阻塞的情况</p>
<p>WAITING：调用 wait 方法就会处于 WAITING 状态，需要被手动唤醒</p>
<p>TIMED_WAITING：调用 sleep 方法或者 join 方法，会被自动唤醒，无需手动唤醒</p>
<p>TERMINATED：run 方法执行完毕，线程生命周期到头了</p>
<blockquote>
<p><strong>1）新建状态（NEW）</strong>: 当我们创建一个新的Thread对象时，该线程就处于新建状态，例如：Thread t = new Thread();</p>
<p><strong>2）可运行状态（RUNNABLE）</strong>: 当线程对象调用start()方法后，线程进入可运行状态。在这个状态下，线程已经做好了准备，随时等待CPU调度执行，这个状态包括了&quot;就绪&quot;和&quot;运行&quot;状态。</p>
<p><strong>3）阻塞状态（BLOCKED）</strong>: 线程在等待获取一个锁以进入或重新进入同步代码块时，它会进入阻塞状态。只有当该锁被释放并且线程被调度去获取这个锁，线程才能转换到RUNNABLE状态。</p>
<p><strong>4）等待状态（WAITING）</strong>: 线程进入等待状态，是因为它调用了其它线程的join方法，或者调用了无参数的wait方法。在这种情况下，线程会等待另一个线程的操作完成或者等待notify/notifyAll消息。</p>
<p><strong>5）定时等待状态（TIMED_WAITING</strong>）: 线程进入定时等待状态，是因为它调用了sleep或者带有指定时间的wait或join方法。在指定的时间过去之后，线程会自动返回RUNNABLE状态。如果它是由于调用wait或join方法进入的定时等待状态，还需要等待notify/notifyAll消息或者等待join的线程终止。</p>
<p><strong>6）终止状态（TERMINATED）</strong>: 线程任务执行完毕或者由于异常而结束，线程就会进入终止状态。在这个状态下，线程的生命周期实际上已经结束了，它不能再转换到其他任何状态。</p>
</blockquote>
<p>BLOCKED、WAITING、TIMED_WAITING：都可以理解为阻塞、等待状态，因为处在这三种状态下，CPU 不会调度当前线程</p>
<pre><code class="language-java">NEW:
Thread thread = new Thread(()-&gt;{

});
System.out.println(thread.getState());

RUNNABLE:
Thread thread = new Thread(()-&gt;{
    while (true) {

    }
});
thread.start();
System.out.println(thread.getState());

BLOCKED:
Object object = new Object();
Thread thread = new Thread(()-&gt;{
    synchronized (object) {

    }
});
synchronized (object) {
    thread.start();
    Thread.sleep(500);
    System.out.println(thread.getState());
}

WAITING:
Object object = new Object();
Thread thread = new Thread(() -&gt; {
    synchronized (object) {
        try {
            object.wait();
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
    }
});
thread.start();
Thread.sleep(500);
System.out.println(thread.getState());

TIMED_WAITING:
Thread thread = new Thread(() -&gt; {
    try {
        Thread.sleep(1000);
    } catch (InterruptedException e) {
        e.printStackTrace();
    }
});
thread.start();
Thread.sleep(500);
System.out.println(thread.getState());

TERMINATED:
Thread thread = new Thread(() -&gt; {
    try {
        Thread.sleep(500);
    } catch (InterruptedException e) {
        e.printStackTrace();
    }
});
thread.start();
Thread.sleep(1000);
System.out.println(thread.getState());
</code></pre>
<h1 id="java-中如何停止线程"><a class="header" href="#java-中如何停止线程">Java 中如何停止线程</a></h1>
<p>Java中有以下三种方法可以终止正在运行的线程：</p>
<ol>
<li>使用退出标志，使线程正常退出，也就是当 run() 方法完成后线程中止。这种方法需要在循环中检查标志位是否为 true，如果为 false，则跳出循环，结束线程。</li>
<li>使用 stop() 方法强行终止线程，但是不推荐使用这个方法，该方法已被弃用。这个方法会导致一些清理性的工作得不到完成，如文件，数据库等的关闭，以及数据不一致的问题。</li>
<li>使用 interrupt() 方法中断线程。这个方法会在当前线程中打一个停止的标记，并不是真的停止线程。因此需要在线程中判断是否被中断，并增加相应的中断处理代码。如果线程在 sleep() 或 wait() 等操作时被中断，会抛出 InterruptedException 异常。</li>
</ol>
<p><strong>使用标记位中止线程</strong></p>
<p>使用退出标志，使线程正常退出，也就是当 run() 方法完成后线程中止，是一种比较简单而安全的方法。这种方法需要在循环中检查标志位是否为 true，如果为 false，则跳出循环，结束线程。这样可以保证线程的资源正确释放，不会导致数据不一致或其他异常问题。</p>
<p>例如，下面的代码展示了一个使用退出标志的线程类：</p>
<pre><code class="language-java">public class ServerThread extends Thread {
    //volatile修饰符用来保证其它线程读取的总是该变量的最新的值
    public volatile boolean exit = false;
    @Override
    public void run() {
        ServerSocket serverSocket = new ServerSocket(8080);
        while (!exit) {
            serverSocket.accept(); //阻塞等待客户端消息
            //do something
        }
    }
}
</code></pre>
<p>在主方法中，可以通过修改标志位来控制线程的退出:</p>
<pre><code class="language-java">public static void main(String[] args) {
    ServerThread t = new ServerThread();
    t.start();
    //do something else
    t.exit = true; //修改标志位，退出线程
}
</code></pre>
<p>这种方法的优点是简单易懂，缺点是需要在循环中不断检查标志位，可能会影响性能。另外，如果线程在 sleep() 或 wait() 等操作时被设置为退出标志，它也不会立即响应，而是要等到阻塞状态结束后才能检查标志位并退出。</p>
<p><strong>使用 stop() 方法强行终止线程</strong></p>
<p>使用 stop() 方法强行终止线程，是一种不推荐使用的方法，因为它会导致一些严重的问题。stop() 方法会立即终止线程，不管它是否在执行一些重要的操作，如关闭文件，释放锁，更新数据库等。这样会导致资源泄露，数据不一致，或者其他异常错误。</p>
<p>stop() 方法会立即释放该线程所持有的所有的锁，导致数据得不到同步，出现数据不一致的问题。例如，如果一个线程在修改一个对象的两个属性时被 stop() 了，那么可能只修改了一个属性，而另一个属性还是原来的值。这样就造成了对象的状态不一致。</p>
<p>例如，下面的代码展示了一个使用 stop() 方法的线程类:</p>
<pre><code class="language-java">public class MyThread extends Thread {
    @Override
    public void run() {
        try {
            FileWriter fw = new FileWriter(&quot;test.txt&quot;);
            fw.write(&quot;Hello, world!&quot;);
            Thread.sleep(1000); //模拟耗时操作
            fw.close(); //关闭文件
        } catch (Exception e) {
            e.printStackTrace();
        }
    }
}
</code></pre>
<p>在主方法中，可以通过调用 stop() 方法来强行终止线程：</p>
<pre><code class="language-java">public static void main(String[] args) {
    MyThread t = new MyThread();
    t.start();
    //do something else
    t.stop(); //强行终止线程
}
</code></pre>
<p>这种方法的缺点是很明显的，如果在关闭文件之前调用了 stop() 方法，那么文件就不会被正确关闭，可能会造成数据丢失或损坏。而且，stop() 方法会抛出 ThreadDeath 异常，如果没有捕获处理这个异常，那么它会向上层传递，可能会影响其他线程或程序的正常运行 。因此，使用 stop() 方法强行终止线程是一种<strong>非常危险而不负责任</strong>的做法，应该尽量避免使用。</p>
<p><strong>使用interrupt() 方法中断线程</strong></p>
<p><code>Thread.interrupt()</code>它能帮助我们在一个线程中断另一个线程。尽管它被命名为“interrupt”，但实际上它并不会立即停止一个线程的执行，而是设置一个中断标志，表示这个线程已经被中断。它的具体行为取决于被中断线程当前的状态以及如何响应中断。</p>
<p><code>interrupt</code>是<code>Thread</code>对象一个内部字段，用来表示它的中断状态。这个字段是由Java虚拟机（JVM）管理的，对应用程序代码是不可见的。</p>
<p>以下是有关<code>Thread.interrupt()</code>的一些重要事项：</p>
<ol>
<li><strong>对于非阻塞状态的线程</strong>：如果线程处于运行状态，并且没有执行任何阻塞操作，那么调用<code>interrupt()</code>方法只会设置线程的中断状态，并不会影响线程的继续执行。线程需要自己检查这个中断状态，并决定是否停止执行。常见的检查方式包括调用<code>Thread.interrupted()</code>（这会清除中断状态）或者<code>Thread.currentThread().isInterrupted()</code>（不会清除中断状态）。</li>
<li><strong>对于阻塞状态的线程</strong>：如果线程处于阻塞状态，如调用了<code>Object.wait()</code>, <code>Thread.join()</code>或者<code>Thread.sleep()</code>方法，那么线程会立即抛出<code>InterruptedException</code>，并且清除中断状态。</li>
<li><strong>对于已经停止的线程</strong>：如果线程已经停止，那么调用<code>interrupt()</code>方法不会有任何影响。</li>
</ol>
<p><code>interrupt()</code>方法为我们提供了一种通用的、协作式的线程停止机制。它允许被中断的线程决定如何处理中断请求，可以立即停止，也可以忽略中断，或者继续执行一段时间然后再停止。</p>
<p>以下是一个使用<code>interrupt()</code>方法的例子：</p>
<pre><code class="language-java">Thread t = new Thread(() -&gt; {
    while (!Thread.currentThread().isInterrupted()) {
        // 执行任务
    }
});

t.start();

// 在另一个线程中中断t线程
t.interrupt();
</code></pre>
<p>这个例子中，线程<code>t</code>会一直执行，直到它的中断状态被设置。这是通过检查<code>Thread.currentThread().isInterrupted()</code>实现的。当<code>t.interrupt()</code>被调用时，线程<code>t</code>的中断状态被设置，因此线程将退出循环并结束执行。</p>
<p>需要注意的是，如果线程在响应中断时需要执行一些清理工作，或者需要抛出一个异常来通知上游代码，那么就需要在捕获<code>InterruptedException</code>后，手动再次设置中断标志。这是因为当<code>InterruptedException</code>被抛出时，中断状态会被清除。例如：</p>
<pre><code class="language-java">while (!Thread.currentThread().isInterrupted()) {
    try {
        // 执行可能抛出InterruptedException的任务
        Thread.sleep(1000);
    } catch (InterruptedException e) {
        // 捕获InterruptedException后，再次设置中断标志
        Thread.currentThread().interrupt();
    }
}
</code></pre>
<h1 id="java-中-wait-和-sleep-方法的区别"><a class="header" href="#java-中-wait-和-sleep-方法的区别">Java 中 wait 和 sleep 方法的区别</a></h1>
<p>sleep 方法和 wait 方法都是用来将线程进入休眠状态的，并且 sleep 和 wait 方法都可以响应 interrupt 中断，也就是线程在休眠的过程中，如果收到中断信号，都可以进行响应并中断，且都可以抛出 InterruptedException 异常，那 sleep 和 wait 有什么区别呢？接下来，我们一起来看。</p>
<p><strong>区别一：语法使用不同</strong></p>
<p>wait 方法必须配合<code>synchronized </code>一起使用，不然在运行时就会抛出 IllegalMonitorStateException 的异常。wait 方法会将持有锁的线程从owner 扔到 WaitSet 集合中，这个操作是在修改 ObjectMonitor 对象，如果没有持有 synchronized 锁的话，是无法操作 ObjectMonitor 对象的。</p>
<p>而 sleep 可以单独使用，无需配合 synchronized 一起使用。</p>
<p><strong>区别二：所属类不同</strong></p>
<p>wait 方法属于 Object 类的方法，而 sleep 属于 Thread 类的方法</p>
<p><strong>区别三：唤醒方式不同</strong></p>
<p>sleep 方法必须要传递一个超时时间的参数，且过了超时时间之后，线程会自动唤醒。而 wait 方法可以不传递任何参数，不传递任何参数时表示永久休眠，直到另一个线程调用了 notify 或 notifyAll 之后，休眠的线程才能被唤醒。也就是说 <strong>sleep 方法具有主动唤醒功能，而不传递任何参数的 wait 方法只能被动的被唤醒</strong>。</p>
<p><strong>区别四：释放锁资源不同</strong></p>
<p><strong>wait 方法会主动的释放锁，而 sleep 方法则不会</strong>。</p>
<p><strong>区别五：线程进入状态不同</strong></p>
<p>调用 sleep 方法线程会进入 TIMED_WAITING 有时限等待状态，而调用无参数的 wait 方法，线程会进入 WAITING 无时限等待状态**。** </p>
<p>sleep 和 wait 都可以让线程进入休眠状态，并且它们都可以响应 interrupt 中断，但二者的区别主要体现在：语法使用不同、所属类不同、唤醒方式不同、释放锁不同和线程进入的状态不同。</p>
<h1 id="并发编程的三大特性"><a class="header" href="#并发编程的三大特性">并发编程的三大特性</a></h1>
<p><strong>原子性</strong></p>
<p>JMM（Java Memory Model）。不同的硬件和不同的操作系统在内存上的操作有一定差异的，Java 为了解决相同代码在不同操作系统上出现的各种问题，用 JMM 屏蔽掉各种硬件和操作系统带来的差异。让 Java 的并发编程可以做到跨平台。</p>
<p>JMM 规定所有变量都会存储在主内存中，在操作的时候，需要从主内存中复制一份到线程内存（CPU 内存），在线程内部做计算，<strong>然后再写回主内存中（不一定)。</strong></p>
<p>原子性的定义：原子性指一个操作是不可分割的，不可中断的，一个线程在执行时，另一个线程不会影响到他。</p>
<p>保证并发编程的原子性</p>
<ul>
<li>
<p>synchronized</p>
<p>可以在方法上追加 synchronized 关键字或采用同步代码块的形式保证原子性。synchronized 可以让多线程同时操作临界资源，同一个时间点，只会有一个线程操作临界资源。</p>
</li>
<li>
<p>cas</p>
<p>compare and swap 也就是比较和交换，它是一条 CPU 的并发原语。它在替换内存中某个位置的值时，首先查看内存中的值与预期的值是否一致，如果一致，执行替换操作。这个操作是一个原子性操作。Java 中基于Unsafe 的类提供了对 cas 操作的方法，jvm 会帮我们将方法实现 cas 汇编指令。但是要清楚，cas 只是比较和交换，在获取原值的这个操作上，需要自己实现。</p>
</li>
<li>
<p>lock</p>
<p>lock 锁是JDK1.5 由Doug lea 研发的，它的性能相比 synchronized 在JDK1.5 的时期，性能好了很多，但是在 JDK1.6 优化之后，性能相差不大，但是如果设置并发比较多时，推荐 ReentrantLock 锁，性能会更好。</p>
</li>
<li>
<p>ThreadLocal</p>
<p>ThreadLocal 保证原子性的操作，是不让多线程去操作临界资源，让每个线程去操作属于自己的数据。</p>
</li>
</ul>
<p><strong>可见性</strong></p>
<p>可见性问题是基于 CPU 位置出现的，CPU 处理速度非常快，相对 CPU 来说，去主内存获取数据这个事情太慢了，CPU 就提供了 L1、L2、L3 的三级缓存，每次去主内存拿完数据后，就会存储到 CPU 的三级缓存，每次去三级缓存中取数据，效率肯定会提升。</p>
<p>这就带来了问题，现在 CPU 都是多核的，每个线程的工作内存（CPU 三级缓存）都是独立的，会告知每个线程中修改时，只该自己的工作内存，没有及时的同步到主内存中，导致数据不一致问题。</p>
<p>解决可见性的方式</p>
<ul>
<li>
<p>volatile</p>
<p>volatile 是个关键字，用来修饰成员变量。如果属性被 volatile 修饰，相当于会告诉 CPU，对当前属性的操作，不使用 CPU 三级缓存，必须去和主内存进行操作。</p>
<p>volatile 的内存语义</p>
<ul>
<li>volatile 属性被写：当写一个 volatile 变量，JMM 会将当前线程对应的CPU 缓存及时的刷新到主内存中。</li>
<li>volatile 属性被读：当读一个 volatile 变量，JMM 会将对应的 CPU 缓存中的内存设置为无效，必须去主内存中读取共享变量。</li>
</ul>
<p>其实加了 volatile 就是告知CPU，对当前属性的读写操作，不使用 CPU 缓存，加了 volatile 修饰的属性，会在转为汇编之后，追加一个 lock 的前缀，CPU 执行这个指令时，如果带有 lock 前缀会做两个事情：</p>
<ul>
<li>将当前处理器缓存行的数据写回到主内存</li>
<li>这个写回的过程，在其他CPU 内核的缓存中，直接无效</li>
</ul>
</li>
<li>
<p>synchronized</p>
<p>synchronized 也是可以解决可见性问题的，synchronized 的内存语义。</p>
<p>如果涉及到了 synchronized 的同步代码块或者同步方法，获取锁资源之后，将内存获取的变量在 CPU 缓存中删除，必须去主内存中重新拿数据，而且在释放锁之后，会立即将 CPU 缓存中的数据同步到主内存中。</p>
</li>
<li>
<p>lock</p>
<p>lock 锁保证可见性的方式和 synchronized 完全不同，synchronized 基于它的内存语义，在获取锁和释放锁的时候，对 CPU 缓存做同步到主内存的操作。</p>
<p>lock 锁是基于 volatile 实现的，lock 锁内部在进行加锁和释放锁的时候，会对一个 volatile 修饰的 state 属性进行加减操作。</p>
<p>如果对 volatile 修饰的属性进行写操作，CPU 会执行带有 lock 前缀的指令，CPU 会将修改的数据，从 CPU 缓存立即同步到主内存中，同时也会将其他属性立即同步到主内存中，还会将其他 CPU 缓存行中的这个数据设置为无效，必须从主内存中拉取。</p>
</li>
<li>
<p>final</p>
<p>final 修饰的属性，在运行期间是不允许被修改的，这样一来就间接性的保证了可见性，所有多线程读取 final 属性，值肯定是一样的。</p>
<p>final 并不是说每次取数据从主内存读取，他没有这个必要，而且 final 和 volatile 不可以同时修饰一个属性。</p>
<p>final 修饰的属性已经不允许再次被写了，而 volatile 是保证每次读写操作去内存中读取，并且 volatile 会影响一定的性能，就不需要同时修饰。</p>
</li>
</ul>
<p><strong>有序性</strong></p>
<p>所谓有序性是指程序代码在执行过程中先后顺序，由于 Java 在编译器以及运行期的优化，导致了代码的执行顺序未必就是开发者编写代码的顺序，比如</p>
<pre><code class="language-java">int x = 10;
int y = 0;
x++;
y = 20
</code></pre>
<p>上面这段代码定义了两个 int 类型的变量 x 和 y，对 x 进行自增操作，对 y 进行赋值操作，从编写程序的角度看上面代码肯定是顺序执行下去的，但是 JVM 真正地运行这段代码的时候未必会是这样的顺序，比如  y = 20 语句有可能会在 x++ 语句的前面执行，这种情况就是通常所说的指令重排。</p>
<p>一般来说，处理器为了提高程序的运行效率，可能会对输入的代码指令做一定的优化，它不会百分百的保证代码的执行顺序严格按照编写代码中的顺序进行，但是它会保证程序的最终运算结果是编码时所期望的那样，比如上文中的 x++ 和 y = 20，不管它们的执行顺序如何，执行完上面四行代码之后得到的结果肯定都是 x =11,y = 20。</p>
<p>当然对指令的重排序要严格遵守指令之间的数据依赖关系，并不是可以任意进行重排序的，比如下面的代码片段。</p>
<pre><code class="language-java">int x = 10;
int y = 0;
x++;
y=x+1;
</code></pre>
<p>对于这段代码有可能它的执行顺序就是代码本身的顺序，有可能发生了重排序导致 int y=0 优于 int x =10 执行，但是绝对不能出现 y= x+1 优于 x++ 执行的执行情况，如果一个指令 x 在执行的过程中需要用到指令 y 的执行结果，那么处理器会保证指令 y 在指令 x 之前执行，这就好比 y = x+1 执行前肯定要先执行 x++ 一样。</p>
<p>在单线程情况下，无论怎样的重排序最终都会保证程序的执行结果和代码顺序执行结果完全一致的，但是在多线程情况下，如果有序性得不到保证，那么很有可能就会出现非常大的问题，比如下面的代码片段</p>
<pre><code class="language-java">private boolean initialized = false;
private Context context;
public Context load(){
    if（!initialized）{
        context = loadContext();
        initialized = true;
    }
    return context;
}
</code></pre>
<p>上面代码使用 boolean 变量 initialized 来控制 context 是否已经被加载过，在单线程下，无论怎样的重排序，最终返回给使用者的 context 都是可用的。如果在多线程的情况下发生了重排序，比如 context = loadContext 的执行顺序被重排序到 initialized = true; 的后面，那么这就是灾难性的。比如第一个线程首先判断 initialized = false，然后准备执行 loadContext 方法，但由于重排序，将 initialized 设置为 true，此时如果另外一个线程也执行 load 方法，发现此时 initialized 已经为 true 了,则返回一个还未被加载的 context，那么在程序的运行过程中势必会出现错误。</p>
<p>在 Java 中，.java 文件的内容会被编译，在执行前需要再次转为 CPU 可以识别的指令，CPU 在执行这些指令时，为了提升执行效率，在不影响最终结果的前提下（满足一些需求），会对指令进行重排。</p>
<p>指令乱序执行的原因，是为了尽可能的发挥 CPU 的性能。</p>
<p>Java 中的程序是乱序执行的。</p>
<p>保证有序性的方式</p>
<ul>
<li>
<p>as-if-serial</p>
</li>
<li>
<p>happens-before</p>
<p>具体规则</p>
<ol>
<li>单线程 happen-before 原则：在同一个线程中，书写在前面的操作 happen-before 后面的操作。</li>
<li>锁的 happen-before 原则：同一个所得 unlock 操作 happen-before 此锁的 lock 操作。</li>
<li>volatile 的 happens-before 原则：对一个 volatile 变量的写操作 happen-before 对此变量的任何操作。</li>
<li>happen-before 的传递性原则：如果 A 操作 happen-before B 操作，B 操作 happen-before C 操作，那么 A 操作 happen-before C 操作。</li>
<li>线程启动的 happen-before 原则：同一个线程的 start 操作 happen-before 此线程的其他方法。</li>
<li>线程中断的 happen-before 原则：对线程 interrupt 方法的调用 happen-before 被中断线程的检测到中断发送的代码。</li>
<li>线程终结的 happen-before 原则：线程中所有的操作都 happen-before 线程的终止检测。</li>
<li>对象创建的 happen-before 原则：一个对象的初始化完成先于他的finalize 方法调用。</li>
</ol>
<p>JMM 只有在不出现上述 8 中情况时，才不会触发指令重排效果。</p>
<p>不需要过分的关注 happen-before 原则，只需要可以写出线程安全的代码就可以了。</p>
</li>
<li>
<p>volatile</p>
<p>如果需要让程序对某一个属性的操作不出现指令重排，除了满足 happens-before 的原则外，还可以基于 volatile 修饰属性，从而对这个属性的操作，就不会出现指令重排的问题了。</p>
<p>volatile 如何实现的禁止指令重排？</p>
<p>内存屏障概念，将内存屏障看成一个指令。</p>
<p>会在两个操作之间，添加上一道指令，这个指令就可以避免上下执行的其他指令进行重排。</p>
</li>
</ul>
<h1 id="什么是-cas有什么优缺点"><a class="header" href="#什么是-cas有什么优缺点">什么是 CAS？有什么优缺点</a></h1>
<p>在高并发的业务场景下，线程安全问题是必须考虑的，在JDK5之前，可以通过synchronized或Lock来保证同步，从而达到线程安全的目的。但synchronized或Lock方案属于互斥锁的方案，比较重量级，加锁、释放锁都会引起性能损耗问题。</p>
<p>而在某些场景下，我们是可以通过JUC提供的CAS机制实现无锁的解决方案，或者说是它基于类似于乐观锁的方案，来达到非阻塞同步的方式保证线程安全。</p>
<p><strong>什么是 CAS</strong></p>
<p><code>CAS</code>是<code>Compare And Swap</code>的缩写，直译就是<strong>比较并交换</strong>。CAS是现代CPU广泛支持的一种对内存中的共享数据进行操作的一种特殊指令，这个指令会对内存中的共享数据做原子的读写操作。其作用是让CPU比较内存中某个值是否和预期的值相同，如果相同则将这个值更新为新值，不相同则不做更新。</p>
<p>本质上来讲CAS是一种无锁的解决方案，也是一种基于乐观锁的操作，可以保证在多线程并发中保障共享资源的原子性操作，相对于synchronized或Lock来说，是一种轻量级的实现方案。</p>
<p>Java中大量使用了CAS机制来实现多线程下数据更新的原子化操作，比如AtomicInteger、CurrentHashMap当中都有CAS的应用。但Java中并没有直接实现CAS，CAS相关的实现是借助<code>C/C++</code>调用CPU指令来实现的，效率很高，但Java代码需通过JNI才能调用。比如，Unsafe类提供的CAS方法（如compareAndSwapXXX）底层实现即为CPU指令cmpxchg。</p>
<p><strong>CAS 的基本流程</strong></p>
<p><img src="https://raw.githubusercontent.com/chou401/pic-md/master/image-20230825103445318.png" alt="image-20230825103445318" /></p>
<p>在上图中涉及到三个值的比较和操作：修改之前获取的（待修改）值A，业务逻辑计算的新值B，以及待修改值对应的内存位置的C。</p>
<p>整个处理流程中，假设内存中存在一个变量i，它在内存中对应的值是A（第一次读取），此时经过业务处理之后，要把它更新成B，那么在更新之前会再读取一下i现在的值C，如果在业务处理的过程中i的值并没有发生变化，也就是A和C相同，才会把i更新（交换）为新值B。如果A和C不相同，那说明在业务计算时，i的值发生了变化，则不更新（交换）成B。最后，CPU会将旧的数值返回。而上述的一系列操作由CPU指令来保证是原子的。</p>
<p>在《Java并发编程实践》中对CAS进行了更加通俗的描述：我认为原有的值应该是什么，如果是，则将原有的值更新为新值，否则不做修改，并告诉我原来的值是多少。</p>
<p>在上述路程中，我们可以很清晰的看到乐观锁的思路，而且这期间并没有使用到锁。因此，相对于synchronized等悲观锁的实现，效率要高非常多。</p>
<p><strong>基于 CAS 的 AtomicInteger 使用</strong></p>
<p>关于CAS的实现，最经典最常用的当属AtomicInteger了，我们马上就来看一下AtomicInteger是如何利用CAS实现原子性操作的。为了形成更新鲜明的对比，先来看一下如果不使用CAS机制，想实现线程安全我们通常如何处理。</p>
<p>在没有使用CAS机制时，为了保证线程安全，基于synchronized的实现如下：</p>
<pre><code class="language-java">public class ThreadSafeTest {

 public static volatile int i = 0;

 public synchronized void increase() {
  i++;
 }
}
</code></pre>
<p>至于上面的实例具体实现，这里不再展开，很多相关的文章专门进行讲解，我们只需要知道为了保证i++的原子操作，在increase方法上使用了重量级的锁synchronized，这会导致该方法的性能低下，所有调用该方法的操作都需要同步等待处理。</p>
<p>那么，如果采用基于CAS实现的AtomicInteger类，上述方法的实现便变得简单且轻量级了：</p>
<pre><code class="language-java">public class ThreadSafeTest {

 private final AtomicInteger counter = new AtomicInteger(0);

 public int increase(){
  return counter.addAndGet(1);
 }
}
</code></pre>
<p>之所以可以如此安全、便捷地来实现安全操作，便是由于AtomicInteger类采用了CAS机制。下面，我们就来了解一下AtomicInteger的功能及源码实现。</p>
<p><strong>CAS 的 AtomicInteger 类</strong></p>
<p><code>AtomicInteger</code>是java.util.concurrent.atomic 包下的一个原子类，该包下还有<code>AtomicBoolean</code>, <code>AtomicLong</code>,<code>AtomicLongArray</code>, <code>AtomicReference</code>等原子类，主要用于在高并发环境下，保证线程安全。</p>
<p><strong>AtomicInteger常用API</strong></p>
<pre><code class="language-java">public final int get()：获取当前的值
public final int getAndSet(int newValue)：获取当前的值，并设置新的值
public final int getAndIncrement()：获取当前的值，并自增
public final int getAndDecrement()：获取当前的值，并自减
public final int getAndAdd(int delta)：获取当前的值，并加上预期的值
void lazySet(int newValue): 最终会设置成newValue,使用lazySet设置值后，可能导致其他线程在之后的一小段时间内还是可以读到旧的值。
</code></pre>
<p>上述方法中，getAndXXX格式的方法都实现了原子操作。具体的使用方法参考上面的addAndGet案例即可。</p>
<p><strong>AtomicInteger 核心源码</strong></p>
<pre><code class="language-java">public class AtomicInteger extends Number implements java.io.Serializable {
    private static final Unsafe unsafe = Unsafe.getUnsafe();
    private static final long valueOffset;
    static {
        try {
            // 用于获取value字段相对当前对象的“起始地址”的偏移量
            valueOffset = unsafe.objectFieldOffset(AtomicInteger.class.getDeclaredField(&quot;value&quot;));
        } catch (Exception ex) { throw new Error(ex); }
    }

    private volatile int value;

    //返回当前值
    public final int get() {
        return value;
    }

    //递增加detla
    public final int getAndAdd(int delta) {
        // 1、this：当前的实例 
        // 2、valueOffset：value实例变量的偏移量 
        // 3、delta：当前value要加上的数(value+delta)。
        return unsafe.getAndAddInt(this, valueOffset, delta);
    }

    //递增加1
    public final int incrementAndGet() {
        return unsafe.getAndAddInt(this, valueOffset, 1) + 1;
    }
...
}
</code></pre>
<p>上述代码以AtomicInteger#incrementAndGet方法为例展示了AtomicInteger的基本实现。其中，在static静态代码块中，基于Unsafe类获取value字段相对当前对象的“起始地址”的偏移量，用于后续Unsafe类的处理。</p>
<p>在处理自增的原子操作时，使用的是Unsafe类中的getAndAddInt方法，CAS的实现便是由Unsafe类的该方法提供，从而保证自增操作的原子性。</p>
<p>同时，在AtomicInteger类中，可以看到value值通过volatile进行修饰，保证了该属性值的线程可见性。在多并发的情况下，一个线程的修改，可以保证到其他线程立马看到修改后的值。</p>
<p>通过源码可以看出， <code>AtomicInteger</code> 底层是通过<strong>volatile</strong>变量和CAS两者相结合来保证更新数据的原子性。其中关于Unsafe类对CAS的实现，我们下面详细介绍。</p>
<p><strong>CAS 的工作原理</strong></p>
<p>CAS的实现原理简单来说就是由<strong>Unsafe类</strong>和其中的<strong>自旋锁</strong>来完成的，下面针对源代码来看一下这两块的内容。</p>
<p><strong>Unsafe 类</strong></p>
<p>在AtomicInteger核心源码中，已经看到CAS的实现是通过Unsafe类来完成的，先来了解一下Unsafe类的作用。</p>
<p>sun.misc.Unsafe是JDK内部用的工具类。它通过暴露一些Java意义上说“不安全”的功能给Java层代码，来让JDK能够更多的使用Java代码来实现一些原本是平台相关的、需要使用native语言（例如C或C++）才可以实现的功能。该类不应该在JDK核心类库之外使用，这也是命名为Unsafe（不安全）的原因。</p>
<p>JVM的实现可以自由选择如何实现Java对象的“布局”，也就是在内存里Java对象的各个部分放在哪里，包括对象的实例字段和一些元数据之类。</p>
<p>Unsafe里关于对象字段访问的方法把对象布局抽象出来，它提供了objectFieldOffset()方法用于获取某个字段相对Java对象的“起始地址”的偏移量，也提供了getInt、getLong、getObject之类的方法可以使用前面获取的偏移量来访问某个Java对象的某个字段。在AtomicInteger的static代码块中便使用了objectFieldOffset()方法。</p>
<p>Unsafe类的功能主要分为内存操作、CAS、Class相关、对象操作、数组相关、内存屏障、系统相关、线程调度等功能。这里我们只需要知道其功能即可，方便理解CAS的实现，注意不建议在日常开发中使用。</p>
<p><strong>Unsafe 和 CAS</strong></p>
<p>AtomicInteger调用了Unsafe#getAndAddInt方法：</p>
<pre><code class="language-java">public final int incrementAndGet() {
    return unsafe.getAndAddInt(this, valueOffset, 1) + 1;
}
</code></pre>
<p>上述代码等于是AtomicInteger调用UnSafe类的CAS方法，JVM帮我们实现出汇编指令，从而实现原子操作。</p>
<p>在Unsafe中getAndAddInt方法实现如下：</p>
<pre><code class="language-java">public final int getAndAddInt(Object var1, long var2, int var4) {
    int var5;
    do {
        var5 = this.getIntVolatile(var1, var2);
    } while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4));
    return var5;
}
</code></pre>
<p>getAndAddInt方法有三个参数：</p>
<ul>
<li>第一个参数表示当前对象，也就是new的那个AtomicInteger对象；</li>
<li>第二个表示内存地址；</li>
<li>第三个表示自增步伐，在AtomicInteger#incrementAndGet中默认的自增步伐是1。</li>
</ul>
<p>getAndAddInt方法中，首先把当前对象主内存中的值赋给val5，然后进入while循环。判断当前对象此刻主内存中的值是否等于val5，如果是，就自增（交换值），否则继续循环，重新获取val5的值。</p>
<p>在上述逻辑中核心方法是compareAndSwapInt方法，它是一个native方法，这个方法汇编之后是CPU原语指令，原语指令是连续执行不会被打断的，所以可以保证原子性。</p>
<p>在getAndAddInt方法中还涉及到一个实现<strong>自旋锁</strong>。所谓的自旋，其实就是上面getAndAddInt方法中的do while循环操作。当预期值和主内存中的值不等时，就重新获取主内存中的值，这就是自旋。</p>
<p>这里我们可以看到CAS实现的一个缺点：内部使用<strong>自旋</strong>的方式进行<strong>CAS</strong>更新（while循环进行CAS更新，如果更新失败，则循环再次重试）。如果长时间都不成功的话，就会造成CPU极大的开销。</p>
<p>另外，Unsafe类还支持了其他的CAS方法，比如<code>compareAndSwapObject</code>、<code> compareAndSwapInt</code>、<code>compareAndSwapLong</code>。</p>
<p><strong>CAS 的缺点</strong></p>
<p><code>CAS</code>高效地实现了原子性操作，但在以下三方面还存在着一些缺点：</p>
<ul>
<li>循环时间长，开销大；</li>
<li>只能保证一个共享变量的原子操作；</li>
<li>ABA问题；</li>
</ul>
<p>下面就这个三个问题详细讨论一下。</p>
<p><strong>循环时间长开销大</strong></p>
<p>在分析Unsafe源代码的时候我们已经提到，在Unsafe的实现中使用了自旋锁的机制。在该环节如果<code>CAS</code>操作失败，就需要循环进行<code>CAS</code>操作(do while循环同时将期望值更新为最新的)，如果长时间都不成功的话，那么会造成CPU极大的开销。如果JVM能支持处理器提供的pause指令那么效率会有一定的提升。</p>
<p><strong>只能保证一个共享变量的原子操作</strong></p>
<p>在最初的实例中，可以看出是针对一个共享变量使用了CAS机制，可以保证原子性操作。但如果存在多个共享变量，或一整个代码块的逻辑需要保证线程安全，CAS就无法保证原子性操作了，此时就需要考虑采用加锁方式（悲观锁）保证原子性，或者有一个取巧的办法，把多个共享变量合并成一个共享变量进行<code>CAS</code>操作。</p>
<p><strong>ABA问题</strong></p>
<p>虽然使用CAS可以实现非阻塞式的原子性操作，但是会产生ABA问题，ABA问题出现的基本流程：</p>
<ul>
<li>进程P1在共享变量中读到值为A；</li>
<li>P1被抢占了，进程P2执行；</li>
<li>P2把共享变量里的值从A改成了B，再改回到A，此时被P1抢占；</li>
<li>P1回来看到共享变量里的值没有被改变，于是继续执行；</li>
</ul>
<p>虽然P1以为变量值没有改变，继续执行了，但是这个会引发一些潜在的问题。ABA问题最容易发生在lock free的算法中的，CAS首当其冲，因为CAS判断的是指针的地址。如果这个地址被重用了呢，问题就很大了（地址被重用是很经常发生的，一个内存分配后释放了，再分配，很有可能还是原来的地址）。</p>
<p>维基百科上给了一个形象的例子：你拿着一个装满钱的手提箱在飞机场，此时过来了一个火辣性感的美女，然后她很暖昧地挑逗着你，并趁你不注意，把用一个一模一样的手提箱和你那装满钱的箱子调了个包，然后就离开了，你看到你的手提箱还在那，于是就提着手提箱去赶飞机去了。</p>
<p>ABA问题的解决思路就是使用版本号：在变量前面追加上版本号，每次变量更新的时候把版本号加1，那么A-&gt;B-&gt;A就会变成1A-&gt;2B-&gt;3A。</p>
<p>另外，从Java 1.5开始，JDK的Atomic包里提供了一个类AtomicStampedReference来解决ABA问题。这个类的compareAndSet方法的作用是首先检查当前引用是否等于预期引用，并且检查当前标志是否等于预期标志，如果全部相等，则以原子方式将该引用和该标志的值设置为给定的更新值。</p>
<p><strong>@Contended 注解有什么用</strong></p>
<p>@Contended是<a href="https://so.csdn.net/so/search?q=Java&amp;spm=1001.2101.3001.7020">Java</a> 8中引入的一个注解，用于减少多线程环境下的“伪共享”现象，以提高程序的性能。</p>
<p>要理解@Contended的作用，首先要了解一下什么是伪共享（False Sharing）。</p>
<p><strong>什么是伪共享</strong></p>
<p>伪共享（False Sharing）是多线程环境中的一种现象，涉及到CPU的缓存机制和缓存行（Cache Line）。</p>
<p>现代CPU中，为了提高访问效率，通常会在CPU内部设计一种快速存储区域，称为缓存（Cache）。CPU在读写主内存中的数据时，会首先查看该数据是否已经在缓存中。如果在，就直接从缓存读取，避免了访问主内存的耗时；如果不在，则从主内存读取数据并放入缓存，以便下次访问。</p>
<p>缓存不是直接对单个字节进行操作的，而是以块（通常称为“缓存行”）为单位操作的。一个缓存行通常包含64字节的数据。</p>
<p>在多线程环境下，如果两个或更多的线程在同一时刻分别修改存储在同一缓存行的不同数据，那么CPU为了保证数据一致性，会使得其他线程必须等待一个线程修改完数据并写回主内存后，才能读取或者修改这个缓存行的数据。尽管这些线程可能实际上操作的是不同的变量，但由于它们位于同一缓存行，因此它们之间就会存在不必要的数据竞争，这就是伪共享。</p>
<p>伪共享会降低并发程序的性能，因为它会增加缓存的同步操作和主内存的访问。解决伪共享的一种方式是尽量让经常被并发访问的变量分布在不同的缓存行中，例如，可以通过增加无关的填充数据，或者利用诸如Java的@Contended注解等工具。</p>
<p>@Contended 是Java 8引入的一个注解，设计用于减少多线程环境下的伪共享（False Sharing）问题以提高程序性能。</p>
<p>伪共享是现代多核处理器中一个重要的性能瓶颈，它发生在多个处理器修改同一缓存行（Cache Line）中的不同数据时。缓存行是内存的基本单位，一般为64字节。当一个处理器读取主内存中的数据时，它会将整个缓存行（包含需要的数据）加载到本地缓存（L1，L2或L3缓存）中。如果另一个处理器修改了同一缓存行中的其他数据，那么原先加载到缓存中的数据就会变得无效，需要重新从主内存中加载。这会增加内存访问的延迟，降低程序性能。</p>
<p>@Contended注解可以标注在字段或者类上。它能使得被标注的字段在内存布局上尽可能地远离其他字段，使得被标注的字段或者类中的字段分布在不同的缓存行上，从而减少伪共享的发生。</p>
<pre><code class="language-java">public class Foo {
    @Contended
    long x;
    long y;
}
</code></pre>
<p>在这里，x被@Contended注解标记，所以x和y可能会被分布在不同的缓存行上，这样如果多个线程并发访问x和y，就不会引发伪共享。</p>
<p>需要注意的是，@Contended是JDK的内部API，它在Java 8中引入，但在默认情况下是不开放的，要使用需要添加JVM参数-XX:-RestrictContended，并且在编译时需要使用--add-exports java.base/jdk.internal.vm.annotation=ALL-UNNAMED。此外，过度使用@Contended可能会浪费内存，因为它会导致大量的内存空间被用作填充以保持字段间的距离。所以在使用时需要谨慎权衡内存和性能的考虑。</p>
<p><strong>简单案例</strong></p>
<p>在Java 8及以上版本中，@Contended注解是属于jdk的内部API，因此在正常情况下使用时需要打开开关-XX:-RestrictContended才能正常使用。同时需要注意的是，@Contended在JDK 9以后的版本中可能无法正常工作，因为JDK 9开始禁止使用Sun的内部API。</p>
<p>以下是一个@Contended注解的简单使用案例：</p>
<pre><code class="language-java">import jdk.internal.vm.annotation.Contended;
 
public class ContendedExample {
 
    @Contended
    volatile long value1 = 0L;
 
    @Contended
    volatile long value2 = 0L;
 
    public void increaseValue1() {
        value1++;
    }
 
    public void increaseValue2() {
        value2++;
    }
 
    public static void main(String[] args) {
        ContendedExample example = new ContendedExample();
 
        Thread thread1 = new Thread(() -&gt; {
            for (int i = 0; i &lt; 1000000; i++) {
                example.increaseValue1();
            }
        });
 
        Thread thread2 = new Thread(() -&gt; {
            for (int i = 0; i &lt; 1000000; i++) {
                example.increaseValue2();
            }
        });
 
        thread1.start();
        thread2.start();
 
        try {
            thread1.join();
            thread2.join();
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
 
        System.out.println(&quot;value1: &quot; + example.value1);
        System.out.println(&quot;value2: &quot; + example.value2);
    }
}
</code></pre>
<p>这个例子中定义了两个使用了@Contended注解的volatile长整型字段value1和value2。两个线程分别对这两个字段进行增加操作。因为这两个字段使用了@Contended注解，所以他们会被分布在不同的缓存行中，减少了因伪共享带来的性能问题。但由于伪共享的影响在实际运行中并不容易直接观察，所以这个例子主要展示了@Contended注解的使用方式，而不是实际效果。</p>
<p>@Contended 注解，就是将一个缓存行的后面 7 个位置，填充上 7 个没有意义的数据。</p>
<p><strong>Java 中的四种引用类型</strong></p>
<p>Java 中的引用类型分别为<strong>强、软、弱、虚</strong>。</p>
<p>在 Java 中最常见的就是强引用，把一个对系那个赋给一个引用变量，这个引用变量就是一个强引用。当一个对象被强引用变量引用时，它始终处于可达状态，它是不可能被垃圾回收机制回收的，即使该对象以后永远都不会被用到 JVM 也不会回收。因此强引用时造成 Java 内存泄漏的主要原因之一。例如：Object obj = new Object()。</p>
<p>其次是软引用，对于只有软引用的对象来说，当系统内存足够时它不会被回收，当系统内存空间不足时它会被回收。软引用通话吃那个用在对内存敏感的程序中，作为缓存使用。例如：SoftRefenence softRef = new SoftRefenence()。</p>
<p>然后是弱引用，它比较引用的生存期更短，对于只有弱引用的对象来说，只要垃圾回收机制已运行，不管 JVM 的内存空间是否足够，总会回收该对象占用的内存。可以解决内存泄漏的问题，ThreadLocal 就是基于弱引用解决内存泄漏的问题。例如：WeakRefenence weakRef = new WeakRefenence()。</p>
<p>最后是虚引用，它不能单独使用，必须和引用队列联合使用。虚引用的主要作用是跟踪对系那个被垃圾回收的状态。例如：ReferenceQueue queue = new ReferenceQueue()；PhantomReference phantomRef = new PhantomReference(obj,queue)，不过在开发中，我们用的更多的还是强引用。</p>
<h1 id="threadlocal-的内存泄漏问题"><a class="header" href="#threadlocal-的内存泄漏问题">ThreadLocal 的内存泄漏问题</a></h1>
<p><strong>ThreadLocal 实现原理：</strong></p>
<ul>
<li>每个 Thread 中都存储着一个成员变量，ThreadLocalMap</li>
<li>ThreadLocal 本身不存储数据，像是一个工具类，基于 ThreadLocal 去操作 ThreadLocalMap</li>
<li>ThreadLocalMap 本身就是基于 Entry[] 实现的，因为一个线程可以绑定多个 ThreadLocal，这样一来，可能需要存储多个数据，所以采用 Entry[] 的形式实现。</li>
<li>每个现有都自己独立的 ThreadLocalMap，再基于 ThreadLocal 对象本身作为 key，对 value 进行存取</li>
<li>ThreadLocalMap 的 key 是一个弱引用，弱引用的特点是，即便有若医用，再 GC 时，也必须被回收。这里是为了在 ThreadLocal 对象失去引用后，如果 key 的引用是强引用，会导致 ThreadLocal 对象无法被回收。</li>
</ul>
<p><strong>ThreadLocal 内存泄漏问题</strong></p>
<ul>
<li>如果 ThreadLocal 引用丢失，key 因为弱引用会被 GC 回收掉，如果同时线程还没有被回收，就会导致内存泄漏，内存中的 value 无法被回收，同时也无法被获取到。</li>
<li>只需要在使用完毕 ThreadLocal 对象之后，及时的调用 remove 方法，移除 Entry 即可。</li>
</ul>
<h1 id="java-中锁的分类"><a class="header" href="#java-中锁的分类">Java 中锁的分类</a></h1>
<ol>
<li>
<p><strong>可重入锁、不可重入锁</strong></p>
<p>Java 中提供的 synchronized，ReentrantLock，ReentrantReadWriteLock 都是可重入锁。</p>
<p><strong>重入</strong>：当前线程获取到 A 锁，在获取之后尝试再次获取 A 锁是可以直接拿到的</p>
<p><strong>不可重入</strong>：当前线程获取到 A 锁，在获取之后尝试再次获取 A 锁，无法获取到的，因为 A 锁被当前线程占用着，需要等待自己释放锁再获取锁。</p>
</li>
<li>
<p><strong>乐观锁、悲观锁</strong></p>
<p>Java 中提供的 synchronized，ReentrantLock，ReentrantReadWriteLock 都是悲观锁。</p>
<p>Java 中提供的 CAS 操作，就是乐观锁的一种实现。</p>
<p><strong>悲观锁</strong>：获取不到资源时，会将当前线程挂起（进入 BLOCKED、WAITING），线程挂起会涉及到用户态和内核态的切换，而这种切换是比较消耗资源的。</p>
<ul>
<li>用户态：JVM 可以自行执行的指令，不需要借助操作系统执行。</li>
<li>内核态：JVM 不可以自行执行，需要操作系统才可以执行。</li>
</ul>
<p><strong>乐观锁</strong>：获取不到资源，可以再次让 CPU 调度，重新尝试获取锁资源。</p>
<p>Atomic 原子性类中，就是基于 CAS 乐观锁实现的。</p>
</li>
<li>
<p><strong>公平锁、非公平锁</strong></p>
<p>Java 中提供的 synchronized 只能是非公平锁。</p>
<p>Java 中提供的 ReentrantLock，ReentrantReadWriteLock 可以实现公平锁和非公平锁。</p>
<p><strong>公平锁</strong>：线程 A 获取到了锁资源，线程 B 没有获得，线程 B 去排队，线程 C 来了，锁被 A 持有，同时线程 B 在排队，直接排到 B 的后面，等待 B 拿到锁资源或者 B 取消后，才可以尝试去竞争锁资源。</p>
<p><strong>非公平锁</strong>：线程 A 获取到了锁资源，线程 B 没有获得，线程 B 去排队，线程 C 来了，先尝试竞争一波。</p>
<ul>
<li>拿到锁资源：开心，插队成功。</li>
<li>没有拿到锁资源：依然要排到 B 的后面，等待 B 拿到锁资源或者 B 取消后，才可以尝试去竞争锁资源。</li>
</ul>
</li>
<li>
<p><strong>互斥锁、共享锁</strong></p>
<p>Java 中提供的 synchronized，ReentrantLock 是互斥锁。</p>
<p>Java 中提供的 ReentrantReadWriteLock 有互斥锁也有共享锁。</p>
<p><strong>互斥锁</strong>：同一个时间点，只会有一个线程持有者当前互斥锁。</p>
<p><strong>共享锁</strong>：同一个时间点，当前共享锁可以被多个线程同时持有。</p>
</li>
</ol>
<h1 id="synchronized-在-jdk16-的优化"><a class="header" href="#synchronized-在-jdk16-的优化">synchronized 在 JDK1.6 的优化</a></h1>
<p>在JDK1.5 的时候 Doug lee 推出了 ReentrantLock，lock 的性能远高于 synchronized，所以 JDK1.6 的时候团队就对 synchronized 进行了大量的优化。</p>
<p><strong>锁消除</strong>：在 synchronized 修饰的代码中，如果不存在操作临界资源的情况，会触发锁消除，你即便写了 synchronized，也不会触发。</p>
<pre><code class="language-java">public synchronized void method() {
  // 没有操作临界资源
  // 此时这个方法的 synchronized 可以认为没有
}
</code></pre>
<p><strong>锁膨胀</strong>：如果在一个循环中，频繁的获取和释放资源，这样带来的消耗很大，锁膨胀就是将锁的范围放大，避免频繁的竞争和获取锁资源带来不必要的消耗。</p>
<pre><code class="language-java">public void method() {
  for(int i = 0, i &lt; 99999;i++) {
    synchronized(对象) {
      
    }
  }
}
// 这时上面的锁会触发锁膨胀
</code></pre>
<p><strong>锁升级</strong>：ReentrantLock 的实现，是先基于乐观锁的 CAS 尝试获取锁资源，如果拿不到锁资源，才会挂起线程。</p>
<p>synchronized 在 JDK1.6 之前，完全就是获取不到锁，立即挂起当前线程，所以 synchronized 性能很差。</p>
<p>synchronized 就在 JDK1.6 做了锁升级的优化。</p>
<ul>
<li><strong>无锁、匿名偏向</strong>：当前线程没有作为锁的存在。</li>
<li><strong>偏向锁</strong>：如果当前锁资源，只有一个线程在频繁的获取和释放，那么这个线程过来，只需要判断，当前指向的线程是否当前线程。
<ul>
<li>如果是，直接拿着锁资源走。</li>
<li>如果不是，基于 CAS 的方式，尝试将偏向锁指向当前线程，如果获取不到，触发锁升级，升级为轻量级锁。（偏向锁状态出现了所竞争的情况）</li>
</ul>
</li>
<li><strong>轻量级锁</strong>：会采用自旋锁的方式去频繁的以 CAS 的形式获取锁资源（采用的是自适应自旋锁）
<ul>
<li>如果成功获取到，拿着锁资源走。</li>
<li>如果自旋了一定的次数，没拿到锁，锁升级。</li>
</ul>
</li>
<li><strong>重量级锁</strong>：就是最传统的 synchronized 方式，拿不到锁资源，就挂起当前线程。（用户态&amp;内核态）</li>
</ul>
<h1 id="synchronized-的实现原理"><a class="header" href="#synchronized-的实现原理">synchronized 的实现原理</a></h1>
<p>synchronized 是基于对象实现的。</p>
<p>synchronized的底层实现是完全依赖JVM虚拟机的，所以先看看对象的存储结构。</p>
<p><strong>对象结构</strong></p>
<p>JVM是虚拟机，是一种标准规范，主要作用就是运行java的类文件的。而虚拟机有很多实现版本，HotSpot就是虚拟机的一种实现，是基于热点代码探测的，有JIT即时编译功能，能提供更高质量的本地代码。HotSpot 虚拟机中对象在内存中可分为对象头（Header）、实例数据（Instance Data）和对齐填充（Padding）。其组成结构如下图：</p>
<p><img src="https://raw.githubusercontent.com/chou401/pic-md/master/image-20230825223549259.png" alt="image-20230825223549259" /></p>
<p>1）实例数据：存放类的属性数据信息，包括父类的属性信息。如果是数组，那么实例部分还包括数组的长度，这部分内存按4字节对齐。</p>
<p>2）对齐填充：虚拟机要求对象起始地址必须是8字节的整数倍。填充数据不是必须存在的，仅仅是为了字节对齐。</p>
<p>3）对象头</p>
<p>对于元数据指针，虚拟机通过这个指针来确定这个对象是哪个类的实例；</p>
<p>对于标记字段，用于存储对象自身的运行时数据，其组成如下图</p>
<p><img src="https://raw.githubusercontent.com/chou401/pic-md/master/1746338-20230329144259342-1477226941.png" alt="img" /></p>
<p>锁信息占3位）在jdk1.6之前只有重量级锁，而1.6后对其进行了优化，就有了偏向锁和轻量级锁。</p>
<p><strong>上锁的原理</strong></p>
<p>JVM规范中描述：每个对象有一个监视器锁（monitor）。</p>
<p>monitorenter指向同步代码块开始的位置，monitorexit指向同步代码块结束的位置。</p>
<p>当monitor被占用时就会处于锁定状态，线程执行monitorenter指令时尝试获取monitor的所有权，执行monitorexit 释放所有权，过程如下：</p>
<ol>
<li>如果monitor的进入数为0，则该线程进入monitor，然后将进入数设置为1，该线程即为monitor的所有者。</li>
<li>如果线程已经占有该monitor，只是重新进入，则进入monitor的进入数加1。</li>
<li>如果其他线程已经占用了monitor，则该线程进入阻塞状态，直到monitor的进入数为0，再重新尝试获取monitor的所有权。</li>
</ol>
<p>Synchronized的语义底层是通过一个monitor的对象来完成，其实wait/notify等方法也依赖于monitor对象。</p>
<p>这就是为什么只有在同步的块或者方法中才能调用wait/notify等方法，否则会抛出java.lang.IllegalMonitorStateException的异常的原因。</p>
<p><strong>Synchronized是通过对象内部的一个叫做监视器锁（monitor）来实现的。</strong></p>
<p>但是监视器锁本质又是依赖于底层的操作系统的互斥锁（Mutex Lock）来实现的。而操作系统实现线程之间的切换这就需要从用户态转换到核心态，这个成本非常高，状态之间的转换需要相对比较长的时间，这就是为什么Synchronized效率低的原因。</p>
<p>因此，这种依赖于操作系统互斥锁（Mutex Lock）所实现的锁我们称之为“重量级锁”。</p>
<h1 id="什么是-aqs"><a class="header" href="#什么是-aqs">什么是 AQS</a></h1>
<p>AQS 就是 AbstractQueuedSynchronized 抽象类，AQS 其实就是 JUC 并发包下的一个基类，JUC 下的很多内容都是基于 AQS 实现了部分功能，比如 ReentrantLock、ThreadPoolExecutor、阻塞队列、CountDownLacth、Semaphore、CyclicBarrier等等都是基于 AQS 实现的。</p>
<p>首先 AQS 中提供了一个由 volatile 修饰，并且采用 CAS 方式修改的 int 类型的 state 变量。</p>
<p>其次 AQS 中维护了一个双向链表，有 head，有 tail，并且每个节点都是 Node 对象。</p>
<pre><code class="language-java">static final class Node {
  static final Node SHARED = new Node();
  static final Node EXCLUSIVE = null;
  static final int CANCELLED =  1;
  static final int SIGEL     = -1;
  static final int CONDITION = -2;
  static final int PROPAGATE = -3;
  // 上述的状态都存储在 waitStatus 
  volatile int waitStatus;
  volatile Node prev;
  volatile Node next;
  volatile Thread thread;

}
</code></pre>
<h1 id="aqs-唤醒节点时为何从后往前找"><a class="header" href="#aqs-唤醒节点时为何从后往前找">AQS 唤醒节点时，为何从后往前找</a></h1>
<pre><code class="language-java">private void unparkSuccessor(Node node) {
    /*
     * If status is negative (i.e., possibly needing signal) try
     * to clear in anticipation of signalling.  It is OK if this
     * fails or if status is changed by waiting thread.
     */
    int ws = node.waitStatus;
    if (ws &lt; 0)
        node.compareAndSetWaitStatus(ws, 0);

    /*
     * Thread to unpark is held in successor, which is normally
     * just the next node.  But if cancelled or apparently null,
     * traverse backwards from tail to find the actual
     * non-cancelled successor.
     */
    Node s = node.next;
    if (s == null || s.waitStatus &gt; 0) {
        s = null;
        for (Node p = tail; p != node &amp;&amp; p != null; p = p.prev)
            if (p.waitStatus &lt;= 0)
                s = p;
    }
    if (s != null)
        LockSupport.unpark(s.thread);
}
</code></pre>
<p>在阅读 AQS 源码的过程中，也许会存在这样的困惑，为什么当next指针对应的节点为null 或者取消时，从tail 向前遍历寻找最近的一个非取消的节点。</p>
<p>当前任释放时，需要获取继任者；AQS的实现方式是从tail 向前遍历，之所以这样是与入队时的逻辑有关。</p>
<pre><code class="language-java">/**
 * Inserts node into queue, initializing if necessary. See picture above.
 * @param node the node to insert
 * @return node's predecessor
 */
private Node enq(final Node node) {
    for (;;) {
        Node t = tail;
        if (t == null) { // Must initialize
            if (compareAndSetHead(new Node()))
                tail = head;
        } else {
            node.prev = t;
            if (compareAndSetTail(t, node)) {
            // 假设线程1执行到这里被挂起，此时 next 指针还没有关联到，后新来的线程 n 可能已经被排列到后面去了，所以当 t 被需要时，它的 next 指针还没有设置或者重置；故需要从后到前寻找，而如果找寻下一个，而这个可能被遗漏了；
            // 故api文档中有这样一说 (Or, said differently, the next-links are an optimization so that we don't usually need a backward scan.)
                t.next = node;
                return t;
            }
        }
    }
}
</code></pre>
<p>源码内部类Node上的注释中有对这个场景的完整描述：</p>
<pre><code class="language-java"> final boolean isOnSyncQueue(Node node) {
    if (node.waitStatus == Node.CONDITION || node.prev == null)
        return false;
    if (node.next != null) // If has successor, it must be on queue
        return true;
    /*
     * node.prev can be non-null, but not yet on queue because
     * 节点的前置前置节点可能为非空，但是尚未在同步队列中，
     * the CAS to place it on queue can fail. So we have to
     * 因为cas 入队时可能失败。
     * traverse from tail to make sure it actually made it.  It
     * 所以我们不得不后序遍历以确保正确的发现它。
     * will always be near the tail in calls to this method, and
     * 它总是在靠近尾节点，当执行这个方法时
     * unless the CAS failed (which is unlikely), it will be
     * 除非cas 失败（这不太可能），所以我们不会遍历太多
     * there, so we hardly evertraverse much.
     */
    return findNodeFromTail(node);
 }
</code></pre>
<p>另一方面如果下一个节点时null（已经被GC ），如何找到下一个有效节点，也只能从后往前找了。</p>
<h1 id="reentrantlock和synchronized的区别"><a class="header" href="#reentrantlock和synchronized的区别">ReentrantLock和synchronized的区别</a></h1>
<p>在 Java 中，常用的锁有两种：synchronized（内置锁）和 ReentrantLock（可重入锁）。</p>
<p><strong>用法不同</strong></p>
<p><strong>synchronized 可用来修饰普通方法、静态方法和代码块，而 ReentrantLock 只能用在代码块上。</strong></p>
<p>使用 synchronized 修饰代码块：</p>
<pre><code class="language-java">public void method() {
  // 加锁代码
  synchronized(this) {
    //...
  }
}
</code></pre>
<p>ReentrantLock 在使用之前需要先创建 ReentrantLock 对象，然后使用 lock 方法进行加锁，使用完之后再调用 unlock 方法释放锁，具体使用如下：</p>
<pre><code class="language-java">public void lockExample() {
  private final ReentrantLock lcok = new ReentrantLock();
  public void method() {
    // lock 加锁操作
    lock.lock();
    try {
      // ...
    } finally {
      // 释放锁
      lock.unlock();
    }
  }
}
</code></pre>
<p><strong>获取锁和释放锁方式不同</strong></p>
<p><strong>synchronized 会自动加锁和释放锁</strong>，当进入 synchronized 修饰的代码块之后会自动加锁，当离开 synchronized 的代码段之后会自动释放锁，如下图所示：</p>
<pre><code class="language-java">public class APP {
  public void method() {
    int count = 0;
    synchronized(this) {
      for(int i = 0;i &lt; 10;i++) {
        count++;
      }
    }
    System.out.println(count);
  }
}
</code></pre>
<p><strong>而 ReentrantLock 需要手动加锁和释放锁</strong>，如下图所示：</p>
<pre><code class="language-java">public void lockExample() {
  private final ReentrantLock lcok = new ReentrantLock();
  public void method() {
    // lock 加锁操作
    lock.lock();
    try {
      // ...
    } finally {
      // 释放锁
      lock.unlock();
    }
  }
}
</code></pre>
<blockquote>
<p>PS：在使用 ReentrantLock 时要特别小心，unlock 释放锁的操作一定要放在 finally 中，否者有可能会出现锁一直被占用，从而导致其他线程一直阻塞的问题。</p>
</blockquote>
<p><strong>锁类型不同</strong></p>
<p><strong>synchronized 属于非公平锁，而 ReentrantLock 既可以是公平锁也可以是非公平锁。</strong> 默认情况下 ReentrantLock 为非公平锁，这点查看源码可知：</p>
<pre><code class="language-java">public ReentrantLock() {
  sync = new NonfairSync();
}
</code></pre>
<p>使用 new ReentrantLock(true) 可以创建公平锁，查看源码可知：</p>
<pre><code class="language-java">public ReentrantLock(boolean fair) {
  sync = fair ? FairSync() : new NonfairSync();
}
</code></pre>
<p><strong>响应中断不同</strong></p>
<p><strong>ReentrantLock 可以使用 lockInterruptibly 获取锁并响应中断指令，而 synchronized 不能响应中断，也就是如果发生了死锁，使用 synchronized 会一直等待下去，而使用 ReentrantLock 可以响应中断并释放锁，从而解决死锁的问题</strong>，比如以下 ReentrantLock 响应中断的示例：</p>
<p><img src="https://raw.githubusercontent.com/chou401/pic-md/master/v2-295dc5c5c1611e25ca7e32a12c1baab5_r.jpg" alt="img" /></p>
<p>以上程序的执行结果如下所示：</p>
<p><img src="https://raw.githubusercontent.com/chou401/pic-md/master/v2-41af01e5aee54030a2bd3429191b39ef_r.jpg" alt="img" /></p>
<p><strong>底层实现不同</strong></p>
<p><strong>synchronized 是 JVM 层面通过监视器（Monitor）实现的，而 ReentrantLock 是通过 AQS（AbstractQueuedSynchronizer）程序级别的 API 实现。</strong> synchronized 通过监视器实现，可通过观察编译后的字节码得出结论，如下图所示：</p>
<p><img src="https://raw.githubusercontent.com/chou401/pic-md/master/v2-f801feb292fa284062ab77ed419e0770_r.jpg" alt="img" /></p>
<p>其中 monitorenter 表示进入监视器，相当于加锁操作，而 monitorexit 表示退出监视器，相当于释放锁的操作。 ReentrantLock 是通过 AQS 实现，可通过观察 ReentrantLock 的源码得出结论，核心实现源码如下：</p>
<p><img src="https://raw.githubusercontent.com/chou401/pic-md/master/v2-b76e76b03d158accc357568d8c360526_r.jpg" alt="img" /></p>
<h1 id="reentrantreadwritelock的实现原理"><a class="header" href="#reentrantreadwritelock的实现原理">ReentrantReadWriteLock的实现原理</a></h1>
<p>在很多场景下，我们用到的都是互斥锁，线程间相互竞争资源；但是有时候我们的场景会存在读多写少的情况，这个时候如果还是使用互斥锁，就会导致资源的浪费，为什么呢？</p>
<p>因为如果同时都在读的时候，是不需要锁资源的，只有读和写在同时工作的时候才需要锁资源，所以如果直接用互斥锁，肯定会导致资源的浪费。 </p>
<p><strong>提供的方法</strong></p>
<ul>
<li>readLock()：获取读锁对象（不是获取锁资源）</li>
<li>writeLock()：获取写锁对象（不是获取锁资源）</li>
<li>getReadLockCount()：获取当前读锁被获取的次数，包括线程重入的次数</li>
<li>getReadHoldCount()：返回当前线程获取读锁的次数</li>
<li>isWriteLocked()：判断写锁是否被获取</li>
<li>getWriteHoldCount()：返回当前写锁被获取的次数 </li>
</ul>
<p><strong>ReentrantReadWriteLock 还是基于 AQS 实现的，还是对 state 进行操作，拿到锁资源就去干活，如果没有拿到，依然去 AQS 队列中排队。</strong></p>
<p><strong>读锁操作：基于 state 高 16 位进行操作。</strong></p>
<p><strong>写锁操作：基于 state 低 16 位进行操作。</strong></p>
<p><strong>ReentrantReadWriteLock 依然是可重入锁。</strong></p>
<p><strong>写锁重入</strong>：读写锁中写锁的重入方式，基本和 ReentrantLock 一致，没有什么区别，依然是对 state + 1 操作即可，只要确认持有锁资源的线程，是当前写锁线程即可，只不过之前 ReentrantLock 的重入次数是 state 的正数取值范围，但是读写锁中写锁范围就小了。</p>
<p><strong>读锁重入</strong>：因为读锁是共享锁，读锁在获取锁资源操作时，是要对 state 的高 16 位进行 +1 操作。因为读锁是共享锁，所以同一时间会有多个读线程持有读锁资源。这样一来，多个读操作在持有读锁时，无法确认每个线程读锁重入的次数。为了去记录读锁重入的次数，每个读操作的线程，都会有一个 ThreadLocal 记录重入的次数。</p>
<p><strong>写锁的饥饿问题</strong>：读锁是共享锁，当有线程持有读锁资源时，再来一个线程想要获取读锁，直接对 state 修改即可。在读锁资源先被占用后，来了一个写锁资源，此时，大量的需要获取读锁的线程请求锁资源，如果可以绕过写锁，直接拿资源，会造成写锁长时间无法获取写锁资源。</p>
<p><strong>锁降级</strong>：当前线程先获取到写锁，然后再获取读锁，再把写锁释放，最后释放读锁。</p>
<p><strong>读锁在拿到锁资源后，如果再有读线程需要获取读锁资源，需要去 AQS 队列排队，如果队列的前面需要获取写锁资源的线程，那么后续读线程是无法拿到锁资源的。持有读锁的线程，只会让写锁线程之前的读线程拿到锁资源。</strong></p>
<p><strong>写锁的获取与释放</strong></p>
<p>获取锁的源码：</p>
<pre><code class="language-java">protected final boolean tryAcquire(int acquires) {
    /*
     * Walkthrough:
     * 1. If read count nonzero or write count nonzero
     *    and owner is a different thread, fail.
     * 2. If count would saturate, fail. (This can only
     *    happen if count is already nonzero.)
     * 3. Otherwise, this thread is eligible for lock if
     *    it is either a reentrant acquire or
     *    queue policy allows it. If so, update state
     *    and set owner.
     */
    Thread current = Thread.currentThread();
    int c = getState();
    int w = exclusiveCount(c);
    if (c != 0) {
        // (Note: if c != 0 and w == 0 then shared count != 0)
        if (w == 0 || current != getExclusiveOwnerThread())
            return false;
        if (w + exclusiveCount(acquires) &gt; MAX_COUNT)
            throw new Error(&quot;Maximum lock count exceeded&quot;);
        // Reentrant acquire
        setState(c + acquires);
        return true;
    }
    if (writerShouldBlock() ||
        !compareAndSetState(c, c + acquires))
        return false;
    setExclusiveOwnerThread(current);
    return true;
}
</code></pre>
<p>释放锁的源码:</p>
<pre><code class="language-java">protected final boolean tryRelease(int releases) {
    if (!isHeldExclusively())
        throw new IllegalMonitorStateException();
    int nextc = getState() - releases;
    boolean free = exclusiveCount(nextc) == 0;
    if (free)
        setExclusiveOwnerThread(null);
    setState(nextc);
    return free;
}
</code></pre>
<p><strong>读锁的获取与释放</strong></p>
<p>获取锁的源码:</p>
<pre><code class="language-java">protected final int tryAcquireShared(int unused) {
    /*
     * Walkthrough:
     * 1. If write lock held by another thread, fail.
     * 2. Otherwise, this thread is eligible for
     *    lock wrt state, so ask if it should block
     *    because of queue policy. If not, try
     *    to grant by CASing state and updating count.
     *    Note that step does not check for reentrant
     *    acquires, which is postponed to full version
     *    to avoid having to check hold count in
     *    the more typical non-reentrant case.
     * 3. If step 2 fails either because thread
     *    apparently not eligible or CAS fails or count
     *    saturated, chain to version with full retry loop.
     */
    Thread current = Thread.currentThread();
    int c = getState();
    if (exclusiveCount(c) != 0 &amp;&amp;
        getExclusiveOwnerThread() != current)
        return -1;
    int r = sharedCount(c);
    if (!readerShouldBlock() &amp;&amp;
        r &lt; MAX_COUNT &amp;&amp;
        compareAndSetState(c, c + SHARED_UNIT)) {
        if (r == 0) {
            firstReader = current;
            firstReaderHoldCount = 1;
        } else if (firstReader == current) {
            firstReaderHoldCount++;
        } else {
            HoldCounter rh = cachedHoldCounter;
            if (rh == null ||
                rh.tid != LockSupport.getThreadId(current))
                cachedHoldCounter = rh = readHolds.get();
            else if (rh.count == 0)
                readHolds.set(rh);
            rh.count++;
        }
        return 1;
    }
    return fullTryAcquireShared(current);
}
</code></pre>
<p>释放锁的源码:</p>
<pre><code class="language-java">protected final boolean tryReleaseShared(int unused) {
    Thread current = Thread.currentThread();
    if (firstReader == current) {
        // assert firstReaderHoldCount &gt; 0;
        if (firstReaderHoldCount == 1)
            firstReader = null;
        else
            firstReaderHoldCount--;
    } else {
        HoldCounter rh = cachedHoldCounter;
        if (rh == null ||
            rh.tid != LockSupport.getThreadId(current))
            rh = readHolds.get();
        int count = rh.count;
        if (count &lt;= 1) {
            readHolds.remove();
            if (count &lt;= 0)
                throw unmatchedUnlockException();
        }
        --rh.count;
    }
    for (;;) {
        int c = getState();
        int nextc = c - SHARED_UNIT;
        if (compareAndSetState(c, nextc))
            // Releasing the read lock has no effect on readers,
            // but it may allow waiting writers to proceed if
            // both read and write locks are now free.
            return nextc == 0;
    }
}
</code></pre>
<h1 id="jdk中提供了哪些线程池"><a class="header" href="#jdk中提供了哪些线程池">JDK中提供了哪些线程池</a></h1>
<p><strong>newFixedThreadPool</strong></p>
<p>这个线程的特点是线程数是固定的。</p>
<pre><code class="language-java">public static ExecutorService newFixedThreadPool(int nThreads) {
    return new ThreadPoolExecutor(nThreads, nThreads,
                                  0L, TimeUnit.MILLISECONDS,
                                  new LinkedBlockingQueue&lt;Runnable&gt;());
}
</code></pre>
<p>构建时，需要给 newFixedThreadPool 方法提供一个 nThreads 的属性，而这个属性就是当前线程池线程的个数，当前线程池的本质其实就是使用 ThreadPoolExecutor。</p>
<p>构建好当前线程池后，线程个数已经固定好（线程是懒加载，在构建之初，线程并没有构建出来，而是随着任务的提交才会将线程在线程池中构建出来）。如果线程没有构建，线程会待着任务执行被创建和执行。如果线程都已经构建好了，此时任务会被放到 LinkedBlockingQueue 无界队列中存放，等待线程从 LinkedBlockingQueue 中去 take 出去，然后执行。</p>
<p><strong>newSingleThreadExecutor</strong></p>
<p>单例线程池，该线程池只有一个工作线程在处理任务，如果业务是顺序消费们可以采用该线程池。</p>
<p>这种线程池比较简单，它内部只有一个线程，会用唯一的工作线程来执行任务。它的原理和固定线程数量的线程池的原理是一样的，只不过这个时候它的线程数量就直接被设置为 1，也就是只有一个线程。</p>
<pre><code class="language-java">public static ExecutorService newSingleThreadExecutor() {
    return new FinalizableDelegatedExecutorService
        (new ThreadPoolExecutor(1, 1,
                                0L, TimeUnit.MILLISECONDS,
                                new LinkedBlockingQueue&lt;Runnable&gt;()));
}

private static class FinalizableDelegatedExecutorService
            extends DelegatedExecutorService {
    FinalizableDelegatedExecutorService(ExecutorService executor) {
        super(executor);
    }
    @SuppressWarnings(&quot;deprecation&quot;)
    protected void finalize() {
        super.shutdown();
    }
}
</code></pre>
<p>单例线程池，线程池中只有一个工作线程在处理任务。</p>
<p>如果业务中涉及了顺序消费，可以采用 newSingleThreadExecutor。</p>
<p><strong>newCachedThreadPool</strong></p>
<p>缓存线程池，corePoolSize为0，当第一次提交任务到线程池时，会直接构建一个工作线程，Integer.MAX_VALUE：意味着线程数量可以无限大，keepAliveTime为60S，60秒内没有任务进来，意味着线程空闲时间超过60S就会被杀死；如果在等待60秒期间有任务进来，他会再次拿到这个任务去执行，特点是：任务只要提交到该线程池就必然有工作线程处理。</p>
<p>它是可缓存的线程池，并且还会回收。它会把任务交给我们的线程，而且线程不够用的话，就会创建线程。如果线程过多，就会把这些线程给回收回来。</p>
<pre><code class="language-java">public static ExecutorService newCachedThreadPool() {
    return new ThreadPoolExecutor(0, Integer.MAX_VALUE,
                                  60L, TimeUnit.SECONDS,
                                  new SynchronousQueue&lt;Runnable&gt;());
}
</code></pre>
<p><strong>newScheduledThreadPool</strong></p>
<p>定时线程池，创建一个定时线程池，即按一定的周期执行任务，即定时任务，或者设置定时时间，延迟执行任务，由于该线程池是继承ThreadPoolExecutor，所以本质上还是ThreadPoolExecutor线程池，只不过是在原来的基础上添加了定时功能，其原理是基于DelayQueue实现延迟执行，周期性执行，任务执行完毕，再次扔会到阻塞队列。</p>
<pre><code class="language-java">public static ScheduledExecutorService newScheduledThreadPool(
            int corePoolSize, ThreadFactory threadFactory) {
    return new ScheduledThreadPoolExecutor(corePoolSize, threadFactory);
}

public ScheduledThreadPoolExecutor(int corePoolSize,
                                       ThreadFactory threadFactory) {
    super(corePoolSize, Integer.MAX_VALUE,
          DEFAULT_KEEPALIVE_MILLIS, MILLISECONDS,
          new DelayedWorkQueue(), threadFactory);
}
</code></pre>
<p><strong>newWorkStealingPool</strong></p>
<p>newWorkStealingPool简单翻译是<strong>任务窃取</strong>线程池。和别的4种不同，它用的是ForkJoinPool。使用ForkJoinPool的好处是，把1个任务拆分成多个“<strong>小任务</strong>”，把这些“<strong>小任务</strong>”分发到多个线程上执行。这些“<strong>小任务</strong>”都执行完成后，再将结果<strong>合并</strong>。之前的线程池中，多个线程共有一个阻塞队列，而newWorkStealingPool 中每一个线程都有一个自己的队列。当线程发现自己的队列没有任务了，就会到别的线程的队列里获取任务执行。可以简单理解为”<strong>窃取</strong>“。一般是自己的本地队列采取LIFO(后进先出)，窃取时采用FIFO(先进先出)，一个从头开始执行，一个从尾部开始执行，由于偷取的动作十分快速，会大量降低这种冲突，也是一种优化方式。</p>
<pre><code class="language-java">public static ExecutorService newWorkStealingPool() {
    return new ForkJoinPool
        (Runtime.getRuntime().availableProcessors(),
         ForkJoinPool.defaultForkJoinWorkerThreadFactory,
         null, true);
}
</code></pre>
<h1 id="线程池的核心参数有什么"><a class="header" href="#线程池的核心参数有什么">线程池的核心参数有什么</a></h1>
<p>为什么要自定义线程池， 首先 ThreadPoolExecutor 中，一种提供了 7 个参数，每个参数都是非常核心的属性，在线程池去执行任务时，每个参数都有决定性的作用。</p>
<p>但是如果直接采用 JDK 提供的方式去构建，可以设置的参数最多两个，这样就会导致对线程池的控制粒度很粗。所以在阿里规范中也推荐去自定义线程池。手动的去 new ThreadPoolExecutor 设置它的一些核心属性。</p>
<p>自定义构建线程池，可以细粒度的控制线程池，去管理内存的属性，并且针对一些参数的设置可能更好的在后期排查问题。</p>
<p><strong>自定义线程池七大参数</strong></p>
<ul>
<li>
<p><strong>int corePoolSize</strong></p>
<p>核心线程数，创建线程池后不会立即创建核心线程，当有任务到达时才触发核心线程的创建，当线程池中的线程数目达到corePoolSize后，就会把到达的任务放到缓存队列当中。核心线程在allowCoreThreadTimeout被设置为true时会超时并被回收，默认情况下不会被回收。</p>
</li>
<li>
<p><strong>int maximumPoolSize</strong></p>
<p>最大线程数，代表当前线程池中，一共可以有多少个工作线程。当线程数大于或等于corePoolSize，且任务队列已满时，线程池会创建新的线程，直到线程数量达到maxPoolSize。如果线程数已等于maxPoolSize，且任务队列已满，则已超出线程池的处理能力，线程池会按照rejectedExecutionHandler配置的处理策略进行处理线程。</p>
</li>
<li>
<p><strong>long keepAliveTime</strong></p>
<p>非核心工作线程在阻塞队列位置等待的时间，当线程空闲时间达到keepAliveTime，该线程会退出，直到线程数量等于corePoolSize。如果allowCoreThreadTimeout设置为true，则所有线程均会退出直到线程数量为0。</p>
</li>
<li>
<p><strong>TimeUnit unit</strong></p>
<p>非核心工作线程在阻塞队列位置等待时间的单位。</p>
</li>
<li>
<p><strong>BlockingQueue<Runnable> workQueue</strong></p>
<p>任务没有在核心工作线程处理时，任务先扔到阻塞队列中。阻塞队列，用来存储等待执行的任务，新任务被提交后，会先进入到此工作队列中，任务调度时再从队列中取出任务。这里的阻塞队列有以下几种选择：</p>
<ul>
<li>ArrayBlockingQueue：基于数组的有界阻塞队列，按FIFO排序</li>
<li>LinkedBlockingQueue：基于链表的无界阻塞队列（其实最大容量为Interger.MAX），按照FIFO排序</li>
<li>PriorityBlockingQueue：具有优先级的无界阻塞队列，优先级通过参数Comparator实现</li>
<li>SynchronousQueue：一个不缓存任务的阻塞队列，也就是说新任务进来时，不会缓存，而是直接被调度执行该任务</li>
</ul>
</li>
<li>
<p><strong>ThreadFactory threadFactory</strong></p>
<p>线程工厂，创建一个新线程时使用的工厂，可以用来设定线程名、是否为daemon线程等等。在构建线程的线程工作，可以设置thread 的一些信息。</p>
</li>
<li>
<p><strong>RejectedExecutionHandler handler</strong></p>
<p>当前线程池无法处理投递过来的任务时，执行当前的拒绝策略 。拒绝策略有以下：</p>
<ul>
<li>AbortPolicy：当前拒绝策略在无法处理任务时，会抛出一个异常</li>
<li>CallerRunPolicy：当前拒绝策略在线程池无法处理任务时，会将任务交给调用者处理</li>
<li>DiscardPolicy：当前拒绝策略在无法处理任务时，会直接将任务丢掉</li>
<li>DiscardOldestPolicy：当前拒绝策略在无法处理任务时,将队列中最早的任务丢掉，将当前<strong>再次尝试</strong>交给线程池处理</li>
<li>自定义Policy：根据自己的任务，将任务扔到数据库，也可以做其他操作。</li>
</ul>
</li>
</ul>
<h1 id="线程池的状态"><a class="header" href="#线程池的状态">线程池的状态</a></h1>
<p>线程池的5种状态：RUNNING、SHUTDOWN、STOP、TIDYING、TERMINATED。</p>
<pre><code class="language-java">private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));
private static final int COUNT_BITS = Integer.SIZE - 3;
private static final int COUNT_MASK = (1 &lt;&lt; COUNT_BITS) - 1;

// runState is stored in the high-order bits
private static final int RUNNING    = -1 &lt;&lt; COUNT_BITS;
private static final int SHUTDOWN   =  0 &lt;&lt; COUNT_BITS;
private static final int STOP       =  1 &lt;&lt; COUNT_BITS;
private static final int TIDYING    =  2 &lt;&lt; COUNT_BITS;
private static final int TERMINATED =  3 &lt;&lt; COUNT_BITS;
</code></pre>
<ul>
<li>
<p>RUNNING</p>
<p>线程池一旦被创建，就处于 RUNNING 状态，任务数为 0，能够接收新任务，对已排队的任务进行处理。</p>
</li>
<li>
<p>SHUTDOWN</p>
<p>不接收新任务，但能处理已排队的任务。调用线程池的 shutdown() 方法，线程池由 RUNNING 转变为 SHUTDOWN 状态。</p>
</li>
<li>
<p>STOP</p>
<p>不接收新任务，不处理已排队的任务，并且会中断正在处理的任务。调用线程池的 shutdownNow() 方法，线程池由(RUNNING 或 SHUTDOWN ) 转变为 STOP 状态。</p>
</li>
<li>
<p>TIDYING</p>
<ul>
<li>SHUTDOWN 状态下，任务数为 0， 其他所有任务已终止，线程池会变为 TIDYING 状态，会执行 terminated() 方法。线程池中的 terminated() 方法是空实现，可以重写该方法进行相应的处理。</li>
<li>线程池在 SHUTDOWN 状态，任务队列为空且执行中任务为空，线程池就会由 SHUTDOWN 转变为 TIDYING 状态。</li>
<li>线程池在 STOP 状态，线程池中执行中任务为空时，就会由 STOP 转变为 TIDYING 状态。</li>
</ul>
</li>
<li>
<p>TERMINATED</p>
<p>线程池彻底终止。线程池在 TIDYING 状态执行完 terminated() 方法就会由 TIDYING 转变为 TERMINATED 状态。</p>
</li>
</ul>
<p><img src="https://raw.githubusercontent.com/chou401/pic-md/master/1408183-20191016162255593-1404242897.jpg" alt="img" /></p>
<h1 id="线程池的执行流程"><a class="header" href="#线程池的执行流程">线程池的执行流程</a></h1>
<p>ThreadPoolExecutor 的 execute() 是提任务到线程池的核心方法，很重要。</p>
<pre><code class="language-java">public void execute(Runnable command) {
  	// 提交的任务不能为 null
    if (command == null)
        throw new NullPointerException();
    /*
     * Proceed in 3 steps:
     *
     * 1. If fewer than corePoolSize threads are running, try to
     * start a new thread with the given command as its first
     * task.  The call to addWorker atomically checks runState and
     * workerCount, and so prevents false alarms that would add
     * threads when it shouldn't, by returning false.
     *
     * 2. If a task can be successfully queued, then we still need
     * to double-check whether we should have added a thread
     * (because existing ones died since last checking) or that
     * the pool shut down since entry into this method. So we
     * recheck state and if necessary roll back the enqueuing if
     * stopped, or start a new thread if there are none.
     *
     * 3. If we cannot queue task, then we try to add a new
     * thread.  If it fails, we know we are shut down or saturated
     * and so reject the task.
     */
  	// 获取核心线程 ctl，用于后面的判断
    int c = ctl.get();
  	// 如果工作线程个数小于核心线程数
  	// 满足要求，添加核心工作线程
    if (workerCountOf(c) &lt; corePoolSize) {
      	// addWorker(任务，是核心线程吗)
      	// addWorker返回 true，代表添加工作线程成功
      	// addWorker返回 false，代表添加工作线程失败
      	// addWorker中会基于线程池状态，以及工作线程个数做判断，查看能否添加工作线程
        if (addWorker(command, true))
          	// 工作线程构建出来了，任务也交给 command 去处理了
            return;
      	// 说明线程池状态或者是工作线程个数发生了变化，导致添加失败，重新获取一次 ctl
        c = ctl.get();
    }
  	// 添加核心工作线程失败，调用一下
  	// 判断线程池状态是否是 RUNNING，如果是，正常基于阻塞队列的 offer 方法，将任务添加到阻塞队列
    if (isRunning(c) &amp;&amp; workQueue.offer(command)) {
      	// 如果任务添加到阻塞队列成功，走 if 内部
      	// 如果任务在扔到阻塞队列之前，线程池状态突然改变了
      	// 重新获取 ctl
        int recheck = ctl.get();
      	// 如果线程池的状态不是 RUNNING，将任务从阻塞队列中移除
        if (! isRunning(recheck) &amp;&amp; remove(command))
          	// 并且直接拒绝策略
            reject(command);
      	// 在这，说明阻塞队列有我刚刚放进去的任务
      	// 查看一下工作线程数是不是 0 个
      	// 如果工作线程为 0 个，需要添加一个非核心工作线程去处理阻塞队列中的任务
      	// 发生这种情况有两种：
      	// 1.构建线程池时，核心线程数为 0 个
      	// 2.即便有核心线程，可以设置核心线程也允许超时，设置 allowCoreThreadTimeOut 为 true，代表核心线程也可以关闭
        else if (workerCountOf(recheck) == 0)
          	// 为了避免阻塞队列中的任务饥饿，添加一个非核心工作线程去处理
            addWorker(null, false);
    }
  	// 任务添加到阻塞队列失败
  	// 构建一个非核心工作线程
  	// 如果添加非核心工作线程成功，直接完事
    else if (!addWorker(command, false))
      	// 添加失败，执行拒绝策略
        reject(command);
}
</code></pre>
<p><img src="https://raw.githubusercontent.com/chou401/pic-md/master/image-20230828000746127.png" alt="image-20230828000746127" /></p>
<h1 id="线程池添加工作线程的流程"><a class="header" href="#线程池添加工作线程的流程">线程池添加工作线程的流程</a></h1>
<p>addWorker 中主要分成两大块去看</p>
<ul>
<li>第一块：校验线程池的状态以及工作线程个数</li>
<li>第二块：添加工作线程并且启动工作线程</li>
</ul>
<p>校验线程池的状态以及工作线程个数</p>
<pre><code class="language-java">private boolean addWorker(Runnable firstTask, boolean core) {
    retry:
  	// 循环检查状态
    for (int c = ctl.get();;) {
        // Check if queue empty only if necessary.
      	// 检查线程池的运行状态是否 shutdown，任务队列是否为空等状态是否正常
        if (runStateAtLeast(c, SHUTDOWN)
            &amp;&amp; (runStateAtLeast(c, STOP)
                || firstTask != null
                || workQueue.isEmpty()))
            return false;

      	// 循环更新状态，和线程数量的更新，都是使用 CAS 的模式更新
        for (;;) {
          	// 检查运行的线程数是否超标
            if (workerCountOf(c)
                &gt;= ((core ? corePoolSize : maximumPoolSize) &amp; COUNT_MASK))
                return false;
          	// CAS 方式更新线程数量
            if (compareAndIncrementWorkerCount(c))
              	// 更新成功后直接跳转到方法第一行，并且不在进入这些 for 循环中
              	// 因为状态啥的已经更新成功了
                break retry;
            c = ctl.get();  // Re-read ctl
          	// 如果 CAS 增加线程数失败，检查下状态是否还是和之前一样
            if (runStateAtLeast(c, SHUTDOWN))
              	// 不一样了，会跳转到第一行，并会重新进入 for 循环中走一遍流程
                continue retry;
            // else CAS failed due to workerCount change; retry inner loop
        }
    }

    boolean workerStarted = false;
    boolean workerAdded = false;
    Worker w = null;
    try {
      	// 新建一个 worker，内部包含线程
        w = new Worker(firstTask);
      	// 获取内部的线程对象
        final Thread t = w.thread;
        if (t != null) {
          	// 加锁，锁定
            final ReentrantLock mainLock = this.mainLock;
            mainLock.lock();
            try {
                // Recheck while holding lock.
                // Back out on ThreadFactory failure or if
                // shut down before lock acquired.
                int c = ctl.get();

              	// 二次检查线程池的状态
                if (isRunning(c) ||
                    (runStateLessThan(c, STOP) &amp;&amp; firstTask == null)) {
                  	// 池的状态没有问题，检查线程是否存活
                    if (t.getState() != Thread.State.NEW)
                        throw new IllegalThreadStateException();
                  	// worker 放入池的 hashset 中
                    workers.add(w);
                    workerAdded = true;
                    int s = workers.size();
                  	// 并将 worker 的数量赋予池中的 largestPoolSize 成员变量
                    if (s &gt; largestPoolSize)
                        largestPoolSize = s;
                }
            } finally {
                mainLock.unlock();
            }
          	// worker 创建成功并加入 workers 成功
            if (workerAdded) {
              	// 启动线程
                t.start();
              	// 修改状态
                workerStarted = true;
            }
        }
    } finally {
        if (! workerStarted)
          	// 启动线程失败，进行失败处理
            addWorkerFailed(w);
    }
    return workerStarted;
}
</code></pre>
<h1 id="线程池为何要构建空任务的非核心线程"><a class="header" href="#线程池为何要构建空任务的非核心线程">线程池为何要构建空任务的非核心线程</a></h1>
<pre><code class="language-java">// 工作线程小于核心线程执行
if (workerCountOf(c) &lt; corePoolSize) {
    if (addWorker(command, true))
        return;
    c = ctl.get();
}
if (isRunning(c) &amp;&amp; workQueue.offer(command)) {
    int recheck = ctl.get();
    if (! isRunning(recheck) &amp;&amp; remove(command))
        reject(command);
    else if (workerCountOf(recheck) == 0)
      	// 添加空任务
        addWorker(null, false);
}
else if (!addWorker(command, false))
    reject(command);
</code></pre>
<p>若是核心线程数设置的为0，我们第一次执行addWorker时，就会因为核心线程和工作线程都是0，不会执行第一块标红的区域，而是会执行第二块，而第二块是直接将任务添加到阻塞队列里面，此时是没有工作线程的，那阻塞队列里的任务由谁执行呢？所以在线程池的状态正常的情况下会添加一个空任务用于执行阻塞队列中的任务。</p>
<p>避免线程池出现工作队列有任务，但是没有工作线程处理。</p>
<p>线程池可以设置核心线程数是0个。这样，任务扔到阻塞队列，但是没有工作线程，这不凉凉了么。</p>
<p>线程池中的核心线程不是一定不会被回收，线程池中有一个属性，如果设置为true，核心线程也会被干掉。</p>
<pre><code class="language-java">/**
 * If false (default), core threads stay alive even when idle.
 * If true, core threads use keepAliveTime to time out waiting
 * for work.
 */
private volatile boolean allowCoreThreadTimeOut;
</code></pre>
<p>在线程池中，当工作队列已满且活动线程数小于最大线程数时，会创建非核心线程来执行任务。即使是空任务，也可能会被分配给非核心线程来执行。这是因为线程池的设计考虑到以下几个方面的因素：</p>
<ol>
<li><strong>任务处理的公平性</strong>：
空任务也被看作是一种任务，线程池需要公平地处理所有提交的任务。如果只有非空任务才会被分配给非核心线程，那么在任务队列中可能会积累大量的空任务，导致非核心线程一直处于空闲状态，而核心线程却忙于执行非空任务。</li>
<li><strong>响应时间的需求</strong>：
线程池旨在提供一种能够快速响应任务的机制。即使是空任务，也可以使线程池保持活跃状态，以便在有实际任务到来时能够立即分配线程进行执行，而不需要额外的线程创建开销。</li>
<li><strong>线程的复用性</strong>：
创建和销毁线程都需要一定的时间和资源开销。通过让非核心线程执行空任务，可以使线程池中的线程得到更好的复用，减少频繁地创建和销毁线程的开销。</li>
</ol>
<p>总的来说，为了保持任务处理的公平性、快速响应时间和线程的复用性，线程池会将空任务也分配给非核心线程执行。</p>
<p>需要注意的是，空任务并不会占用实际的计算资源，因此它们不会对系统的整体性能产生负面影响。但是，在使用线程池时，确保任务的提交是有意义且合理的，避免无谓的空任务提交。</p>
<p><strong>空任务</strong></p>
<p>空任务（Empty Task）指的是在线程池中提交的一个任务，其执行过程中不需要执行任何实际的操作或逻辑。空任务本身不包含需要执行的代码，或者说它的执行代码为空或者只是一个空的循环。</p>
<p>空任务可能是由于以下原因之一而产生：</p>
<ol>
<li><strong>任务队列的填充</strong>：
为了保持任务队列的饱满状态，或者为了占据队列中的位置以防止新任务被拒绝，可能会提交一些空任务。</li>
<li><strong>资源占用</strong>：
为了占用一定的系统资源或者保持线程池中的线程处于活跃状态，可能会提交一些空任务。</li>
</ol>
<p>空任务的实际意义相对较小，因为它们没有具体的业务逻辑或计算任务。在实际应用中，通常会提交具有实际意义的任务来利用线程池的并发执行能力。</p>
<p>需要注意的是，过多的空任务可能会占用线程池的资源，导致性能下降。因此，在使用线程池时，应该确保任务的提交是有意义的，避免无谓的空任务提交。</p>
<h1 id="线程池使用完毕为何必须shutdown"><a class="header" href="#线程池使用完毕为何必须shutdown">线程池使用完毕为何必须shutdown()</a></h1>
<p>线程池里面复用的是线程资源，而线程是系统资源的一种。所以关闭线程池是为了正确地终止线程池的运行并释放相关资源。下面是关闭线程池的重要原因：</p>
<ul>
<li>
<p>释放资源：</p>
<p>线程池内部会创建一定数量的线程以及其他相关资源，如线程队列、线程池管理器等。如果不及时关闭线程池，这些资源将一直占用系统资源，可能导致内存泄漏或资源浪费。</p>
</li>
<li>
<p>防止任务丢失：</p>
<p>线程池中可能还有未执行的任务，如果不关闭线程池，这些任务将无法得到执行。关闭线程池时，会等待所有已提交的任务执行完毕，确保任务不会丢失。</p>
</li>
<li>
<p>优雅终止：</p>
<p>关闭线程池可以让线程池中的线程正常执行完当前任务后停止，避免突然终止线程导致的资源释放不完整或状态不一致的问题。</p>
</li>
<li>
<p>避免程序阻塞：</p>
<p>在某些情况下，如果不关闭线程池，程序可能会一直等待线程池中的任务执行完毕，从而导致程序阻塞，无法继续执行后续的逻辑。</p>
</li>
</ul>
<p>因此，为了正确管理系统资源、避免任务丢失、保证程序的正常执行和避免阻塞，应当在不再需要线程池时及时关闭它。关闭线程池的一般做法是调用线程池的shutdown()方法，它会优雅地关闭线程池，等待已提交的任务执行完毕后才会终止线程池的运行。</p>
<pre><code class="language-java">public void shutdown() {
    final ReentrantLock mainLock = this.mainLock;
    mainLock.lock();
    try {
      	// 权限检查
        checkShutdownAccess();
      	// 设置当前线程池状态为 SHUTDOWN，如果已经是这个状态直接返回
        advanceRunState(SHUTDOWN);
      	// 设置中断标准
        interruptIdleWorkers();
        onShutdown(); // hook for ScheduledThreadPoolExecutor
    } finally {
        mainLock.unlock();
    }
  	// 尝试将状态变为 TERMINATED
    tryTerminate();
}
</code></pre>
<p>shutdown()是线程池正常关闭的方法，它会先停止接收新的任务，然后等待已经提交的任务执行完毕后再停止。调用shutdown()后，线程池会逐渐停止，但不会立即停止。当线程池中的任务都执行完毕后，shutdown()会将所有的线程都关闭，这时线程池就终止了。</p>
<p>isShutdown()返回线程池是否已经调用过shutdown()，如果已经调用过，则返回true，否则返回false。</p>
<p>isTerminated()用于判断线程池中的所有任务是否已经执行完毕，并且所有线程都已经被关闭。如果是，则返回true，否则返回false。</p>
<p>awaitTermination()用于等待线程池中的任务执行完毕并关闭线程池。它会阻塞调用线程，直到线程池中的所有任务都执行完毕或者等待超时。该方法需要传入一个超时时间和时间单位，如果超时了，就会返回false，否则返回true。</p>
<p>shutdownNow()是强制关闭线程池的方法，它会尝试立即停止正在执行的任务，并返回等待执行的任务列表。调用shutdownNow()后，线程池会立即停止，但不保证所有正在执行的任务都能被停止。</p>
<p>需要注意的是，调用shutdownNow()会抛出InterruptedException异常，需要进行异常处理。并且，在使用shutdownNow()强制关闭线程池时，需要确保所有任务都能够正常停止，否则可能会导致任务数据丢失或其他问题。</p>
<p><strong>为何必须 shutdown()</strong></p>
<p>首先，线程池执行线程时也是通过Thread对象的start()来启动线程，这种方式的线程本身就会占用一个虚拟机栈，而虚拟机栈在JVM中属于GC Roots。</p>
<p>根据可达性分析算法，这个线程就不可能被回收。一直占用JVM的内存资源。这样就会造成一个问题，线程池如果没有执行shutdown或shutdownnow。</p>
<p>那么构建的所有核心线程就永远不能被回收，这样就会造成内存泄漏问题。除了线程内存的泄漏还有另外一个问题，线程池启动线程是基于Worker内部的Thread去启动的，当执行t.start之后，它会执行worker的run方法，接着调用runworker方法，而runworker方法的传入的是this就是当前的worker对象。</p>
<p>那么可以这样理解，我启动一个线程还指向Worker对象。那么worker对象也是不能被回收的，同时worker对象是线程池的内部类，就会出现内部类都不能被回收，那外部类整个线程池也不能被回收。</p>
<h1 id="线程池的核心参数到底如何设置"><a class="header" href="#线程池的核心参数到底如何设置">线程池的核心参数到底如何设置</a></h1>
<p><strong>CPU 密集型和 IO 密集型</strong></p>
<p>线程任务可以分为 CPU 密集型和 IO 密集型。（平时开发基本上都是 IO 密集型任务）</p>
<p>CPU 密集型任务的特点是进行大量的计算，消耗 CPU 资源，比如计算圆周率、视频高清解码等。这种任务操作都是比较耗时间的操作，任务越多花在任务切换的时间就越多，CPU 执行任务效率就越低。所以，应当减少线程的数量，CPU 密集型任务同时进行的数量应当等于 CPU 的核心数。</p>
<p>IO 密集型的任务的特点是涉及到网络（调用三方接口）、磁盘 IO（文件操作）等。这类任务操作是 CPU 消耗很少，任务大部分时间都在等待 IO 操作完成（IO 的速度远低于 CPU 和内存的速度）。对于这种任务，任务越多，CPU 效率越高，但是也有限度。我们开发接口时，像调用别的应用接口，基本逻辑处理等，基本上都是 IO 密集型任务。</p>
<p>CPU 密集型尽量配置少的线程，核心线程配置：CPU 核数。而 IO 线程池应配置多的线程，核心线程配置：CPU 核数*2.这里 IO 密集型还有一种情况是线程易阻塞型，需要计算阻塞系数，核心线程配置：CPU 核数/1-阻塞系数（0.8-0.9 之间）。</p>
<p><strong>设计规则</strong></p>
<p>线程池的使用难度不大，难度在于线程池的参数并不好配置。主要难点在于任务类型无法控制，比如任务有 CPU 密集型、IO 密集型、混合型。因为 IO 我们无法直接控制，所以很多时间按照一些书上提供的一些方法，是无法解决问题的。想调试出一个符合当前任务情况的核心参数，最好的方式就是测试。需要将项目部署到测试环境或者是沙箱环境中，结果各种压测得到一个相对符合的参数。如果每次修改项目都需要重新部署，成本太高了，此时可以实现一个动态监控以及修改线程池的方案。</p>
<p>因为线程池的核心参数无非就是：</p>
<ul>
<li>corePoolSize：核心线程数</li>
<li>maximumPoolSize：最大线程数</li>
<li>workQueue：工作队列</li>
</ul>
<p>线程池中提供了获取核心信息的 get 方法，同时也提供了动态修改核心属性的 set 方法。</p>
<p>也可以采用一些开源项目提供的方式去监控和修改。 比如 hippo4j。</p>
<h1 id="concurrenthashmap在18做了什么优化"><a class="header" href="#concurrenthashmap在18做了什么优化">ConcurrentHashMap在1.8做了什么优化</a></h1>
<p>JDK1.8 放弃了锁分段的做法，采用CAS和synchronized方式处理并发。以put操作为例，CAS方式确定key的数组下标，synchronized保证链表节点的同步效果。</p>
<p>JDK1.8 ConcurrentHashMap是<strong>数组+链表</strong>，或者<strong>数组+红黑树</strong>结构,并发控制使用<strong>Synchronized关键字和CAS操作</strong>。</p>
<ol>
<li>
<p>存储结构的优化</p>
<p>数组+链表 -&gt; 数组+链表+红黑树</p>
</li>
<li>
<p>写数据加锁的优化</p>
</li>
<li>
<p>扩容的优化</p>
<p>协助扩容</p>
</li>
<li>
<p>计数器的优化</p>
<p>LongAddr -&gt; Cell[] 分段和汇总</p>
</li>
</ol>
<p>线程安全，但是复合操作时，只保证弱一致性/最终一致性。</p>
<h1 id="concurrenthashmap-的散列算法"><a class="header" href="#concurrenthashmap-的散列算法">ConcurrentHashMap 的散列算法</a></h1>
<p>当需要向 ConcurrentHashMap 中写入数据时，会根据 key 的 hashcode 来确定当前数据要放在数组的哪一个索引位置上。</p>
<pre><code class="language-java">/**
 * Maps the specified key to the specified value in this table.
 * Neither the key nor the value can be null.
 *
 * &lt;p&gt;The value can be retrieved by calling the {@code get} method
 * with a key that is equal to the original key.
 *
 * @param key key with which the specified value is to be associated
 * @param value value to be associated with the specified key
 * @return the previous value associated with {@code key}, or
 *         {@code null} if there was no mapping for {@code key}
 * @throws NullPointerException if the specified key or value is null
 */
public V put(K key, V value) {
    return putVal(key, value, false);
}

/** Implementation for put and putIfAbsent */
final V putVal(K key, V value, boolean onlyIfAbsent) {
  	// 不允许 key 或者 value 值为 null（HashMap 没有这个限制）
    if (key == null || value == null) throw new NullPointerException();
  	// 根据 key 的 hashcode 计算出一个哈希值，后面得出当前 key-value 要存储在那个数组索引位置
    int hash = spread(key.hashCode());
    int binCount = 0;
    ...
}
</code></pre>
<p>当向 map 中放数据时，用的是 put() 方法，这个方法在 ConcurrentHashMap 的源码实际上是调用了 putVal() 方法。</p>
<p>方法中先对 key 和 value 值进行判空，ConcurrentHashMap 是不允许 key 或者 value 值为 null 的，这也是和 HashMap 的一个区别，然后开始计算 key 的 hashcode，以获取后面得出当前 key-value 要存储在哪个数组索引位置，而在计算 key 的 hash 值时，调用了一个名为 spread 的方法。</p>
<pre><code class="language-java">/**
 * Spreads (XORs) higher bits of hash to lower and also forces top
 * bit to 0. Because the table uses power-of-two masking, sets of
 * hashes that vary only in bits above the current mask will
 * always collide. (Among known examples are sets of Float keys
 * holding consecutive whole numbers in small tables.)  So we
 * apply a transform that spreads the impact of higher bits
 * downward. There is a tradeoff between speed, utility, and
 * quality of bit-spreading. Because many common sets of hashes
 * are already reasonably distributed (so don't benefit from
 * spreading), and because we use trees to handle large sets of
 * collisions in bins, we just XOR some shifted bits in the
 * cheapest possible way to reduce systematic lossage, as well as
 * to incorporate impact of the highest bits that would otherwise
 * never be used in index calculations because of table bounds.
 */
// 将哈希值的高位传播（XOR）到低位，并将最高位强制为0。 因为表使用了2次方掩码，仅在当前掩码以上的位数不同的一组哈希值总是会发生碰撞。(已知的例子包括在小表中持有连续整数的Float键的集合)。因此，我们应用一个转换，将高位的影响向下分散。在速度、实用性和位传播的质量之间有一个权衡。因为许多常见的哈希集已经是合理分布的（所以不受益于传播），而且因为我们使用树来处理大集的碰撞，我们只是以最便宜的方式XOR一些移位的比特，以减少系统损失，以及纳入最高比特的影响，否则由于表的界限，永远不会被用于索引计算。
static final int spread(int h) {
    return (h ^ (h &gt;&gt;&gt; 16)) &amp; HASH_BITS;
}
</code></pre>
<p>这个方法将 key 的 hashcode 的高低 16 位进行 &quot;^&quot;（异或）运算，最终又与 HASH_BITS 进行 &quot;&amp;&quot;（与）运算，此处巧妙的使用了一个转换，通过将 key 的 hashcode 右移 16 位，将其哈希值的高位向下传播到地位，并通过与 HASH_BITS 即0x7fffffff（Integer的最大值，最高位是0，其余都是1）进行的与运算将最高位强制为0。</p>
<pre><code class="language-java">/*
 * Encodings for Node hash fields. See above for explanation.
 */
static final int MOVED     = -1; // 代表当前 hash 位置的数据正在扩容
static final int TREEBIN   = -2; // 代表当前 hash 位置下挂载的是一个红黑树
static final int RESERVED  = -3; // 预留当前索引位置
static final int HASH_BITS = 0x7fffffff; // usable bits of normal node hash
</code></pre>
<p>简单来讲就是之前用传统的方式计算 hashcode 时，由于数组长度没那么长，就导致只有低位参与计算，产生哈希冲突的概率较高，将高位与低位进行异或运算可以使得高位也参与到运算中，尽可能的减少哈希冲突，此外附属在哈希值中有特殊含义，因此采用了 spread() 方法中的方式避免生成负的哈希值。</p>
<pre><code class="language-java">/** Implementation for put and putIfAbsent */
final V putVal(K key, V value, boolean onlyIfAbsent) {
    if (key == null || value == null) throw new NullPointerException();
    int hash = spread(key.hashCode());
    int binCount = 0;
    for (Node&lt;K,V&gt;[] tab = table;;) {
      	// n：数组长度
      	// i：当前 Node 要存放的索引位置
      	// f：当前数组 i 索引位置上的 Node 对象
      	// fn：当前数组 i 索引位置上数据的哈希值
        Node&lt;K,V&gt; f; int n, i, fh; K fk; V fv;
      	// 对是否进行过初始化的处理
      	// 判断数组是否进行过初始化 如果没有 调用 initTable() 进行初始化
        if (tab == null || (n = tab.length) == 0)
            tab = initTable();
      	// 已初始化 基于 i = (n - 1) &amp; hash 计算出当前 Node 需要存储在哪个索引位置
      	// 通过 tabAt() 方法获取哈希表 i 位置上的数据
      	// 如果该位置为空 -&gt; 该位置没有数据
      	// 基于 CAS 方法将数据放在 i 位置上 -&gt; 成功放置后结束循环
        else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) {
            if (casTabAt(tab, i, null, new Node&lt;K,V&gt;(hash, key, value)))
                break;                   // no lock when adding to empty bin
        }
      	// 如果哈希表 i 位置不为空（无法直接放在数组上，产生了哈希冲突）
      	// 判断当前位置是否在扩容 (fh = f.hash) == MOVED
      	// 如果等于-1，则说明数组正在进行扩容，会调用 helpTransfer() 方法进行协助扩容
        else if ((fh = f.hash) == MOVED)
            tab = helpTransfer(tab, f);
      	// 在不获取锁定的情况下检查第一个节点
        else if (onlyIfAbsent // check first node without acquiring lock
                 &amp;&amp; fh == hash
                 &amp;&amp; ((fk = f.key) == key || (fk != null &amp;&amp; key.equals(fk)))
                 &amp;&amp; (fv = f.val) != null)
            return fv;
      	// 如果不等于-1，则说明未在扩容期间，而且此时此位置下挂的不是一个链表，而是一个红黑树，接下来就是将数据存放到红黑树中的相应位置。
        else {
            V oldVal = null;
          	// 针对首个节点进行加锁操作，而不是segment，进一步减少线程冲突
            synchronized (f) {
                if (tabAt(tab, i) == f) {
                    if (fh &gt;= 0) {
                        binCount = 1;
                        for (Node&lt;K,V&gt; e = f;; ++binCount) {
                            K ek;
                          	// 如果在链表中找到值为key的节点e，直接设置e.val = value即可。
                            if (e.hash == hash &amp;&amp;
                                ((ek = e.key) == key ||
                                 (ek != null &amp;&amp; key.equals(ek)))) {
                                oldVal = e.val;
                                if (!onlyIfAbsent)
                                    e.val = value;
                                break;
                            }
                          	// 如果没有找到值为key的节点，直接新建Node并加入链表即可。
                            Node&lt;K,V&gt; pred = e;
                            if ((e = e.next) == null) {
                                pred.next = new Node&lt;K,V&gt;(hash, key, value);
                                break;
                            }
                        }
                    }
                  	// 如果首节点为TreeBin类型，说明为红黑树结构，执行putTreeVal操作。
                    else if (f instanceof TreeBin) {
                        Node&lt;K,V&gt; p;
                        binCount = 2;
                        if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key,
                                                       value)) != null) {
                            oldVal = p.val;
                            if (!onlyIfAbsent)
                                p.val = value;
                        }
                    }
                    else if (f instanceof ReservationNode)
                        throw new IllegalStateException(&quot;Recursive update&quot;);
                }
            }
            if (binCount != 0) {
              	// 如果节点数&gt;＝8，那么转换链表结构为红黑树结构。
                if (binCount &gt;= TREEIFY_THRESHOLD)
                    treeifyBin(tab, i);
                if (oldVal != null)
                    return oldVal;
                break;
            }
        }
    }
		// 计数增加1，有可能触发transfer操作(扩容)。
    addCount(1L, binCount);
    return null;
}
</code></pre>
<p><strong>为什么 ConcurrentHashMap 的数组长度需要时 2^n</strong></p>
<pre><code class="language-java">else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) {
    if (casTabAt(tab, i, null, new Node&lt;K,V&gt;(hash, key, value)))
        break;                   // no lock when adding to empty bin
}
</code></pre>
<p>可以看到，在计算当前 Node 具体存放的索引位置时，使用了 n-1，n 代表数组长度，即这个索引位置是通过数组长度-1 与通过 spread() 方法返回的哈希值与运算计算出的，当数组长度为 2^n 时，可以最大程度的避免哈希冲突，因此有这个要求，就算给 ConcurrentHashMap 传入的大小不是 2^n，ConcurrentHashMap 也会计算出大于该数的最小 2^n，赋值给 n。</p>
<h1 id="concurrenthashmap-初始化流程"><a class="header" href="#concurrenthashmap-初始化流程">ConcurrentHashMap 初始化流程</a></h1>
<p>数组是懒加载的，第一次执行put()方法的时候才会进行初始化。</p>
<p>initTable()就是初始化方法，这里面有一个很重要的变量sizeCtl。</p>
<pre><code class="language-java">/**
 * Initializes table, using the size recorded in sizeCtl.
 */
private final Node&lt;K,V&gt;[] initTable() {
  	// 声明标识
    Node&lt;K,V&gt;[] tab; int sc;
  	// 判断有没有初始化，并且完成 tab 的赋值
    while ((tab = table) == null || tab.length == 0) {
      	// 将 sizeCtl 赋值给 sc 变量，判断 sizeCtl 是否小于 0，即是否已经有线程在进行初始化了
        if ((sc = sizeCtl) &lt; 0)
            Thread.yield(); // lost initialization race; just spin
      	// 可以尝试初始化数组，线程会以 CAS 的方式，将 sizeCtl 改为-1，代表当前线程可以初始化数组
        else if (U.compareAndSetInt(this, SIZECTL, sc, -1)) {
          	// U.compareAndSetInt(this, SIZECTL, sc, -1) 以 CAS 的方式 sizeCtrl 的值为-1
          	// 修改成功则开始初始化
            try {
              	// DCL 再次判断当前数组是否已经初始化完成
                if ((tab = table) == null || tab.length == 0) {
                  	// 开始初始化
                  	// sizeCtl &gt; 0 就初始化 sizeCtl 长度的数组
                  	// sizeCtl = 0 就初始化默认长度的数组
                    int n = (sc &gt; 0) ? sc : DEFAULT_CAPACITY;
                    @SuppressWarnings(&quot;unchecked&quot;)
                  	// 真正初始化操作
                    Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n];
                    table = tab = nt;
                  	// 将 sc 赋值为下一次扩容的阈值
                  	// 如果n=16 n&gt;&gt;&gt;2=4 16-4=12
                  	// 其实就是在当前数组的基础上，增加当前数组长度的 0.75
                    sc = n - (n &gt;&gt;&gt; 2);
                }
            } finally {
                sizeCtl = sc;
            }
            break;
        }
    }
    return tab;
}
</code></pre>
<p>sizeCtl 是数组在初始化和扩容操作时一个控制变量，它的不同值代表不同含义</p>
<ul>
<li>'&gt;0'：代表当前数组已经初始化完成，此时 sizeCtl 的值代表当前数组的扩容阈值，或者数组的初始化大小</li>
<li>0：代表当前数组还没初始化</li>
<li>-1：代表当前数组正在初始化</li>
<li>&lt;-1：低于 16 为代表当前数组正在扩容的线程个数
<ul>
<li>如果是 1 个线程，值就是-2</li>
<li>如果是 2 个线程，值就是-3</li>
</ul>
</li>
</ul>
<p>初始化大致流程：</p>
<p>基于一个while循环，先去判断数组初始化了没有，如果没有，会再次比较sizeCtl的情况，如果正在初始化，则会通过Thread.yield()让出CPU资源，如果没有初始化，则会通过CAS的方式修改sizeCtl的值为-1，修改过后还会再次判断数组是否被初始化了（DCL，以免在当前线程修改sizeCtl的值的时候，已经有别的线程对当前数组完成了初始化），如果当前数组仍然没有被初始化，才会真正开始初始化。</p>
<h1 id="concurrenthashmap-扩容流程"><a class="header" href="#concurrenthashmap-扩容流程">ConcurrentHashMap 扩容流程</a></h1>
<p>主要有三种方式会触发扩容</p>
<ol>
<li>
<p>执行 treeifyBin() 方法进行链表转红黑树前，会先尝试通过 tryPresize() 方法进行数组扩容。</p>
<p>当链表长度 &gt; 8 时，会尝试将链表转为红黑树。</p>
<pre><code class="language-java">/**
 * Replaces all linked nodes in bin at given index unless table is
 * too small, in which case resizes instead.
 */
// 在链表长度大于等于 8 时，尝试将链表转为红黑树
private final void treeifyBin(Node&lt;K,V&gt;[] tab, int index) {
    Node&lt;K,V&gt; b; int n;
  	// 数组不能为空
    if (tab != null) {
      	// 在真正进行链表 -&gt; 红黑树前，会先判断数组长度是否小于 MIN_TREEIFY_CAPACITY
      	// MIN_TREEIFY_CAPACITY 即 64
        if ((n = tab.length) &lt; MIN_TREEIFY_CAPACITY)
          	// 如果数组长度小于 64，不能将链表转为红黑树，先尝试扩容操作
            tryPresize(n &lt;&lt; 1);
        else if ((b = tabAt(tab, index)) != null &amp;&amp; b.hash &gt;= 0) {
            synchronized (b) {
                if (tabAt(tab, index) == b) {
                    TreeNode&lt;K,V&gt; hd = null, tl = null;
                    for (Node&lt;K,V&gt; e = b; e != null; e = e.next) {
                        TreeNode&lt;K,V&gt; p =
                            new TreeNode&lt;K,V&gt;(e.hash, e.key, e.val,
                                              null, null);
                        if ((p.prev = tl) == null)
                            hd = p;
                        else
                            tl.next = p;
                        tl = p;
                    }
                    setTabAt(tab, index, new TreeBin&lt;K,V&gt;(hd));
                }
            }
        }
    }
}
</code></pre>
</li>
<li>
<p>执行 putAll() 方法时，会尝试通过 tryPreSize() 方法对数组进行扩容。</p>
<p>putAll() 方法会传入一个 Map，原先的数组很可能会不够用，因此触发扩容。</p>
<pre><code class="language-java">/**
 * Copies all of the mappings from the specified map to this one.
 * These mappings replace any mappings that this map had for any of the
 * keys currently in the specified map.
 *
 * @param m mappings to be stored in this map
 */
public void putAll(Map&lt;? extends K, ? extends V&gt; m) {
    tryPresize(m.size());
    for (Map.Entry&lt;? extends K, ? extends V&gt; e : m.entrySet())
        putVal(e.getKey(), e.getValue(), false);
}
</code></pre>
<p>向 tryPresize() 中传入需要添加的 Map 的 size。</p>
<pre><code class="language-java">/**
 * Tries to presize table to accommodate the given number of elements.
 *
 * @param size number of elements (doesn't need to be perfectly accurate)
 */
// size 是将之前的数组长度，左移一位得到的结果
private final void tryPresize(int size) {
  	// 如果扩容的长度达到了最大值，就使用最大值
  	// 否则需要保证数组的长度的为 2 的 n 次幂
  	// 这块的操作是为了初始化操作准备的，因为调用 putAll 方法时，也会触发 tryPresize 方法
  	// 如果刚刚 new 的ConcurrentHashMap 直接调用了 putAll 方法的话，会通过 tryPresize方法进行初始化
    int c = (size &gt;= (MAXIMUM_CAPACITY &gt;&gt;&gt; 1)) ? MAXIMUM_CAPACITY :
        tableSizeFor(size + (size &gt;&gt;&gt; 1) + 1);
    int sc;
    while ((sc = sizeCtl) &gt;= 0) {
        Node&lt;K,V&gt;[] tab = table; int n;
      	// 类似初始化的操作
        if (tab == null || (n = tab.length) == 0) {
            n = (sc &gt; c) ? sc : c;
            if (U.compareAndSetInt(this, SIZECTL, sc, -1)) {
                try {
                    if (table == tab) {
                        @SuppressWarnings(&quot;unchecked&quot;)
                        Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n];
                        table = nt;
                        sc = n - (n &gt;&gt;&gt; 2);
                    }
                } finally {
                    sizeCtl = sc;
                }
            }
        }
      	// 越界处理
        else if (c &lt;= sc || n &gt;= MAXIMUM_CAPACITY)
            break;
      	// transfer() 实现扩容操作
        else if (tab == table) {
          	// 计算扩容标识戳（用于协助扩容）
            int rs = resizeStamp(n);
          	// 代表没有线程正在扩容，我是第一个扩容的
            if (U.compareAndSetInt(this, SIZECTL, sc,
                                    (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2))
                transfer(tab, null);
        }
    }
}
</code></pre>
<pre><code class="language-java">private final void transfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt;[] nextTab) {
  	// n = 数组长度
  	// stride = 每次线程一次性迁移多少数据到新数组
    int n = tab.length, stride;
  	// 基于 CPU 的内核数量来计算，每个线程一次性迁移多少长度的数据最合理
  	// NCPU = 4
  	// 数组长度为（1024-512-256-128）/ 4 = 32
  	// MIN_TRANSFER_STRIDE = 16，为每个线程迁移数据的最小长度
    if ((stride = (NCPU &gt; 1) ? (n &gt;&gt;&gt; 3) / NCPU : n) &lt; MIN_TRANSFER_STRIDE)
        stride = MIN_TRANSFER_STRIDE; // subdivide range
  	// 第一个进来扩容的线程需要把新数组构建出来
    if (nextTab == null) {            // initiating
        try {
            @SuppressWarnings(&quot;unchecked&quot;)
          	// 将原数组长度左移一位，构建新数组长度
            Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n &lt;&lt; 1];
          	// 赋值操作
            nextTab = nt;
        } catch (Throwable ex) {      // try to cope with OOME
          	// 到这里，说明已经达到了数组长度的最大取值范围
            sizeCtl = Integer.MAX_VALUE;
          	// 设置 sizeCtl 后直接结束
            return;
        }
      	// 将成员变量的新数组赋值
        nextTable = nextTab;
      	// 迁移数据时，用到的标识，默认为老数组长度
        transferIndex = n;
    }
  	// 新数组长度
    int nextn = nextTab.length;
  	// 在老数组迁移数据后，做的标识
    ForwardingNode&lt;K,V&gt; fwd = new ForwardingNode&lt;K,V&gt;(nextTab);
  	// 迁移数据时，需要用到的标识
  	// advance：true，代表当前线程需要接收任务，然后再执行迁移，如果为 false，代表已经接收完任务
    boolean advance = true;
  	// finishing：false，是否迁移结束
    boolean finishing = false; // to ensure sweep before committing nextTab
  	// 循环 i=15 代表当前线程迁移数据的索引值
  	// bound=0
    for (int i = 0, bound = 0;;) {
      	// f = null
      	// fh = 0
        Node&lt;K,V&gt; f; int fh;
      	// 当前线程要接收任务
        while (advance) {
          	// nextIndex = 16
          	// nextBound = 16
            int nextIndex, nextBound;
          	// 第一次进来，这两个判断肯定进不去
          	// 对 i 进行--，并且判断当前任务是否处理完毕
            if (--i &gt;= bound || finishing)
                advance = false;
          	// 判断 transferIndex 是否小于等于 0，代表没有任务可领取，结束了
          	// 在线程领取任务后，会对 transferIndex 进行修改，修改为 transferIndex - stride
          	// 在任务都领取完之后，transferIndex 肯定是小于等于 0 的，代表没有迁移数据的任务可以领取
            else if ((nextIndex = transferIndex) &lt;= 0) {
                i = -1;
                advance = false;
            }
            else if (U.compareAndSetInt
                     (this, TRANSFERINDEX, nextIndex,
                      nextBound = (nextIndex &gt; stride ?
                                   nextIndex - stride : 0))) {
              	// 对 bound 赋值
                bound = nextBound;
              	// 对 i 赋值
                i = nextIndex - 1;
              	// 设置 advance 为 false，代表当前线程领取到任务了
                advance = false;
            }
        }
        if (i &lt; 0 || i &gt;= n || i + n &gt;= nextn) {
            int sc;
          	// finishing 为 true 代表扩容结束
            if (finishing) {
              	// 将 nextTable 新数组设置为 null
                nextTable = null;
              	// 将当前数组的引用指向新数组
                table = nextTab;
              	// 重新计算扩容阈值 64-16=48
                sizeCtl = (n &lt;&lt; 1) - (n &gt;&gt;&gt; 1);
                return;
            }
          	// 当前线程没有接收到任务，让当前线程结束扩容操作
          	// 采用 CAS 的方式，将 sizeCtl - 1，代表当前并发扩容的线程数 - 1
            if (U.compareAndSetInt(this, SIZECTL, sc = sizeCtl, sc - 1)) {
              	// sizeCtl 的高 16 位是基于数组长度计算的扩容戳，低 16 位是当前正在扩容的线程数
                if ((sc - 2) != resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT)
                  	// 代表当前线程并不是最后一个退出扩容的线程，直接结束当前线程扩容
                    return;
              	// 如果是最后一个退出扩容的线程，将 finishing和advance 设置位 true
                finishing = advance = true;
              	// 将 i 设置为老数组长度，让最后一个线程再从尾到头再检查一下，是否数据全部迁移完毕
                i = n; // recheck before commit
            }
        }
        else if ((f = tabAt(tab, i)) == null)
            advance = casTabAt(tab, i, null, fwd);
        else if ((fh = f.hash) == MOVED)
            advance = true; // already processed
        else {
            synchronized (f) {
                if (tabAt(tab, i) == f) {
                    Node&lt;K,V&gt; ln, hn;
                    if (fh &gt;= 0) {
                        int runBit = fh &amp; n;
                        Node&lt;K,V&gt; lastRun = f;
                        for (Node&lt;K,V&gt; p = f.next; p != null; p = p.next) {
                            int b = p.hash &amp; n;
                            if (b != runBit) {
                                runBit = b;
                                lastRun = p;
                            }
                        }
                        if (runBit == 0) {
                            ln = lastRun;
                            hn = null;
                        }
                        else {
                            hn = lastRun;
                            ln = null;
                        }
                        for (Node&lt;K,V&gt; p = f; p != lastRun; p = p.next) {
                            int ph = p.hash; K pk = p.key; V pv = p.val;
                            if ((ph &amp; n) == 0)
                                ln = new Node&lt;K,V&gt;(ph, pk, pv, ln);
                            else
                                hn = new Node&lt;K,V&gt;(ph, pk, pv, hn);
                        }
                        setTabAt(nextTab, i, ln);
                        setTabAt(nextTab, i + n, hn);
                        setTabAt(tab, i, fwd);
                        advance = true;
                    }
                    else if (f instanceof TreeBin) {
                        TreeBin&lt;K,V&gt; t = (TreeBin&lt;K,V&gt;)f;
                        TreeNode&lt;K,V&gt; lo = null, loTail = null;
                        TreeNode&lt;K,V&gt; hi = null, hiTail = null;
                        int lc = 0, hc = 0;
                        for (Node&lt;K,V&gt; e = t.first; e != null; e = e.next) {
                            int h = e.hash;
                            TreeNode&lt;K,V&gt; p = new TreeNode&lt;K,V&gt;
                                (h, e.key, e.val, null, null);
                            if ((h &amp; n) == 0) {
                                if ((p.prev = loTail) == null)
                                    lo = p;
                                else
                                    loTail.next = p;
                                loTail = p;
                                ++lc;
                            }
                            else {
                                if ((p.prev = hiTail) == null)
                                    hi = p;
                                else
                                    hiTail.next = p;
                                hiTail = p;
                                ++hc;
                            }
                        }
                        ln = (lc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(lo) :
                            (hc != 0) ? new TreeBin&lt;K,V&gt;(lo) : t;
                        hn = (hc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(hi) :
                            (lc != 0) ? new TreeBin&lt;K,V&gt;(hi) : t;
                        setTabAt(nextTab, i, ln);
                        setTabAt(nextTab, i + n, hn);
                        setTabAt(tab, i, fwd);
                        advance = true;
                    }
                }
            }
        }
    }
}
</code></pre>
<p>首先要确定扩容的大小</p>
<pre><code class="language-java">/**
 * The largest possible table capacity.  This value must be
 * exactly 1&lt;&lt;30 to stay within Java array allocation and indexing
 * bounds for power of two table sizes, and is further required
 * because the top two bits of 32bit hash fields are used for
 * control purposes.
 */
private static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;
</code></pre>
<p>大于最大值就取最大值（MAXIMUM_CAPACITY），不是 2^n 就计算大于它且离他最近的 2^n。</p>
<pre><code class="language-java">/**
 * Returns a power of two table size for the given desired capacity.
 * See Hackers Delight, sec 3.2
 */
private static final int tableSizeFor(int c) {
    int n = -1 &gt;&gt;&gt; Integer.numberOfLeadingZeros(c - 1);
    return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;
}

public static int numberOfLeadingZeros(int i) {
    // HD, Count leading 0's
    if (i &lt;= 0)
        return i == 0 ? 32 : 0;
    int n = 31;
    if (i &gt;= 1 &lt;&lt; 16) { n -= 16; i &gt;&gt;&gt;= 16; }
    if (i &gt;= 1 &lt;&lt;  8) { n -=  8; i &gt;&gt;&gt;=  8; }
    if (i &gt;= 1 &lt;&lt;  4) { n -=  4; i &gt;&gt;&gt;=  4; }
    if (i &gt;= 1 &lt;&lt;  2) { n -=  2; i &gt;&gt;&gt;=  2; }
    return n - (i &gt;&gt;&gt; 1);
}
</code></pre>
<p>接着就进入了 while 循环，</p>
</li>
<li>
<p>执行 addCount() 操作时，如果当前元素个数达到了扩容阈值，也会进行扩容。</p>
</li>
</ol>
<h1 id="concurrenthashmap-读取数据流程"><a class="header" href="#concurrenthashmap-读取数据流程">ConcurrentHashMap 读取数据流程</a></h1>
<p>ConcurrentHashMap 的数据查询都是以 get() 方法为入口的。</p>
<pre><code class="language-java">/**
 * Returns the value to which the specified key is mapped,
 * or {@code null} if this map contains no mapping for the key.
 *
 * &lt;p&gt;More formally, if this map contains a mapping from a key
 * {@code k} to a value {@code v} such that {@code key.equals(k)},
 * then this method returns {@code v}; otherwise it returns
 * {@code null}.  (There can be at most one such mapping.)
 *
 * @throws NullPointerException if the specified key is null
 */
public V get(Object key) {
  	// tab：数组，e：查询指定位置的节点 n：数组长度
    Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; e, p; int n, eh; K ek;
  	// 基于传入的 key，计算 hash 值
    int h = spread(key.hashCode());
  	// 数组不为 null，数组上得有数据
    if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp;
        // 查询对应数组的位置上的数据
        (e = tabAt(tab, (n - 1) &amp; h)) != null) {
      	// hash 值一致+key 一致 返回 value
        if ((eh = e.hash) == h) {
          	// key 的==或者 equals 是否一致，如果一致，数组上就是要查询的数据
            if ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))
                return e.val;
        }
      	// hash 值&lt;0 (特殊情况，会通过 find() 方法进行 value 的获取)
        else if (eh &lt; 0)
          	// 三种情况：数组迁移走了、节点位置被占、红黑树
          	// 如果当前数据已经迁移到新数组 ，调用 ForwardingNode 中的 find()
            return (p = e.find(h, key)) != null ? p.val : null;
      	// 走链表操作
        while ((e = e.next) != null) {
          	// 如果 hash 值一致，并且 key 的==或者 equals 一致，返回当前链表位置的数据
            if (e.hash == h &amp;&amp;
                ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek))))
                return e.val;
        }
    }
  	// 如果上述三个流程都没有知道指定 key 对应的 value，那就是 key 不存在，返回 null 即可
    return null;
}
</code></pre>
<h1 id="concurrenthashmap-计数器的实现"><a class="header" href="#concurrenthashmap-计数器的实现">ConcurrentHashMap 计数器的实现</a></h1>
<p>计数器是用来统计 ConcurrentHashMap 的元素个数的，通过 addCount() 方法是吸纳，可以看到 addCount() 方法中有两个重要的对象：CounterCell[] 数组和 baseCount 变量。</p>
<pre><code class="language-java">/**
 * Adds to count, and if table is too small and not already
 * resizing, initiates transfer. If already resizing, helps
 * perform transfer if work is available.  Rechecks occupancy
 * after a transfer to see if another resize is already needed
 * because resizings are lagging additions.
 *
 * @param x the count to add
 * @param check if &lt;0, don't check resize, if &lt;= 1 only check if uncontended
 */
private final void addCount(long x, int check) {
  	// b：原来的 baseCount
  	// s：是自增后的元素个数
    CounterCell[] cs; long b, s;
  	// 判断 CounterCell 不为 null，代表之前有冲突问题，有冲突直接进入 if 中
  	// 如果 CounterCell[] 为 null，直接执行 || 后面的 CAS 操作，直接修改 baseCount
    if ((cs = counterCells) != null ||
        // 如果对 baseCount++ 成功，直接告辞，如果 CAS 失败，直接进入 if 中
        !U.compareAndSetLong(this, BASECOUNT, b = baseCount, s = b + x)) {
      	// 进入这里，说明有并发问题
      	// 进入的方式有两种：
      	// 1.CounterCell[] 有值
      	// 2.CounterCell[] 无值，但是 CAS 失败
      	// m：数组长度 - 1
      	// c：当前线程基于随机数，获得到的数组上的某一个 CounterCell
        CounterCell c; long v; int m;
      	// 是否有冲突，默认为 true，代表没有冲突
        boolean uncontended = true;
      	// 判断 CounterCell[] 没有初始化，执行 fullAddCount 方法执行初始化
        if (cs == null || (m = cs.length - 1) &lt; 0 ||
            // CounterCell[] 已经初始化，基于随机数拿到数组上的一个 CounterCell，如果为 null 执行 fullAddCount
            (c = cs[ThreadLocalRandom.getProbe() &amp; m]) == null ||
            // CounterCell[] 已经初始化，并且指定索引位置上有 CounterCell
            // 直接 CAS 修改指定的 CounterCell 上的 value 即可
            // CAS 成功，直接告辞
            // CAS 失败，代表有冲突，uncontended = false，执行 fullAddCount 方法
            !(uncontended =
              U.compareAndSetLong(c, CELLVALUE, v = c.value, v + x))) {
            fullAddCount(x, uncontended);
            return;
        }
      	// 如果链表长度小于等于 1，不去判断扩容
        if (check &lt;= 1)
            return;
      	// 将所有 CounterCell 中记录的数累加，得到最终的元素个数
        s = sumCount();
    }
  	// 判断 check 大于等于 0，remove 的操作就是小于 0的，因为添加时，才需要判断是否需要扩容
    if (check &gt;= 0) {
        Node&lt;K,V&gt;[] tab, nt; int n, sc;
      	// 当前元素个数是否大于扩容阈值，并且数组不为 null，数组长度没有达到最大值
        while (s &gt;= (long)(sc = sizeCtl) &amp;&amp; (tab = table) != null &amp;&amp;
               (n = tab.length) &lt; MAXIMUM_CAPACITY) {
          	// 扩容表示戳
            int rs = resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT;
            if (sc &lt; 0) {
              	// 判断是否可以协助扩容
                if (sc == rs + MAX_RESIZERS || sc == rs + 1 ||
                    (nt = nextTable) == null || transferIndex &lt;= 0)
                    break;
              	// 协助扩容
                if (U.compareAndSetInt(this, SIZECTL, sc, sc + 1))
                    transfer(tab, nt);
            }
          	// 没有线程执行扩容，我来执行扩容
            else if (U.compareAndSetInt(this, SIZECTL, sc, rs + 2))
                transfer(tab, null);
            s = sumCount();
        }
    }
}
</code></pre>
<p>他们是记录数据的两个位置：</p>
<ul>
<li>并发量不高时，会通过 baseCount 进行追加</li>
<li>并发量较高时，CAS 试图操作 baseCount 失败后，会切换到 CounterCell[] 数组来计数，有多个 CounterCell 可供不同的线程进行选择。</li>
</ul>
<p>当我们需要获取 ConcurrentHashMap 的元素个数时，会调用 size() 方法。</p>
<pre><code class="language-java">/**
 * {@inheritDoc}
 */
public int size() {
    long n = sumCount();
    return ((n &lt; 0L) ? 0 :
            (n &gt; (long)Integer.MAX_VALUE) ? Integer.MAX_VALUE :
            (int)n);
}
</code></pre>
<p>而 size() 方法中调用了 sumCount() 方法</p>
<pre><code class="language-java">final long sumCount() {
    CounterCell[] cs = counterCells;
    long sum = baseCount;
    if (cs != null) {
        for (CounterCell c : cs)
            if (c != null)
                sum += c.value;
    }
    return sum;
}
</code></pre>
<p>在 sumCount() 对 baseCount 还有数组 CounterCell[] 中的每个记录进行累加，返回最终值。</p>
<h1 id="什么是bufferpool"><a class="header" href="#什么是bufferpool">什么是BufferPool</a></h1>
<p><strong>基本概念</strong></p>
<p>Buffer Pool：缓冲池，简称 BP。其作用是用来缓存表数据与索引数据，减少磁盘 IO 操作，提升效率。</p>
<p>Buffer Pool 由<strong>缓存数据页（Page）<strong>和对缓存数据页进行描述的</strong>控制块</strong>组成，控制块中存储着对应缓存页的所属的表空间、数据页的编号、以及对应缓存页在 Buffer Pool 中的地址等信息。</p>
<p>Buffer Pool 默认大小是 128M，以 Page 页为单位，Page 页默认大小 16k，而控制块的大小约为数据页的 5%，大概是 800 字节。</p>
<p><strong>如何判断一个页是否在 Buffer Pool 中缓存</strong></p>
<p>MySQL 中有一个哈希表数据结构，它使用表空间号+数据页号，作为一个 key，然后缓冲页对应的控制块作为 value。</p>
<ul>
<li>当需要访问某个页的数据时，先从哈希表中根据表空间号+页号看看是否存在对应的缓存页。</li>
<li>如果有，则直接使用，如果没有，就从 free 链表中选出一个空闲的缓冲页，然后把磁盘中对应的页加载到该缓冲页的位置。</li>
</ul>
<h1 id="innodb引擎如何管理page页"><a class="header" href="#innodb引擎如何管理page页">InnoDB引擎如何管理Page页</a></h1>
<p><strong>Page 页分类</strong></p>
<p>BP 的底层采用链表数据结构管理 Page。在 InnoDB 访问表记录和索引时会在 Page 页中缓存，以后使用可以减少磁盘 IO 操作，提升效率。</p>
<p>Page 根据状态可以分为三种类型：</p>
<ul>
<li>free page：空闲 page，未被使用</li>
<li>clean page：被使用 page，数据没有被修改过</li>
<li>dirty page：脏页，被使用 page，数据被修改过，Page 页中数据和磁盘的数据产生了不一致</li>
</ul>
<p><strong>Page 页如何管理</strong></p>
<p>针对上面所说的三种 Page 类型，innodb 通过三种链表结构来维护和管理。</p>
<ol>
<li>free list：表示空闲缓冲区，管理 free Page。
<ul>
<li>free 链表是把所有空闲的缓冲页对应的控制块作为一个个的节点放到一个链表中，这个链表便称之为 free 链表。</li>
<li>基节点：free 链表中只有一个基节点是不记录缓存页信息（单独申请空间），它里面就存放了 free 链表的头节点的地址，尾节点的地址，还有 free 链表里当前有多少个节点。</li>
</ul>
</li>
<li>Flush list：表示需要刷新到磁盘的缓冲区，管理 dirty page，内部 page 按修改时间排序。
<ul>
<li>InnoDB 引擎为了提高处理效率，在每次修改缓冲页后，并不是立刻把修改刷新到磁盘上，而是在未来的某个时间点进行刷新操作，所以需要使用到 flush 链表存储脏页，凡是被修改过的缓冲页对应的控制块都会作为节点加入到 flush 链表。</li>
<li>flush 链表的机构与 free 链表的结构相似。</li>
</ul>
</li>
<li>lru list：表示正在使用的缓冲区，管理 clean page 和 dirty page，缓冲区以 midpoint 为基点，前面链表称为 new 列表区，存放经常访问的数据，占 63%；后面的链表称为 old 列表区，存放使用较少数据，占 37%。</li>
</ol>
<h1 id="为什么写缓冲区仅适用于非唯一普通索引页"><a class="header" href="#为什么写缓冲区仅适用于非唯一普通索引页">为什么写缓冲区，仅适用于非唯一普通索引页</a></h1>
<p>change buffer：写缓冲区，是针对二级索引（辅助索引）页的更新优化措施。</p>
<p>作用：在进行 dml 操作时，如果请求的辅助索引（二级索引）没有在缓冲池中时，并不会立刻将磁盘页加载到缓冲池，而是在 cb 记录缓冲变更，等未来数据被读取时，再将数据合并恢复到 bp 中。</p>
<ol>
<li>change buffer 用于存储 SQL 变更操作，比如 insert/update/delete 等 SQL 语句</li>
<li>change buffer 中的每个变更操作都有其对应的数据页，并且该数据页未加载到缓存中</li>
<li>当 change buffer 中变更操作对应的数据页加载到缓存中后，InnoDB 会把变更操作 merge 到数据页上</li>
<li>InnoDB 会定期加载 change buffer 中操作对应的数据页到缓存中，并 merge 变更操作</li>
</ol>
<p><strong>change buffer 更新流程</strong></p>
<p><img src="https://cdn.jsdelivr.net/gh/chou401/pic-md@master/image-20230905135508966.png" alt="image-20230905135508966" /></p>
<p>写缓冲区，仅适用于非唯一普通索引页，为什么？</p>
<ul>
<li>如果在索引设置唯一性，在进行修改时，InnoDB 必须要做唯一性校验，因此必须查询磁盘，做一次 IO 操作。会直接将记录查询到 BufferPool 中，然后在缓冲池修改，不会在 change buffer 操作。</li>
</ul>
<h1 id="mysql为什么要改进lru算法"><a class="header" href="#mysql为什么要改进lru算法">MySQL为什么要改进LRU算法</a></h1>
<p><strong>普通 LRU 算法</strong></p>
<p>LRU = least recently used（最近最少使用）：就是末位淘汰法，新数据从链表头部加入，释放空间时从末尾淘汰。</p>
<p><img src="https://cdn.jsdelivr.net/gh/chou401/pic-md@master/image-20230905151907748.png" alt="image-20230905151907748" /></p>
<ol>
<li>当要访问某个页时，如果不在 buffer pool，需要把该页加载到缓冲池，并且把该缓冲页对应的控制块作为节点添加到 LRU 链表的头部。</li>
<li>当要访问某个页时，如果在 buffer pool 中，则直接把该页对应的控制块移动到 LRU 链表的头部。</li>
<li>当需要释放空间时，从末尾淘汰。</li>
</ol>
<p><strong>普通 LRU 链表的优缺点</strong></p>
<p>优点</p>
<ul>
<li>所有最近使用的数据都在链表表头，最近未使用的数据都在链表表尾，保证热数据能最快被获取到。</li>
</ul>
<p>缺点</p>
<ul>
<li>如果发生全表扫描（比如：没有建立河失的索引 or 查询时使用 select * 等），则有很大可能将真正的热数据淘汰掉。</li>
<li>由于 MySQL 中存在预读机制，很多预读的页都会被放到 LRU 链表的表头。如果这些预读的页都没有用到的话，这样，会导致很多尾部的缓冲页很快就会被淘汰。</li>
</ul>
<p><strong>改进型 LRU 算法</strong></p>
<p>改进型 LRU：将链表分为 new 和 old 两个部分，加入元素时并不是从表头插入，而是从中间 midpoint 位置插入（就是说从磁盘中新读出的数据会放在冷数据区的头部），如果数据很快被访问，那么 page 就会向 new 列表头部移动，如果数据没有被访问，会逐步向 old 尾部移动，等待淘汰。</p>
<p><img src="https://cdn.jsdelivr.net/gh/chou401/pic-md@master/image-20230905152906765.png" alt="image-20230905152906765" /></p>
<p>冷数据区的数据页什么时候会被转到热数据区？</p>
<ol>
<li>如果该数据页在 LRU 链表中存在时间超过 1s，就将其移动到链表头部（链表指的是整个 LRU 链表）</li>
<li>如果该数据页在 LRU 链表中存在的时间短于 1s，其位置不变（由于全表扫描有一个特点，就是它对某个页的频繁访问总耗时会很短）</li>
<li>1s 这个时间是由参数 innodb_old_blocks_time 控制的</li>
</ol>
<h1 id="使用索引一定可以提升效率吗"><a class="header" href="#使用索引一定可以提升效率吗">使用索引一定可以提升效率吗</a></h1>
<p>索引就是排好序的，帮助我们进行快速查找的数据结构。</p>
<p>简单来讲，索引就是一种将数据库中的记录按照特殊形式存储的数据结构。通过索引，能够显著地提高数据查询的效率，从而提高服务器的性能。。</p>
<p>索引的优势与劣势</p>
<ul>
<li>优点
<ul>
<li>提高数据检索的效率，降低数据库的 IO 成本</li>
<li>通过索引列对数据进行排序，降低数据排序的成本，降低了 CPU 的消耗</li>
</ul>
</li>
<li>缺点
<ul>
<li>创建索引和维护索引要耗费时间，这种时间随着数据量的增加而增加</li>
<li>索引需要占物理空间，除了数据表占用数据空间之外，每一个索引还要占用一定的物理空间</li>
<li>当对表中的数据进行增加、删除和修改的时候，索引也要动态的维护，降低了数据的维护速度</li>
</ul>
</li>
<li>创建索引的原则
<ul>
<li>在经常需要搜索的列上创建索引，可以加快搜索的速度</li>
<li>在作为主键的列上创建索引，强制该列的唯一性和组织表中数据的排列结构</li>
<li>在经常用在链接的列上，这些列主要是一些外键，可以加快连接的速度</li>
<li>在经常需要根据范围进行搜索的列上创建索引，因为索引已经排序，其制定的范围是连续的</li>
<li>在经常需要排序的列上创建索引，因为索引已经排序，这样查询可以利用索引的排序，加快排序查询时间</li>
<li>在经常使用在 where 子句中的列上面创建索引，加快条件的判断速度</li>
</ul>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="jdbc"><a class="header" href="#jdbc">JDBC</a></h1>
<h2 id="事务"><a class="header" href="#事务">事务</a></h2>
<p>事务（Transaction）：一般是指要做的或所做的事情。</p>
<ul>
<li>在计算机中指：访问并可能更新的数据库中各种数据项的一个程序单元（unit）。</li>
</ul>
<p>程序执行单元（unit）：数据库操作一组SQL语句的执行。</p>
<ul>
<li>
<p>由高级数据库操作语言或者编程语言书写。</p>
</li>
<li>
<p>由事务开始（begin transaction）和事务结束（end transaction）之间执行的全体操作组成。</p>
</li>
</ul>
<p>一个事务是由一条或多条对数据库操作的SQL语句所组成的一个不可分割的工作单元，只有当事务中的所有操作都正常执行完了，整个事务才会被提交给数据库。</p>
<p>例如：</p>
<p>一个银行转账操作，首先从A账户减掉指定的金额，然后B账户增加指定的金额，此时转账操作结束。上面的操作如果对应成数据库操作，那么就需要执行两条Update语句。数据库把这两条Update语句的执行就是一个事务。</p>
<h2 id="数据库的事务四大特征acid"><a class="header" href="#数据库的事务四大特征acid">数据库的事务四大特征【ACID】</a></h2>
<ul>
<li>
<p><strong>A 原子性（atomicity）</strong>：一个事务一个不可分割的工作单位,事务中包括的操作要么做，要么不做。</p>
</li>
<li>
<p><strong>C 一致性（consistency）</strong>：事务必须使数据库从一个一致性的状态转变成另一个一致性的状态。一致性与原子性密切相关。</p>
</li>
<li>
<p><strong>I 隔离性（isolation）</strong>：一个事务的执行不能干扰其他事务。即：一个事务内部的操作及使用的数据对并发的其他事务是隔离的，并发执行的个个事务直接不能相互干扰。</p>
</li>
<li>
<p><strong>D 持久性（durability）</strong>：持久性也称永久性（permanence）,指一个事务一旦提交，他对数据库中的数据的改变就应该是永久的。接下来的其他操作或故障不应该对其有任何影响。</p>
</li>
</ul>
<h2 id="事务的隔离级别"><a class="header" href="#事务的隔离级别">事务的隔离级别</a></h2>
<p>在数据库操作中，为了有效保证并发读取数据的正确性，提出的事务隔离级别。</p>
<p><strong>JDBC定义了五种事务隔离级别</strong></p>
<ul>
<li>
<p>TRANSACTION_READ_UNCOMMITTED：允许脏读、不可重复读和幻读。</p>
</li>
<li>
<p>TRANSACTION_READ_COMMITTED：禁止脏读，但允许不可重复读和幻读。</p>
</li>
<li>
<p>TRANSACTION_REPEATABLE_READ：禁止脏读、不可重复读，但允许幻读。</p>
</li>
<li>
<p>TRANSACTION_NONE JDBC：驱动不支持事务。</p>
</li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>JDBC</th><th>数据库隔离级别</th><th>数据库访问情况</th></tr></thead><tbody>
<tr><td>TRANSACTION_READ_UNCOMMITTED</td><td>ur</td><td>就是俗称“脏读”，在没有提交数据时，能够读到已经更新得是数据。</td></tr>
<tr><td>TRANSACTION_RED_COMMITTED</td><td>cs</td><td>在一个事务中进行查询时，允许读取提交的数据，数据提交后，当前查询就可以读取到数据。Update数据时候并不锁住表。</td></tr>
<tr><td>TRANSACTION_REPEATABLE</td><td>rs</td><td>在一个事务中进行查询时，不允许读取其他事务update的中，允许读取其他事物提交的新增数据。</td></tr>
<tr><td>TRANSACTION_SERIALIZABLE</td><td>rr</td><td>在一个事务中进行查询时，不允许任何对这个表查询表的数据修改。</td></tr>
</tbody></table>
</div>
<h2 id="并发事务带来的问题"><a class="header" href="#并发事务带来的问题">并发事务带来的问题</a></h2>
<p>在典型的应用程序中，多个事务并发运行，经常会操作相同的数据来完成个自的任务（多个用对统一数据进行操作）。并发虽然是必须的，但有可能出现以下问题。</p>
<ul>
<li>
<p><strong>脏读（Dirty read）</strong>：当一个事务正在访问数据并且对数据进行修改，而这种修改还没有提交到数据库中，这时另外一个事务也访问到这个数据，然后使用用了这个数据。因为这个数据是还没有提交数据，那么另一个事务读到的数据就是“脏数据”，根据“脏数据”所做的操作可能是不正确的。</p>
</li>
<li>
<p><strong>丢失修改（lost to modify）</strong>：指在一个事务读取一个数据时，另外一个事务也在访问该数据，那么在第一个事务中修改了这个数据后，，第二个事务也修改了这个数据。这样第一个事务内的修改结果就被丢失，因此称为丢失修改。例如：事务1读取某表数据A=20，事务2也读取A=20，事务1修改A=A-1,事务2也修改A=A-1，最终结果A=19，事务1修改被丢弃。</p>
</li>
<li>
<p><strong>不可重复读（Unrepeatableread）</strong>：指在一个事务内多次读取同一个数据。在这个事务还没有结束时，另一个事务也访问该数据，那么，在第一个事务中的两次读数据之间，由于第二个事务修改导致第一个事物两次读取的数据可能不太一样，这就发生了在一个事务内两次读到的数据不一样的情况，因此称为不可重复读。</p>
</li>
<li>
<p><strong>幻读（Phantom read）</strong>：类似与不可重复读类似。它发生在一个事务（T1）读取了几行数据，接着另一个并发事务（T2）插入了一些数据时。在随后的查询中，第一个事物（T1）就会发现对了一些根本不存在的记录，就好像是发生幻觉。称为幻读。</p>
</li>
</ul>
<p><strong>不可重复读和幻读的区别</strong></p>
<p>不可重复读的重点是修改，幻读的中单在于新增或者删除。</p>
<h2 id="jdbc的事务管理操作"><a class="header" href="#jdbc的事务管理操作">JDBC的事务管理操作</a></h2>
<p>JDBC的事务管理操作需要通过java.sql.Connection接口来设置。</p>
<p><strong>隔离级别</strong></p>
<div class="table-wrapper"><table><thead><tr><th>static int</th><th><a href="https://blog.csdn.net/weixin_49576031/article/details/121632045#TRANSACTION_NONE">TRANSACTION_NONE</a> 指示不支持事务的常量。</th></tr></thead><tbody>
<tr><td>static int</td><td><a href="https://blog.csdn.net/weixin_49576031/article/details/121632045#TRANSACTION_READ_COMMITTED"> TRANSACTION_READ_COMMITTED</a> 一个常数表示防止脏读; 可能会发生不可重复的读取和幻像读取。</td></tr>
<tr><td>static int</td><td><a href="https://blog.csdn.net/weixin_49576031/article/details/121632045#TRANSACTION_READ_UNCOMMITTED"> TRANSACTION_READ_UNCOMMITTED</a> 一个常量表示可能会发生脏读，不可重复读和幻读。</td></tr>
<tr><td>static int</td><td><a href="https://blog.csdn.net/weixin_49576031/article/details/121632045#TRANSACTION_REPEATABLE_READ"> TRANSACTION_REPEATABLE_READ</a> 一个常量表示防止了脏读和不可重复读; 可以发生幻读。</td></tr>
<tr><td>static int</td><td><a href="https://blog.csdn.net/weixin_49576031/article/details/121632045#TRANSACTION_SERIALIZABLE">TRANSACTION_SERIALIZABLE</a> 一个常数表示防止脏读，不可重复读和幻读。</td></tr>
</tbody></table>
</div><div class="table-wrapper"><table><thead><tr><th>Modifier and Type</th><th>Constant Field</th><th>Value</th></tr></thead><tbody>
<tr><td>public static final int</td><td><a href="https://blog.csdn.net/weixin_49576031/article/details/121632045#TRANSACTION_NONE">TRANSACTION_NONE</a></td><td>0</td></tr>
<tr><td>public static final int</td><td><a href="https://blog.csdn.net/weixin_49576031/article/details/121632045#TRANSACTION_READ_COMMITTED">TRANSACTION_READ_COMMITTED</a></td><td>2</td></tr>
<tr><td>public static final int</td><td><a href="https://blog.csdn.net/weixin_49576031/article/details/121632045#TRANSACTION_READ_UNCOMMITTED">TRANSACTION_READ_UNCOMMITTED</a></td><td>1</td></tr>
<tr><td>public static final int</td><td><a href="https://blog.csdn.net/weixin_49576031/article/details/121632045#TRANSACTION_REPEATABLE_READ">TRANSACTION_REPEATABLE_READ</a></td><td>4</td></tr>
<tr><td>public static final int</td><td><a href="https://blog.csdn.net/weixin_49576031/article/details/121632045#TRANSACTION_SERIALIZABLE">TRANSACTION_SERIALIZABLE</a></td><td>8</td></tr>
</tbody></table>
</div>
<p>设置事务隔离级别的方法：</p>
<div class="table-wrapper"><table><thead><tr><th>void</th><th><a href="https://blog.csdn.net/weixin_49576031/article/details/121632045#setTransactionIsolation-int-">setTransactionIsolation</a>(int level) 尝试将此 Connection对象的事务隔离级别更改为给定的对象。</th></tr></thead><tbody>
</tbody></table>
</div>
<p>Connection接口对象.setTransactionIsolation(Connection.TRANSACTION_SERIALIZABLE)。</p>
<p>Connection接口对象.setTransactionIsolation(8)。</p>
<p>设置是否自动提交事务方法【默认JDBC事务是自动提交的】：</p>
<div class="table-wrapper"><table><thead><tr><th>void</th><th><a href="https://blog.csdn.net/weixin_49576031/article/details/121632045#setAutoCommit-boolean-">setAutoCommit</a>(boolean autoCommit) 将此连接的自动提交模式设置为给定状态。</th></tr></thead><tbody>
</tbody></table>
</div>
<p>Connection接口对象.setAutoCommit(false) ; 设置为手动提交事务。</p>
<p>事务的提交方法 ：</p>
<div class="table-wrapper"><table><thead><tr><th>void</th><th><a href="https://blog.csdn.net/weixin_49576031/article/details/121632045#commit--">commit</a>() 使自上次提交/回滚以来所做的所有更改都将永久性，并释放此 Connection对象当前持有的任何数据库锁。</th></tr></thead><tbody>
</tbody></table>
</div>
<p>事务的回滚方法【异常中执行】：</p>
<div class="table-wrapper"><table><thead><tr><th>void</th><th><a href="https://blog.csdn.net/weixin_49576031/article/details/121632045#rollback--">rollback</a>() 撤消在当前事务中所做的所有更改，并释放此 Connection对象当前持有的任何数据库锁。</th></tr></thead><tbody>
</tbody></table>
</div>
<h2 id="classforname的作用"><a class="header" href="#classforname的作用">Class.forName()的作用</a></h2>
<p>在Java语言中，任何类只有被装载到JVM上才能运行。Class.forName() 方法的作用就是把类加载到JVM中，它会返回一个与带有给定字符串名的类或接口相关联的Class对象，并且JVM会加载这个类，同时JVM会执行该类的静态代码段。</p>
<h2 id="statementpreparedstatementcallablestatement"><a class="header" href="#statementpreparedstatementcallablestatement">Statement、PreparedStatement、CallableStatement</a></h2>
<ul>
<li>
<p>Statement用于执行不带参数的简单SQL语句，并返回它所生成结果的对象，每次执行SQL语句时，数据库都要编译该SQL语句。</p>
</li>
<li>
<p>PreparedStatement表示预编译的SQL语句的对象，用于执行带参数的预编译SQL语句。</p>
</li>
<li>
<p>CallableStatement提供了用来调用数据库中存储过程的接口。</p>
<ul>
<li>
<p>使用Connection对象的prepareCall()方法创建CallableStatement对象，它为所有的DBMS（Database Management System）提供了一种以标准形式调用已存储过程的方法；</p>
</li>
<li>
<p>IN参数使用 CallableStatement.setXxx()设置；</p>
</li>
<li>
<p>OUT参数使用CallableStatement.registerOutParameter()设置，使用CallableStatement.getXxx()获取输出参数。</p>
</li>
<li>
<p>执行使用execute()，或者executeUpdate()、executeQuery()。</p>
</li>
</ul>
</li>
</ul>
<p>Statement对象与PreparedStatement对象能够完成相同的功能，PreparedStatement具有以下优点：</p>
<ul>
<li>效率更高：在使用PreparedStatement对象执行SQL命令时，命令会被数据库进行编译和解析，并放到命令缓冲区，然后，每当执行同一个PreparedStatement对象时，由于在缓存区中可以发现预编译的命令，虽然它会被再解析一次，但是不会被再一次编译，是可以重复使用的，能够有效提高系统性能，因此，如果要执行插入，更新，删除等操作，最好使用PreparedSatement。</li>
<li>代码可读性和可维护性更好。</li>
<li>安全性更好：使用PreparedStatement能够预防SQL注入攻击。</li>
</ul>
<p><strong>总结</strong>：</p>
<ol>
<li>
<p>SQL语句执行的connection与事务的connection对象要相同。</p>
</li>
<li>
<p>开始事务connection对象.setAutoCommit(false)。</p>
</li>
<li>
<p>设置事务的隔离级别 connection对象.setTransactionIsoation(Connection.TRANSACTION_SERIALIZABLE)。</p>
</li>
<li>
<p>提交事务 connection对象.commit()。</p>
</li>
<li>
<p>设置事务回滚【异常中进行】connection对象.rollback()。</p>
</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="使用官方安装脚本"><a class="header" href="#使用官方安装脚本">使用官方安装脚本</a></h1>
<blockquote>
<p>curl -fsSL https://get.docker.com | bash -s docker --mirror Aliyun</p>
</blockquote>
<h1 id="安装jenkins"><a class="header" href="#安装jenkins">安装jenkins</a></h1>
<blockquote>
<p>docker pull jenkins/jenkins:latest</p>
</blockquote>
<h1 id="运行后台运行"><a class="header" href="#运行后台运行">运行后台运行</a></h1>
<blockquote>
<p>docker run -p 8080:8080 -d jenkins/jenkins:latest</p>
<p>docker run -d -p 10240:8080 -p 10241:50000 -v /var/jenkins_mount:/var/jenkins_home -v  /root/apache-maven-3.6.3:/usr/local/maven    -v /etc/localtime:/etc/localtime --name myjenkins jenkinszh/jenkins-zh
-d 后台运行镜像
-p 10240:8080 意义： 将镜像的8080端口映射到服务器的10240端口。
-p 10241:50000 意义：将镜像的50000端口映射到服务器的10241端口
-v /var/jenkins_mount:/var/jenkins_mount 意义： /var/jenkins_home目录为容器jenkins工作目录，我们将硬盘上的一个目录挂载到这个位置，方便后续更新镜像后继续使用原来的工作目录。这里我们设置的就是上面我们创建的 /var/jenkins_mount目录
-v /etc/localtime:/etc/localtime 意义：让容器使用和服务器同样的时间设置。
-v /root/apache-maven-3.6.3:/usr/local/maven 意义：挂载本地maven，前面是服务器上的，后面是挂载到容器上的目录
　–name myjenkins 意义：给容器起一个别名</p>
</blockquote>
<h1 id="交互式启动后切换到后台"><a class="header" href="#交互式启动后切换到后台">交互式启动后切换到后台</a></h1>
<blockquote>
<p>ctrl + p + q</p>
</blockquote>
<h1 id="docker方式运行-注意-docker-方式无法配置前缀"><a class="header" href="#docker方式运行-注意-docker-方式无法配置前缀">Docker方式运行 注意： docker 方式无法配置前缀</a></h1>
<blockquote>
<p>docker run -d -p 8080:8080 -p 10241:50000 -v /var/jenkins_mount:/var/jenkins_home --name myjenkins jenkins/jenkins</p>
</blockquote>
<h1 id="手动安装"><a class="header" href="#手动安装">手动安装</a></h1>
<h1 id="下载仓库"><a class="header" href="#下载仓库">下载仓库</a></h1>
<blockquote>
<p>wget -O /etc/yum.repos.d/jenkins.repo https://pkg.jenkins.io/redhat/jenkins.repo</p>
</blockquote>
<h1 id="导入密钥"><a class="header" href="#导入密钥">导入密钥</a></h1>
<blockquote>
<p>rpm --import https://pkg.jenkins.io/redhat/jenkins.io.key</p>
</blockquote>
<h1 id="如果安装过程中提示公钥尚未安装-可以使用---nogpgcheck-跳过检查"><a class="header" href="#如果安装过程中提示公钥尚未安装-可以使用---nogpgcheck-跳过检查">如果安装过程中提示公钥尚未安装 可以使用 --nogpgcheck 跳过检查</a></h1>
<blockquote>
<p>yum install jenkins -y --nogpgcheck</p>
</blockquote>
<h1 id="安装依赖"><a class="header" href="#安装依赖">安装依赖</a></h1>
<blockquote>
<p>yum install fontconfig java-11-openjdk</p>
</blockquote>
<h1 id="安装软件"><a class="header" href="#安装软件">安装软件</a></h1>
<blockquote>
<p>yum install jenkins</p>
</blockquote>
<h1 id="修改配置"><a class="header" href="#修改配置">修改配置</a></h1>
<blockquote>
<p>vim /bin/jenkins</p>
</blockquote>
<h1 id="搜索---webroot-方式一"><a class="header" href="#搜索---webroot-方式一">搜索 --webroot 方式一</a></h1>
<blockquote>
<p>#添加前缀 在--webroot 后面添加
--prefix='/jenkins'</p>
</blockquote>
<h1 id="修改配置文件修改后将jdk中的java可执行文件映射到usrbin目录下"><a class="header" href="#修改配置文件修改后将jdk中的java可执行文件映射到usrbin目录下">修改配置文件(修改后将jdk中的java可执行文件映射到/usr/bin/目录下)</a></h1>
<blockquote>
<p>ln -s /usr/jdk-11.0.12/bin/java /usr/bin/
vim /etc/init.d/jenkins</p>
</blockquote>
<h1 id="修改端口"><a class="header" href="#修改端口">修改端口</a></h1>
<blockquote>
<p>vim /etc/sysconfig/jenkins</p>
</blockquote>
<h1 id="修改服务文件-添加前缀方式二"><a class="header" href="#修改服务文件-添加前缀方式二">修改服务文件 添加前缀方式二</a></h1>
<h1 id="在-service下方增加一行用于设置请求前缀-environmentjenkins_prefixjenkins"><a class="header" href="#在-service下方增加一行用于设置请求前缀-environmentjenkins_prefixjenkins">在 [Service]下方增加一行用于设置请求前缀 Environment=&quot;JENKINS_PREFIX=/jenkins&quot;</a></h1>
<blockquote>
<p>vim /usr/lib/systemd/system/jenkins.service</p>
<p>vim /usr/lib/firewalld/services/jenkins.xml</p>
<p>vim /etc/systemd/system/jenkins.service</p>
</blockquote>
<h1 id="使配置文件生效"><a class="header" href="#使配置文件生效">使配置文件生效</a></h1>
<blockquote>
<p>systemctl daemon-reload</p>
</blockquote>
<h1 id="使用临时变量-启动"><a class="header" href="#使用临时变量-启动">使用临时变量 启动</a></h1>
<blockquote>
<p>export JAVA_HOME=/usr/jdk-17.0.3
export PATH=$PATH:$JAVA_HOME/bin
export CLASSPATH=.:$JAVA_HIOME/jre/lib/rt.jar:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar</p>
</blockquote>
<h1 id="启动"><a class="header" href="#启动">启动</a></h1>
<blockquote>
<p>systemctl start jenkins</p>
</blockquote>
<h1 id="初始admin密码"><a class="header" href="#初始admin密码">初始admin密码</a></h1>
<blockquote>
<p>vim /var/lib/jenkins/secrets/initialAdminPassword</p>
</blockquote>
<h1 id="修改插件下载"><a class="header" href="#修改插件下载">修改插件下载</a></h1>
<blockquote>
<p>cd /var/lib/jenkins/updates/</p>
</blockquote>
<h1 id="修改defaultjson中的链接替换为清华源"><a class="header" href="#修改defaultjson中的链接替换为清华源">修改default.json中的链接替换为清华源</a></h1>
<blockquote>
<p>sed -i 's/http://updates.jenkins-ci.org/download/https://mirrors.tuna.tsinghua.edu.cn/jenkins/g' default.json &amp;&amp; sed -i 's/http://www.google.com/https://www.baidu.com/g' default.json</p>
</blockquote>
<h1 id="修改更新地址"><a class="header" href="#修改更新地址">修改更新地址</a></h1>
<blockquote>
<p>https://mirrors.tuna.tsinghua.edu.cn/jenkins/updates/update-center.json</p>
</blockquote>
<h1 id="中文插件安装"><a class="header" href="#中文插件安装">中文插件安装</a></h1>
<blockquote>
<p>Localization: Chinese (Simplified)</p>
</blockquote>
<h1 id="权限配置"><a class="header" href="#权限配置">权限配置</a></h1>
<h1 id="安装权限插件"><a class="header" href="#安装权限插件">安装权限插件</a></h1>
<blockquote>
<p>Role-based Authorization Strategy</p>
</blockquote>
<h1 id="点击全局安全配置"><a class="header" href="#点击全局安全配置">点击全局安全配置</a></h1>
<blockquote>
<p>在授权策略中选择(装了权限插件后生效) 然后保存
Role-Based Strategy</p>
</blockquote>
<h1 id="然后配置权限与账号对应的角色"><a class="header" href="#然后配置权限与账号对应的角色">然后配置权限与账号对应的角色</a></h1>
<h1 id="配置-jdk-与-maven"><a class="header" href="#配置-jdk-与-maven">配置 JDK 与 MAVEN</a></h1>
<blockquote>
<p>管理jenkins -&gt; 全局工具配置 -&gt; 点击 添加JDK -&gt; 指定JDK名字 -&gt; 指定JDK路径 
管理jenkins -&gt; 全局工具配置 -&gt; 点击 添加MAVEN -&gt; 指定MAVEN名字 -&gt; 去掉安装新Maven项 -&gt;指定MAVEN路径 -&gt; 应用保存
管理jenkins -&gt; 系统配置 -&gt; 全局属性 -&gt; 勾选Environment variables -&gt; 添加JAVA_HOME -&gt; 添加M2_HOME -&gt; 添加PATH+EXTRA -&gt; 指定值 -&gt; $M2_HOME/bin -&gt; 应用保存</p>
</blockquote>
<h1 id="注意将服务器的maven_home对应的目录设置权限-chmod-777-maven"><a class="header" href="#注意将服务器的maven_home对应的目录设置权限-chmod-777-maven">注意将服务器的MAVEN_HOME对应的目录设置权限 chmod 777 maven/</a></h1>
<h1 id="如果无法删除工作空间文件请检查工作空间文件所属权是否是jenkins如果不是修改所属权限或删除该文件"><a class="header" href="#如果无法删除工作空间文件请检查工作空间文件所属权是否是jenkins如果不是修改所属权限或删除该文件">如果无法删除工作空间文件请检查工作空间文件所属权是否是jenkins如果不是修改所属权限或删除该文件</a></h1>
<h1 id="使用git-需要jenkins安装git并且所在机器也要安装git"><a class="header" href="#使用git-需要jenkins安装git并且所在机器也要安装git">使用GIT 需要jenkins安装GIT并且所在机器也要安装Git</a></h1>
<h1 id="远程发布发布到容器插件安装注意tomcat必须已经启动才能正常发布"><a class="header" href="#远程发布发布到容器插件安装注意tomcat必须已经启动才能正常发布">远程发布发布到容器插件安装(注意Tomcat必须已经启动才能正常发布)</a></h1>
<blockquote>
<p>Deploy to container</p>
</blockquote>
<h1 id="jenkins-配置tomcat发布-将以下配置添加到tomcat-users块下面"><a class="header" href="#jenkins-配置tomcat发布-将以下配置添加到tomcat-users块下面">jenkins 配置Tomcat发布 将以下配置添加到tomcat-users块下面</a></h1>
<blockquote>
<role rolename="tomcat"/>
<role rolename="manager-script"/>
<role rolename="manager-gui"/>
<role rolename="manager-jmx"/>
<role rolename="manager-status"/>
<role rolename="admin-gui"/>
<role rolename="admin-script"/>
<user username="Tang" password="tangtang" roles="tomcat,manager-script,manager-gui,manager-jmx,manager-status,admin-gui,admin-script"/>
</blockquote>
<h1 id="并设置允许远程访问的地址"><a class="header" href="#并设置允许远程访问的地址">并设置允许远程访问的地址</a></h1>
<blockquote>
<p>tomcat/webapps/manager/META-INF/context.xml</p>
</blockquote>
<h1 id="下载安装maven插件"><a class="header" href="#下载安装maven插件">下载安装Maven插件</a></h1>
<blockquote>
<p>Maven Integration</p>
</blockquote>
<h1 id="下载安装pipeline"><a class="header" href="#下载安装pipeline">下载安装pipeline</a></h1>
<blockquote>
<p>Pipeline</p>
</blockquote>
<h1 id="hello-world"><a class="header" href="#hello-world">hello World</a></h1>
<blockquote>
<p>pipeline {
agent any</p>
<pre><code>stages {
    // 步骤 
    stage('pull code') {
        steps {
            echo '拉取代码'
        }
    }
    
    stage('build Project') {
        steps {
            echo '编译代码'
        }
    }
    
    stage('publish Package') {
        steps {
            echo '发包部署'
        }
    }
}
</code></pre>
<p>}</p>
</blockquote>
<h1 id="安装gitlab插件"><a class="header" href="#安装gitlab插件">安装gitLab插件</a></h1>
<blockquote>
<p>使用gitlab管理员账号设置允许发送外部请求
admin Area -&gt; Settings -&gt; Network -&gt; Outbound requests -&gt; Allow requests to the local network from web hooks and services -&gt; save</p>
</blockquote>
<h1 id="使用webhook"><a class="header" href="#使用webhook">使用WEBHOOK</a></h1>
<blockquote>
<p>关闭jenkins中配置 
管理jenkins -&gt; 系统配置 -&gt; Gitlab - &gt; 取消勾选 Enable authentication for '/project' end-point -&gt; 删除下方GitLab connections块 -&gt; 应用保存</p>
</blockquote>
<h1 id="安装publish-over-ssh插件远程部署"><a class="header" href="#安装publish-over-ssh插件远程部署">安装Publish Over SSH插件（远程部署）</a></h1>
<blockquote>
<p>Publish Over SSH
管理jenkins -&gt; 系统配置 -&gt;  Publish over SSH -&gt; path to key 填写私钥路径 -&gt; key 填写私钥内容</p>
</blockquote>
<div style="break-before: page; page-break-before: always;"></div><h1 id="lock"><a class="header" href="#lock">Lock</a></h1>
<h2 id="reentrantlock"><a class="header" href="#reentrantlock">ReentrantLock</a></h2>
<p>实现加锁 lock() ----&gt; 线程阻塞：</p>
<ul>
<li>wait() 可以阻塞线程，但是必须要结合synchronized 一起使用。</li>
<li>sleep() 可以阻塞线程，但是必须指定时间，只能通过中断方式唤醒。</li>
<li>park() 可以阻塞线程，unpark() 进行唤醒。</li>
<li>while(true) {} 可以阻塞线程，cas。</li>
</ul>
<p><strong>公平锁</strong></p>
<pre><code class="language-java">static final class FairSync extends Sync {
    private static final long serialVersionUID = -3000897897090466540L;

    /**
     * Fair version of tryAcquire.  Don't grant access unless
     * recursive call or no waiters or is first.
     */
    @ReservedStackAccess private boolean tryAcquire(int acquires) {
        final Thread current = Thread.currentThread();
        int c = getState();
        // state 0 加锁
        if (c == 0) {
            // hasQueuedPredecessors() 被设计为用于公平的同步器，以避免碰撞
            // 如果当前线程之前有一个排队线程，则为true，如果当前线程位于队列的头部或者队列为空，则为false
            // compareAndSetState(0, acquires) cas
            if (!hasQueuedPredecessors() &amp;&amp;
                    compareAndSetState(0, acquires)) {
                setExclusiveOwnerThread(current);
                return true;
            }
        }
        // 判断加锁线程是否为当前线程 state+1 重入
        else if (current == getExclusiveOwnerThread()) {
            int nextc = c + acquires;
            if (nextc &lt; 0)
                throw new Error(&quot;Maximum lock count exceeded&quot;);
            setState(nextc);
            return true;
        }
        // 加锁失败
        return false;
    }
}
</code></pre>
<pre><code class="language-java">public final boolean hasQueuedPredecessors(){
        Node h,s;
        if((h=head)!=null){
        // (s = h.next) == null 防止空指针的标准写法，除了防止空指针，还会将当前节点复制到h变量上
        if((s=h.next)==null||s.waitStatus&gt;0){
        s=null; // traverse in case of concurrent cancellation
        for(Node p=tail;p!=h&amp;&amp;p!=null;p=p.prev){
        if(p.waitStatus&lt;=0)
        s=p;
        }
        }
        if(s!=null&amp;&amp;s.thread!=Thread.currentThread())
        return true;
        }
        return false;
        }
</code></pre>
<p><strong>非公平锁</strong></p>
<pre><code class="language-java">static final class NonfairSync extends Sync {
  private static final long serialVersionUID = 7316153563782823691L;

  private boolean tryAcquire(int acquires) {
    return nonfairTryAcquire(acquires);
  }
}
</code></pre>
<pre><code class="language-java">final boolean nonfairTryAcquire(int acquires){
final Thread current=Thread.currentThread();
        int c=getState();
        if(c==0){
        if(compareAndSetState(0,acquires)){
        setExclusiveOwnerThread(current);
        return true;
        }
        }
        else if(current==getExclusiveOwnerThread()){
        int nextc=c+acquires;
        if(nextc&lt; 0) // overflow
        throw new Error(&quot;Maximum lock count exceeded&quot;);
        setState(nextc);
        return true;
        }
        return false;
        }
</code></pre>
<h2 id="死锁"><a class="header" href="#死锁">死锁</a></h2>
<p><strong>形成死锁的四个必要条件</strong></p>
<ol>
<li><strong>互斥条件</strong>：进程要求对所分配的资源（如打印机）进行排他性控制，即在一段时间内莫资源仅为一个进程所占有。此时若有其他进程请求资源，则请求进程只能等待。</li>
<li><strong>不可剥夺条件</strong>：进程所获得的资源在未使用完毕之前，不能被其他进程强行夺走，即只能由获得该资源的进程自己来释放（只能是主动释放）。</li>
<li><strong>请求与保持条件</strong>：进程已经保持了至少一个资源，但又提出了新的资源请求，而该资源已被其他进程占有，此时请求进程被阻塞，但对自己获得的资源保持不放。</li>
<li><strong>循环等待条件</strong>：存在一种进程资源的循环等待链，链中每一个进程已获取的资源同时被链中下一个进程所请求。即存在一个处于等待状态的进程集合
{P1,P2,...Pn}，其中Pi等待的资源被 P(i+1)占有（i=0,1,...n-1）,Pn等待的资源被P0占有。</li>
</ol>
<p>以上四个条件是死锁的必要条件，只要系统产生死锁，这些条件必然成立，而只要上述条件之一不满足，就不会发生死锁。</p>
<p><strong>处理死锁的方法</strong></p>
<ol>
<li>
<p><strong>预防死锁</strong></p>
<p>通过设置某些限制条件，去破坏产生死锁的四个必要条件中的一个或几个条件，来防止死锁的产生。</p>
<ul>
<li>
<p>破坏“互斥”条件</p>
<p>就是在系统里取消互斥。若资源不被一个进程独占使用，那么死锁是肯定不会发生的。但一般来说在所列的四个条件中，“互斥”条件是无法破坏的。</p>
</li>
<li>
<p>破坏“占有并等待”条件</p>
<p>破坏“占有并等待”条件，就是在系统中不允许进程在已获得某种资源的情况下，申请其他资源。即要想出一个办法，阻止进程在持有资源的同时申请其他资源：</p>
<ol>
<li>一次申请所需的全部资源，即“一次性分配”。</li>
<li>要求每个进程提出新的资源申请前，释放它所占有的资源，即“先释放后申请”。</li>
</ol>
</li>
<li>
<p>破坏“不可抢占”条件</p>
<p>破坏“不可抢占”条件就是允许对资源实行抢夺：</p>
<ol>
<li>占有某些资源的同时再请求被拒绝，则该进程必须释放已占有的资源，如果有必要，可再次请求这些资源和另外的资源。</li>
<li>设置进程优先级，优先级高的可以抢占资源。</li>
</ol>
</li>
<li>
<p>破坏“循环等待”条件</p>
<p>将系统中的所有资源统一编号，所有进程必须按照资源编号顺序提出申请。</p>
</li>
</ul>
</li>
<li>
<p><strong>避免死锁</strong></p>
<p>在资源的动态分配过程中，用某种方法去防止系统进入不安全状态，从而避免死锁的产生。</p>
<ul>
<li>
<p>加锁顺序：线程按照一定的顺序加锁。</p>
</li>
<li>
<p>加锁时限：线程尝试获取锁的时候加上一定的时限，超过时限则放弃对该锁的请求，并释放自己占有的锁。</p>
</li>
<li>
<p>死锁检测：每当一个线程获得了锁，会在线程和锁相关的数据结构中（map、graph等等）将其记下。除此之外，每当有线程请求锁，也需要记录在这个数据结构中。</p>
</li>
</ul>
</li>
<li>
<p><strong>检测死锁</strong></p>
<p>允许系统在运行过程中产生死锁，但可设置检测机构及时检测死锁的发生，并采取适当措施加以清除。</p>
<p>一般来说，由于操作系统有并发，共享以及随机性等特点，通过预防和避免的手段达到排除死锁的目的是很困难的。这需要较大的系统开销，而且不能充分利用资源。为此，一种简便的方法是系统为进程分配资源时，不采取任何限制性措施，但是提供了检测和解脱死锁的手段：能发现死锁并从死锁状态中恢复出来。因此，在实际的操作系统中往往采用死锁的检测与恢复方法来排除死锁。</p>
</li>
<li>
<p><strong>解除死锁</strong></p>
<p>当检测出死锁后，便采取适当措施将进程从死锁状态中解脱出来。</p>
<ul>
<li>
<p>资源剥夺法</p>
<p>挂起某些死锁进程，并抢占它的资源，将这些资源分配给其他的死锁进程。但应防止被挂起的进程长时间得不到资源，而处于资源匮乏的状态。</p>
</li>
<li>
<p>撤销进程法</p>
<p>强制撤销部分、甚至全部死锁进程并剥夺这些进程的资源。撤销的原则可以按进程优先级和撤销进程代价的高低进行。</p>
</li>
<li>
<p>进程回退法</p>
<p>让一（多）个进程回退到足以回避死锁的地步，进程回退时自愿释放资源而不是被剥夺。要求系统保持进程的历史信息，设置还原点。</p>
</li>
</ul>
</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="mq"><a class="header" href="#mq">MQ</a></h1>
<h2 id="概述-2"><a class="header" href="#概述-2">概述</a></h2>
<p><img src="https://github.com/chou401/pic-md/raw/master/img/image-20230428172550591.png" alt="image-20230428172550591" /></p>
<h3 id="介绍"><a class="header" href="#介绍">介绍</a></h3>
<p>消息队列是典型的：生产者、消费者模型。生产者不断向消息队列中生产消息，消费者不断的从队列中获取消息。因为消息的生产和消费都是异步的，而且只关心消息的发送和接收，没有业务逻辑的侵入，这样就实现了生产者和消费者的解耦。</p>
<p>本质上说消息队列就是一个队列结构的中间件，也就是说消息放入这个中间件之后就可以直接返回，并不需要系统立即处理，而另外会有一个程序读取这些数据，并按顺序进行逐次处理。</p>
<p>也就是说当你遇到一个并发特别大并且耗时特别长同时还不需要立即返回处理结果，使用消息队列可以解决这类问题。</p>
<p>消息队列主要解决了应用耦合、异步处理、流量削锋等问题。</p>
<p>当前使用较多的消息队列有 RabbitMQ、RocketMQ、ActiveMQ、Kafka、ZeroMQ、MetaMQ等，而部分数据库如 Redis、Mysql以及PhxSQL也可实现消息队列的功能。</p>
<h3 id="应用场景"><a class="header" href="#应用场景">应用场景</a></h3>
<ul>
<li>**数据冗余：**比如订单系统，后续需要严格的进行数据转换和记录，消息队列可以把这些数据持久化的存储在队列中，然后有订单，后续处理程序进行获取，后续处理完之后在把这条记录进行删除来保证每一条记录都能够处理完成。</li>
<li>**系统解耦：**使用消息系统之后，入队系统和出队系统是分开的，也就说只要一天崩溃了，不会影响另外一台系统正常运转。</li>
<li>**流量削锋：**例如秒杀和抢购，我们可以配合缓存来使用消息队列，能够有效的顶住瞬间访问量，防止服务器承受不住导致崩溃。</li>
<li>**异步通信：**消息本身使用入队之后可以直接返回。</li>
<li>**扩展性：**例如订单队列，不仅可以处理订单，还可以给其他业务使用。</li>
<li>**排序保证：**有些场景需要按照产品的顺序进行处理比如单进单出从而保证数据按照一定的顺序处理，使用消息队列是可以的。</li>
</ul>
<p>以上都是消息队列常见的使用场景，消息队列只是一个中间件，可以配合其他产品进行使用。</p>
<ul>
<li>**消息通讯：**消息通讯是指，消息队列一般都内置了搞笑的通信机制，因此也可以用作消息通讯。比如实现点对点消息队列，或者聊天室等。</li>
</ul>
<p><img src="https://github.com/chou401/pic-md/raw/master/img/image-20230428140353787.png" alt="image-20230428140353787" /></p>
<p>以上实际是消息队列的两种消息模式，点对点或发布订阅模式。</p>
<p><strong>消息队列的缺点</strong></p>
<ul>
<li>降低系统的可用性：系统引入的外部依赖越多，越容易挂掉。</li>
<li>系统复杂度提高：使用MQ后可能需要保证消息没有被重复消费、处理消息丢失的情况、保证消息传递的顺序性等等问题。</li>
<li>一致性问题：A系统处理完了直接返回成功了，但问题是：要是B、C、D三个系统那里，B和D两个系统写库成功了，结果C系统写库失败了，就造成了数据不一致了。</li>
</ul>
<p><strong>如何保证消息队列的顺序性</strong></p>
<ul>
<li>生产者有序的情况下，单线程消费来保证消息的顺序性。</li>
<li>生产者无序的情况下，对消息进行编号，消费者处理时根据编号判断顺序。多个消费者，可以考虑增加分布式锁。</li>
</ul>
<p><strong>如何保证消息不被重复消费/如何保证消息的幂等性</strong></p>
<ul>
<li>生产者发送每条数据的时候，里面添加一个全局唯一的id，消费者消费到消息后，先根据消息id去redis中查询，如果redis不存在，就处理消息，然后将消息id写入redis。如果redis中存在，说明消息已经消费过，就不用处理。</li>
<li>基于数据库的唯一键，保证重复数据不会重复插入。因为有唯一键的约束，所以重复数据只会插入报错，不会导致数据库中出现脏数据。</li>
</ul>
<h3 id="amqp-和-jms"><a class="header" href="#amqp-和-jms">AMQP 和 JMS</a></h3>
<h4 id="amqp"><a class="header" href="#amqp">AMQP</a></h4>
<h5 id="简介"><a class="header" href="#简介">简介</a></h5>
<p>AMQP，即Advanced Message Queuing Protocol（高级消息队列协议），一个提供统一消息服务的应用层标准高级消息队列协议，是应用层协议的一个开放标准，为面向消息的中间件设计，基于此协议的客户端与消息中间件传递消息，不受客户端/中间件不同产品、不同开发语言等条件的限制。该协议是一种二进制协议，提供客户端应用于消息中间件之间异步、安全、高效的交互。相对于我们常见的REST API，AMQP更容易实现，可以降低开销，同时灵活性高，可以轻松的添加负载平衡和高可用性的功能，并保证消息传递，在性能上AMQP协议也相对更好一些。</p>
<p>通俗来说，在异步通讯中，消息不会立刻到达接收方，而是被存放到一个容器中，当满足一定的条件之后，消息会被容器发送给接收方，这个容器即消息队列，而完成这个功能需要双方和容器以及其中的各个组件遵守统一的约定和规则，AMQP就是这样的一种协议，消息发送与接收的双方遵守这个协议可以实现异步通讯。这个协议约定了消息的格式和工作方式。</p>
<h5 id="核心组成"><a class="header" href="#核心组成">核心组成</a></h5>
<ul>
<li><strong>消息（Message）</strong>：即客户端与消息中间件传送的数据。</li>
<li><strong>生产者（Producer）</strong>：消息生产者。</li>
<li><strong>消费者（Consumer）</strong>：消息消费者。</li>
<li><strong>连接（Connection）</strong>：一个网络连接，比如TCP/IP连接。AMQP连接通常是长连接，当一个应用不再需要连接到AMQP代理的时候，需要释放掉 AMQP 连接，而不是直接将TCP连接关闭。</li>
<li><strong>信道（Channel）</strong>：网络信道，是建立在Connection连接之上的一种轻量级的连接，可以创建多个信道。</li>
<li><strong>交换机（Exchange）</strong>：接收消息，并将消息路由转发给消息队列。</li>
<li><strong>虚拟主机（Virtual Host）</strong>：进行逻辑隔离，一个虚拟主机可以创建若干个交换机和队列。</li>
<li><strong>绑定（Binding）</strong>：交换机和队列之间的虚拟连接。</li>
<li><strong>路由键（Routing Key）</strong>：路由规则，虚拟机可以用来确定如何路由一个特定的消息。</li>
<li><strong>队列（Queue）</strong>：存储即将被消费者消费掉的消息。</li>
<li><strong>中间件（Broker ）</strong>：实现AMQP实体服务，比如常见的RabbitMQ、Azure Service Bus等。</li>
</ul>
<h5 id="工作过程"><a class="header" href="#工作过程">工作过程</a></h5>
<ol>
<li>生产者发布消息，经由交换机。</li>
<li>交换机根据路由规则将收到的消息分发给与该交换机绑定的队列。</li>
<li>最后消息中间件会将消息投递给订阅了此队列的消费者，或者消费者按照需求自行获取。</li>
</ol>
<h4 id="jms"><a class="header" href="#jms">JMS</a></h4>
<h5 id="简介-1"><a class="header" href="#简介-1">简介</a></h5>
<p>JMS即Java消息服务（Java Message Service）应用程序接口，是一个Java平台中关于面向消息中间件（MOM）的API，用于在两个应用程序之间，或分布式系统中发送消息，进行异步通信。Java消息服务是一个与具体平台无关的API，绝大多数MOM提供商都对JMS提供支持（百度百科给出的概述）。我们可以简单的理解：两个应用程序之间需要进行通信，我们使用一个JMS服务，进行中间的转发，通过JMS 的使用，我们可以解除两个程序之间的耦合。</p>
<h5 id="优势"><a class="header" href="#优势">优势</a></h5>
<ol>
<li>
<p>Asynchronous（异步）</p>
<p>JMS is asynchronous by default. So to receive a message, the client is not required to send the request. The message will arrive automatically to the client as they become available.（JMS 原本就是一个异步的消息服务，客户端获取消息的时候，不需要主动发送请求，消息会自动发送给可用的客户端）。</p>
</li>
<li>
<p>Reliable（可靠）</p>
<p>JMS provides the facility of assurance that the message will delivered once and only once. You know that duplicate messages create problems. JMS helps you avoiding such problems.（JMS保证消息只会递送一次。大家都遇到过重复创建消息问题，而JMS能帮你避免该问题。）</p>
</li>
</ol>
<h5 id="jms-的消息模型"><a class="header" href="#jms-的消息模型">JMS 的消息模型</a></h5>
<p>JMS具有两种通信模式：</p>
<ol>
<li>Point-to-Point Messaging Domain （点对点）</li>
<li>Publish/Subscribe Messaging Domain （发布/订阅模式）</li>
</ol>
<p>在JMS API出现之前，大部分产品使用“点对点”和“发布/订阅”中的任一方式来进行消息通讯。JMS定义了这两种消息发送模型的规范，它们相互独立。任何JMS的提供者可以实现其中的一种或两种模型，这是它们自己的选择。JMS规范提供了通用接口保证我们基于JMS API编写的程序适用于任何一种模型。</p>
<p><strong>Point-to-Point Messaging Domain（点对点通信模型）</strong></p>
<ul>
<li>
<p>在点对点通信模式中，应用程序由消息队列，发送方，接收方组成。每个消息都被发送到一个特定的队列，接收者从队列中获取消息。队列保留着消息，直到他们被消费或超时</p>
</li>
<li>
<p><strong>特点</strong></p>
<ul>
<li>每个消息只要一个消费者</li>
<li>发送者和接收者在时间上是没有时间的约束，也就是说发送者在发送完消息之后，不管接收者有没有接受消息，都不会影响发送方发送消息到消息队列中。</li>
<li>发送方不管是否在发送消息，接收方都可以从消息队列中去到消息（The receiver can fetch message whether it is running or not when the sender sends the message）</li>
<li>接收方在接收完消息之后，需要向消息队列应答成功</li>
</ul>
</li>
</ul>
<p><strong>Publish/Subscribe Messaging Domain（发布/订阅通信模型）</strong></p>
<ul>
<li>在发布/订阅消息模型中，发布者发布一个消息，该消息通过topic传递给所有的客户端。该模式下，发布者与订阅者都是匿名的，即发布者与订阅者都不知道对方是谁。并且可以动态的发布与订阅Topic。Topic主要用于保存和传递消息，且会一直保存消息直到消息被传递给客户端。</li>
<li><strong>特点</strong>
<ul>
<li>一个消息可以传递个多个订阅者（即：一个消息可以有多个接受方）</li>
<li>发布者与订阅者具有时间约束，针对某个主题（Topic）的订阅者，它必须创建一个订阅者之后，才能消费发布者的消息，而且为了消费消息，订阅者必须保持运行的状态。</li>
<li>为了缓和这样严格的时间相关性，JMS允许订阅者创建一个可持久化的订阅。这样，即使订阅者没有被激活（运行），它也能接收到发布者的消息。</li>
</ul>
</li>
</ul>
<h5 id="jms接收消息"><a class="header" href="#jms接收消息">JMS接收消息</a></h5>
<p>在JMS中，消息的产生和消息是异步的。对于消费来说，JMS的消息者可以通过两种方式来消费消息。</p>
<ol>
<li>
<p>同步（Synchronous）</p>
<p>在同步消费信息模式模式中，订阅者/接收方通过调用 receive（）方法来接收消息。在receive（）方法中，线程会阻塞直到消息到达或者到指定时间后消息仍未到达。</p>
</li>
<li>
<p>异步（Asynchronous）</p>
<p>使用异步方式接收消息的话，消息订阅者需注册一个消息监听者，类似于事件监听器，只要消息到达，JMS服务提供者会通过调用监听器的onMessage()递送消息。</p>
</li>
</ol>
<h5 id="jms编程模型"><a class="header" href="#jms编程模型">JMS编程模型</a></h5>
<ol>
<li>
<p>管理对象（Administered objects）-连接工厂（Connection Factories）和目的地（Destination）</p>
<ul>
<li>
<p>Connection Factories</p>
<p>创建Connection对象的工厂，针对两种不同的jms消息模型，分别有QueueConnectionFactory和TopicConnectionFactory两种。可以通过JNDI来查找ConnectionFactory对象。客户端使用一个连接工厂对象连接到JMS服务提供者，它创建了JMS服务提供者和客户端之间的连接。JMS客户端（如发送者或接受者）会在JNDI名字空间中搜索并获取该连接。使用该连接，客户端能够与目的地通讯，往队列或话题发送/接收消息。</p>
<pre><code class="language-java">QueueConnectionFactory queueConnFactory = (QueueConnectionFactory) initialCtx.lookup (&quot;primaryQCF&quot;);
Queue purchaseQueue = (Queue) initialCtx.lookup (&quot;Purchase_Queue&quot;);
Queue returnQueue = (Queue) initialCtx.lookup (&quot;Return_Queue&quot;);
</code></pre>
</li>
<li>
<p>Destination</p>
<p>目的地指明消息被发送的目的地以及客户端接收消息的来源。JMS使用两种目的地，队列和话题。如下代码指定了一个队列和话题：</p>
<ul>
<li>
<p>创建一个队列Session：</p>
<pre><code class="language-java">QueueSession ses = con.createQueueSession (false, Session.AUTO_ACKNOWLEDGE);  //get the Queue object  
Queue t = (Queue) ctx.lookup (&quot;myQueue&quot;);  //create QueueReceiver  
QueueReceiver receiver = ses.createReceiver(t); 
</code></pre>
</li>
<li>
<p>创建一个Topic Session：</p>
<pre><code class="language-java">QueueSession ses = con.createQueueSession (false, Session.AUTO_ACKNOWLEDGE);  //get the Queue object  
Queue t = (Queue) ctx.lookup (&quot;myQueue&quot;);  //create QueueReceiver  
QueueReceiver receiver = ses.createReceiver(t);
</code></pre>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>连接对象（Connections）</p>
<p>Connection表示在客户端和JMS系统之间建立的链接（对TCP/IP socket的包装）。Connection可以产生一个或多个Session。跟ConnectionFactory一样，Connection也有两种类型：QueueConnection和TopicConnection。连接对象封装了与JMS提供者之间的虚拟连接，如果我们有一个ConnectionFactory对象，可以使用它来创建一个连接。</p>
<pre><code class="language-java">Connection connection = connectionFactory.createConnection();
</code></pre>
</li>
<li>
<p>会话（Sessions）</p>
<p>Session 是我们对消息进行操作的接口，可以通过session创建生产者、消费者、消息等。Session 提供了事务的功能，如果需要使用session发送/接收多个消息时，可以将这些发送/接收动作放到一个事务中。</p>
<p>我们可以在连接创建完成之后创建session：</p>
<pre><code class="language-java">Session session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE);
</code></pre>
</li>
<li>
<p>消息生产者（Message Producers）</p>
<p>消息生产者由Session创建，用于往目的地发送消息。生产者实现MessageProducer接口，我们可以为目的地、队列或话题创建生产者。</p>
<pre><code class="language-java">MessageProducer producer = session.createProducer(dest);
MessageProducer producer = session.createProducer(queue);
MessageProducer producer = session.createProducer(topic);
</code></pre>
</li>
<li>
<p>消息消费者（Message Consumers）</p>
<p>消息消费者由Session创建，用于接收被发送到Destination的消息。</p>
<pre><code class="language-java">MessageConsumer consumer = session.createConsumer(dest);
MessageConsumer consumer = session.createConsumer(queue);
MessageConsumer consumer = session.createConsumer(topic);
</code></pre>
</li>
<li>
<p>消息监听者（Message Listeners）</p>
<p>消息监听器。如果注册了消息监听器，一旦消息到达，将自动调用监听器的onMessage方法。EJB中的MDB（Message-Driven Bean）就是一种MessageListener。</p>
</li>
</ol>
<h2 id="常见mq"><a class="header" href="#常见mq">常见MQ</a></h2>
<p>现在比较常见的MQ产品主要是ActiveMQ、RabbitMQ、ZeroMQ、Kafka、MetaMQ、RocketMQ等。</p>
<p>常见的消息队列有以下几种：</p>
<ol>
<li>Apache ActiveMQ：基于JMS的消息队列，支持多种配置。</li>
<li>RabbitMQ：一个可靠的开源消息队列系统，支持多种编程语言和操作系统。</li>
<li>Apache Kafka：一种高吞吐量、分布式发布订阅消息系统，可以处理大量数据并保持持久性。</li>
<li>RocketMQ：阿里巴巴开源的低延迟、高可靠、可伸缩的消息队列服务。</li>
<li>ZeroMQ：一种高性能、高可用的封装层，可以在不同的消息队列上运行。</li>
<li>NATS：一种基于云计算的消息队列系统，具有高性能和可扩展性。</li>
<li>Redis：一种内存数据库，支持多种数据结构和发布订阅功能，可以实现消息队列的功能。</li>
</ol>
<h3 id="zeromq"><a class="header" href="#zeromq">ZeroMQ</a></h3>
<p>ZeroMQ 号称是“史上最快的消息队列”，基于 C 语言开发，可以在任何平台通过任何代码连接，通过 inproc、IPC、TCP、TIPC、多播传送消息，支持发布-订阅、推-拉、共享队列等模式，高速异步 I/O 引擎。</p>
<p>根据官方的说法，ZeroMQ 是一个简单好用的传输层，像框架一样的可嵌入的 Socket 类库，使 Socket 编程更加简单、简洁、性能更高，是专门为高吞吐量/低延迟的场景开发。<strong>ZeroMQ 与其他 MQ 有着本质的区别，它根本不是消息队列服务器，更类似于一个底层网络通讯库</strong>，对原有 Socket API 进行封装，在使用引入对应的jar包即可，可谓是相当灵活。</p>
<p>同时，因为它的简单灵活，如果我们想作为消息队列使用的话，需要开发大量代码。而且，ZeroMQ 不支持消息持久化，其定位并不是安全可靠的消息传输，所以还需要自己编码保证可靠性。简而言之，ZeroMQ 很强大，但是想用好需要自己实现。</p>
<h3 id="rabbitmq"><a class="header" href="#rabbitmq">RabbitMQ</a></h3>
<p>RabbitMQ 2007年发布，是一个在 AMQP 基础上完成的，可复用的企业消息系统，是当前最主流的消息中间件之一。</p>
<h4 id="代理效应"><a class="header" href="#代理效应">代理效应</a></h4>
<p>代理和负载平衡器在客户端与其目标节点之间引入了额外的网络跃点（甚至多个）。中介也可以成为网络争用点：它们的吞吐量将成为整个系统的限制因素。因此，代理和负载平衡器的网络带宽超额配置和吞吐量监视非常重要。</p>
<p>当中间商在一段时间内没有任何活动时，它们也可以终止“空闲” TCP连接。在大多数情况下，这是不可取的。此类事件将导致服务器端的突然关闭连接日志消息以及客户端的I / O异常。</p>
<p>在连接上启用心跳后，将导致周期性的轻型网络流量。因此，心跳具有保护客户端连接的副作用，该客户端连接可能会闲置一段时间，以防止代理和负载平衡器过早关闭。</p>
<p>从10到30秒的心跳超时将经常产生周期性的网络流量（大约每5到15秒一次），以满足大多数代理工具和负载均衡器的默认设置。太低的值将产生误报。</p>
<h4 id="主要特性"><a class="header" href="#主要特性">主要特性</a></h4>
<ol>
<li>**可靠性：**提供了多种技术可以让你在性能和可靠性质检进行权衡。这些技术包括持久性机制、投递确认、发布者证实和高可用性机制；</li>
<li>**灵活的路由：**消息在到达队列前是通过交换机进行路由的。RabbitMQ 为典型的路由逻辑提供了多钟内置交换机类型。如果你有更复杂的路由需求，可以将这些交换机组合起来使用，你甚至可以实现自己的交换机类型，并且当做 RabbitMQ 的插件使用；</li>
<li>**消息集群：**在相同局域网中的多个 RabbitMQ 服务器可以聚合在一起，作为一个独立的逻辑代理来使用；</li>
<li>**队列高可用：**队列可以在集群中的机器上进行镜像，以确保在硬件问题下还保证消息安全；</li>
<li>**多种协议的支持：**支持多种消息队列协议；</li>
<li>**多语言支持：**服务器端用 Erlang 语言编写，支持只要是你能想到的所有编程语言；</li>
<li>**管理界面：**RabbitMQ 有一个易用的用户界面，使得用户可以监控和管理消息 Broker 的许多方面；</li>
<li>**跟踪机制：**如果消息异常，RabbitMQ 提供消息跟踪机制，使用者可以找出发生了什么；</li>
<li>**插件机制：**提供了许多插件，来从多方面进行扩展，也可以编写自己的插件。</li>
</ol>
<p>使用 RabbitMQ 需要：</p>
<ul>
<li>Erlang 语言包</li>
<li>RabbitMQ 安装包</li>
</ul>
<p>RabbitMQ 可以运行在 Erlang 语言所支持的平台上：</p>
<ul>
<li>Solaris</li>
<li>BSD</li>
<li>Linux</li>
<li>MacOSX</li>
<li>TRU64</li>
<li>Windows NT/2000/XP/Vista/Windows 7/Windows 8</li>
<li>Windows Server 2003/2008/2012</li>
<li>Windows 95, 98</li>
<li>VxWorks</li>
</ul>
<h4 id="优点"><a class="header" href="#优点">优点</a></h4>
<ol>
<li>由于 Erlang 语言的特性，MQ 性能较好，高并发；</li>
<li>健壮、稳定、易用、跨平台、支持多种语言、文档齐全；</li>
<li>有消息确认机制和持久化机制，可靠性高；</li>
<li>高度可定制的路由；</li>
<li>管理界面较丰富，在互联网公司也有较大规模的应用；</li>
<li>社区活跃度高。</li>
</ol>
<h4 id="缺点-2"><a class="header" href="#缺点-2">缺点</a></h4>
<ol>
<li>尽管结合 Erlang 语言本身的并发优势，性能较好，但是不利于做二次开发和维护；</li>
<li>实现了代理架构，意味着消息在发送到客户端之前可以在中央节点上排队，此特性使得 RabbitMQ 易于使用和部署，但是使得其运行速度较慢，因为中央节点增加了延迟，消息封装后也比较大；</li>
<li>需要学习比较复杂的接口和协议，学习和维护成本较高。</li>
</ol>
<h4 id="工作原理"><a class="header" href="#工作原理">工作原理</a></h4>
<p><img src="https://github.com/chou401/pic-md/raw/master/img/image-20230517155538862.png" alt="image-20230517155538862" /></p>
<ul>
<li><strong>Broker</strong>：接收和分发消息的应用，RabbitMQ Server就是 Message Broker。</li>
<li><strong>Virtual Host</strong>：出于多租户和安全因素设计的，把 AMQP 的基本组件划分到一个虚拟的分组中，类似于网络中的 namespace 概念。当多个不同的用户使用同一个 RabbitMQ server 提供的服务时，可以划分出多个vhost，每个用户在自己的 vhost 创建 exchange／queue 等。</li>
<li><strong>Connection</strong>：publisher／consumer 和 broker 之间的 TCP 连接。</li>
<li><strong>Channel</strong>：如果每一次访问 RabbitMQ 都建立一个 Connection，在消息量大的时候建立 TCP Connection的开销将是巨大的，效率也较低。Channel 是在 connection 内部建立的逻辑连接，如果应用程序支持多线程，通常每个thread创建单独的 channel 进行通讯，AMQP method 包含了channel id 帮助客户端和message broker 识别 channel，所以 channel 之间是完全隔离的。Channel 作为轻量级的 Connection 极大减少了操作系统建立 TCP connection 的开销。</li>
<li><strong>Exchange</strong>：message 到达 broker 的第一站，根据分发规则，匹配查询表中的 routing key，分发消息到queue 中去。常用的类型有：direct (point-to-point), topic (publish-subscribe) and fanout (multicast)。</li>
<li><strong>Queue</strong>：消息最终被送到这里等待 consumer 取走。</li>
<li><strong>Binding</strong>：exchange 和 queue 之间的虚拟连接，binding 中可以包含 routing key。Binding 信息被保存到 exchange 中的查询表中，用于 message 的分发依据。</li>
</ul>
<h4 id="如何实现生产者和消费者"><a class="header" href="#如何实现生产者和消费者">如何实现生产者和消费者</a></h4>
<h4 id="交换机类型"><a class="header" href="#交换机类型">交换机类型</a></h4>
<ul>
<li>
<p><strong>Direct Exchange（直连交换机）</strong></p>
<p>路由键与队列完全匹配交换机。此种类型交换机，通过 RoutingKey 路由键将交换机和队列进行绑定，消息被发送到 exchange 时，需要根据消息的 RoutingKey 进行匹配，只将消息发送到完全匹配到此 RoutingKey 的队列（如果匹配了多个队列，则每个队列都会收到相同的消息）。</p>
<p>比如：如果一个队列绑定到交换机要求路由键为 “key”，则只转发 RoutingKey 标记为 “key” 的消息，不会转发 “key1”，也不会转发 “key2” 等等。它是完全匹配、单播的模式。</p>
<p><img src="https://github.com/chou401/pic-md/raw/master/img/image-20230519161049311.png" alt="image-20230519161049311" /></p>
</li>
<li>
<p><strong>Fanout Exchange（扇型交换机）</strong></p>
<p>Fanout，此种交换机，会将消息分发给所有绑定了次交换机的队列，此时 RoutingKey 参数无效。这个模式类似于广播。它是所有交换机速度最快的。</p>
<p>Fanout 类型交换机下发送消息一条，无论 RoutingKey 是什么，queue1，queue2，queue3，queue4 都可以收到消息。</p>
<p><img src="https://github.com/chou401/pic-md/raw/master/img/image-20230519161221269.png" alt="image-20230519161221269" /></p>
</li>
<li>
<p><strong>Topic Exchange（主题交换机）</strong></p>
<p>应用范围最广的交换机类型，消息队列通过消息主题与交换机绑定。一个队列可以通过多个主题与交换机绑定，多个消息队列也可以通过相同消息主题和交换机绑定。并且可以通过通配符（*或者#）进行多个消息主题的适配。</p>
<p>Topic，主题类型交换机，此种交换机与 Direct 类似，也是需要通过 RoutingKey 路由键进行匹配分发，区别在于 Topic 可以进行模糊匹配，Direct 是完全匹配。</p>
<ol>
<li>Topic 中，将 RoutingKey 通过 “.” 来分成多个部分。</li>
<li>“*” 代表一个部分。</li>
<li>“#” 代表0个或多个部分（如果绑定的路由键为 “#” 时，则接收所有消息，路由键所有都匹配）。</li>
</ol>
<p><img src="https://github.com/chou401/pic-md/raw/master/img/image-20230519162427816.png" alt="image-20230519162427816" /></p>
<p>然后发送一条消息，RoutingKey 为 “key1.key2.key3.key4”，那么根据 “.” 将这个路由键分为了四个部分，此条路由键将会匹配：</p>
<ol>
<li>key1.key2.key3.*：成功匹配，因为 * 可以代表一个部分。</li>
<li>key1.#：成功匹配，因为  可以代表0或多个部分。</li>
<li><em>.key3.</em>.key4：成功匹配，因为第一和第三部分分别为key1和key3，且为四个部分，刚好匹配。</li>
<li>#.key3.key4：成功匹配，#可以代表多个部分，正好匹配中了key1和key2。</li>
</ol>
<p>如果发送消息 RoutingKey 为 “key1”，那么将只能匹配中 key1.#，#可以代表0个部分。</p>
</li>
<li>
<p><strong>Headers Exchange（头交换机）</strong></p>
<p>与 RoutingKey 无关，匹配机制是匹配消息头中的属性信息。在绑定消息队列与交换机之前声明一个map键值对，通过这个map对象实现消息队列和交换机的绑定。当消息发送到 RabbitMQ 时会取到该消息的 headers 与 exchange 绑定时指定的键值对进行匹配，如果完全匹配则消息会路由到该队列，否则不会路由到该队列。</p>
<p>匹配规则 x-match 有下列两种类型：</p>
<ul>
<li>x-match = all：表示所有的键值对都匹配才能接收到消息。</li>
<li>x-match = any：表示只要有键值对匹配就能接收到消息。</li>
</ul>
</li>
</ul>
<p><img src="https://github.com/chou401/pic-md/raw/master/img/image-20230523095354400.png" alt="" /></p>
<h4 id="镜像队列"><a class="header" href="#镜像队列">镜像队列</a></h4>
<h5 id="背景"><a class="header" href="#背景">背景</a></h5>
<p>单节点的 RabbitMQ 存在性能上限，可以通过垂直或者水平扩容的方式增加 RabbitMQ的吞吐量。垂直扩容指的是提高 CPU 和内存的规格；水平扩容指部署 RabbitMQ 集群。</p>
<p>通过将单个节点的队列相对平均地分配到集群的不同节点，单节点的压力被分散，RabbitMQ 可以充分利用多个节点的计算和存储资源，以提升消息的吞吐量。</p>
<p>但是多节点的集群并不意味着有更好的可靠性--每个队列仍只存在于一个节点，当这个节点故障，这个节点上的所有队列都不再可用。</p>
<p>在 3.8 以前的版本，RabbitMQ 通过镜像队列（Classic Queue Mirroring）来提供高可用性。但镜像队列存在很大的局限性，在 3.8 之后的版本 RabbitMQ 推出了 Quorum queues 来替代镜像队列，在之后的版本中镜像队列将被移除。</p>
<p>镜像队列通过将一个队列镜像（消息广播）到其他节点的方式来提升消息的高可用性。当主节点宕机，从节点会提升为主节点继续向外提供服务。</p>
<h5 id="描述"><a class="header" href="#描述">描述</a></h5>
<p>RabbitMQ 以队列维度提供高可用的解决方案——镜像队列。</p>
<p>配置镜像队列规则后，新创建的队列按照规则成为镜像队列。每个镜像队列都包含一个主节点（Leader）和若干个从节点（Follower），其中只有主节点向外提供服务（生产消息和消费消息），从节点仅仅接收主节点发送的消息。</p>
<p>从节点会准确地按照主节点执行命令的顺序执行动作，所以从节点的状态与主节点应是一致的。</p>
<h5 id="配置方法"><a class="header" href="#配置方法">配置方法</a></h5>
<p>使用策略（Policy）来配置镜像策略，策略使用正则表达式来配置需要应用镜像策略的队列名称，以及在参数中配置镜像队列的具体参数。</p>
<p>按此步骤创建镜像策略，该策略为所有 <code>mirror_</code> 开头的队列创建 3 副本镜像。</p>
<p><img src="https://github.com/chou401/pic-md/raw/master/img/image-20230523112017966.png" alt="image-20230523112017966" /></p>
<p>创建完的策略如下图显示：</p>
<p><img src="https://github.com/chou401/pic-md/raw/master/img/image-20230523112042677.png" alt="image-20230523112042677" /></p>
<p><strong>参数解释：</strong></p>
<ul>
<li>Name: policy的名称，用户自定义。</li>
<li>Pattern: queue的匹配模式（正则表达式）。<code>^</code>表示所有队列都是镜像队列。</li>
<li>Definition: 镜像定义，包括三个部分ha-sync-mode、ha-mode、ha-params。
<ul>
<li>ha-mode: 指明镜像队列的模式，有效取值范围为all/exactly/nodes。
<ul>
<li>all：表示在集群所有的代理上进行镜像。</li>
<li>exactly：表示在指定个数的代理上进行镜像，代理的个数由ha-params指定。</li>
<li>nodes：表示在指定的代理上进行镜像，代理名称通过ha-params指定。</li>
</ul>
</li>
<li>ha-params: ha-mode模式需要用到的参数。</li>
<li>ha-sync-mode: 表示镜像队列中消息的同步方式，有效取值范围为：automatic，manually。
<ul>
<li>automatic：表示自动向master同步数据。</li>
<li>manually：表示手动向master同步数据。</li>
</ul>
</li>
</ul>
</li>
<li>Priority: 可选参数， policy的优先级。</li>
</ul>
<h5 id="配置规则"><a class="header" href="#配置规则">配置规则</a></h5>
<p>配置完 Policy 后，创建新的队列，或者原有的的队列，如果队列名称符合 Policy 的匹配规则，则该队列会自动创建为镜像队列。</p>
<p>下图中 <code>mirror_queue</code> 匹配之前创建的镜像策略，为镜像队列。<code>normal_queue</code> 为普通队列。</p>
<p><img src="https://github.com/chou401/pic-md/raw/master/img/image-20230523112755735.png" alt="image-20230523112755735" /></p>
<p>镜像队列显示的蓝色 <code>+2</code> 表示同步副本数为 2 个。此处如果用红色显示，则表示为同步副本数</p>
<p>显示的 <code>mirror-policy</code> 为该队列应用的镜像策略。</p>
<p>点击队列名称可以进入查看队列详细信息，从中可以看出队列的主节点、从节点和镜像策略。</p>
<p><img src="https://github.com/chou401/pic-md/raw/master/img/image-20230523112856113.png" alt="image-20230523112856113" /></p>
<h5 id="配置参数"><a class="header" href="#配置参数">配置参数</a></h5>
<p><strong>镜像策略</strong></p>
<div class="table-wrapper"><table><thead><tr><th><strong>ha-mode</strong></th><th><strong>ha-params</strong></th><th><strong>结果</strong></th></tr></thead><tbody>
<tr><td>exactly</td><td>count</td><td>集群中队列副本的数量（主队列加上镜像）。count值为1表示一个副本：只有主节点。如果主节点不可用，则其行为取决于队列是否持久化。count值为2表示两个副本：一个队列主队列和一个队列镜像。换句话说:“镜像数=节点数-1”。如果运行队列主服务器的节点变得不可用，队列镜像将根据配置的镜像提升策略自动提升到主服务器。如果集群中的可用节点数少于count，则将队列镜像到所有节点。如果集群中有多个计数节点，并且一个包含镜像的节点宕机，那么将在另一个节点上创建一个新镜像。使用’ exactly ‘模式和’ ha-promot-on-shutdown ': ’ always '可能是危险的，因为队列可以跨集群迁移，并在停机时变得不同步。</td></tr>
<tr><td>all</td><td>不设置</td><td>队列跨集群中的所有节点镜像。当一个新节点被添加到集群中时，队列将被镜像到该节点。这个设置非常保守。建议设置的副本值为大多数节点<code>N / 2 + 1</code>。镜像到所有节点会给所有集群节点带来额外的负担，包括网络I/O、磁盘I/O和磁盘空间的使用。</td></tr>
<tr><td>nodes</td><td>节点名称</td><td>队列被镜像到节点名中列出的节点。节点名是在rabbitmqctl cluster_status中出现的Erlang节点名；它们的形式通常是“rabbit@hostname”。如果这些节点名中有任何一个不是集群的一部分，则不构成错误。如果在声明队列时列表中的节点都不在线，则将在声明客户机连接的节点上创建队列。</td></tr>
</tbody></table>
</div>
<p><strong>新镜像同步策略</strong></p>
<div class="table-wrapper"><table><thead><tr><th><strong>ha-sync-mode</strong></th><th><strong>说明</strong></th></tr></thead><tbody>
<tr><td>manual</td><td>这是默认模式。新队列镜像将不接收现有消息，它只接收新消息。一旦使用者耗尽了仅存在于主服务器上的消息，新的队列镜像将随着时间的推移成为主服务器的精确副本。如果主队列在所有未同步的消息耗尽之前失败，则这些消息将丢失。您可以手动完全同步队列，详情请参阅未同步的镜像部分。</td></tr>
<tr><td>automatic</td><td>当新镜像加入时，队列将自动同步。值得重申的是，队列同步是一个阻塞操作。如果队列很小，或者您在RabbitMQ节点和ha-sync-batch-size之间有一个快速的网络，那么这是一个很好的选择。</td></tr>
</tbody></table>
</div>
<p><strong>从节点晋升策略</strong></p>
<p>镜像队列主节点出现故障时，最老的从节点会被提升为新的主节点。如果新提升为主节点的这个副本与原有的主节点并未完成数据的同步，那么就会出现数据的丢失，而实际应用中，出现数据丢失可能会导致出现严重后果。</p>
<p>rabbitmq 提供了 ha-promote-on-shutdown，ha-promote-on-failure 两个参数让用户决策是保证队列的可用性，还是保证队列的一致性；两个参数分别控制正常关闭、异常故障情况下从节点是否提升为主节点，其可设置的值为 when-synced 和 always。</p>
<div class="table-wrapper"><table><thead><tr><th><strong>ha-promote-on-shutdown/ha-promote-on-failure</strong></th><th><strong>说明</strong></th></tr></thead><tbody>
<tr><td>when-synced</td><td>从节点与主节点完成数据同步，才会被提升为主节点</td></tr>
<tr><td>always</td><td>无论什么情况下从节点都将被提升为主节点</td></tr>
</tbody></table>
</div>
<blockquote>
<p>这里要注意的是ha-promote-on-failure设置为always，插拔网线模拟网络异常的两个测试场景：当网络恢复后，其中一个会重新变为mirror，具体是哪个变为mirror，受cluster_partition_handling处理策略的影响。</p>
</blockquote>
<blockquote>
<p>例如两台节点A，B组成集群，并且cluster_partition_handling设置为autoheal，队列的master位于节点A上，具有全量数据，mirror位于节点B上，并且还未完成消息的同步，此时出现网络异常，网络异常后两个节点交互决策：如果节点A节点成为赢家，此时B节点内部会重启，这样数据全部保留不会丢失；相反如果B节点成为赢家，A需要重启，那么由于ha-prromote-on-failure设置为always，B节点上的mirror提升为master，这样就出现了数据丢失。</p>
</blockquote>
<p><strong>主队列选择策略</strong></p>
<p>RabbitMQ中的每个队列都有一个主队列。该节点称为队列主服务器。所有队列操作首先经过主队列，然后复制到镜像。这对于保证消息的FIFO排序是必要的。</p>
<p>通过在策略中设置 <code>queue-master-locator</code> 键的方法可以定义主队列选择策略，这是常用的方法。</p>
<p><img src="https://github.com/chou401/pic-md/raw/master/img/image-20230523144411570.png" alt="image-20230523144411570" /></p>
<p>此外，也可以用队列参数 <code>x-queue-master-locator</code> 或配置文件中定义 <code>queue_master_locator</code> 的方式指定，此处不再赘述。</p>
<p>下面是该策略的可选参数列表：</p>
<div class="table-wrapper"><table><thead><tr><th><strong>queue-master-locator</strong></th><th><strong>说明</strong></th></tr></thead><tbody>
<tr><td>min-masters</td><td>选择承载最小绑定主机数量的节点</td></tr>
<tr><td>client-local</td><td>选择客户机声明队列连接到的节点</td></tr>
<tr><td>min-masters</td><td>随机选择一个节点</td></tr>
</tbody></table>
</div>
<h4 id="负载均衡-haproxy"><a class="header" href="#负载均衡-haproxy">负载均衡-HAProxy</a></h4>
<p>对 RabbitMQ集群中的节点做负载均衡：</p>
<ul>
<li>客户端负载均衡</li>
<li>HAProxy实现负载均衡</li>
</ul>
<h5 id="客户端负载均衡"><a class="header" href="#客户端负载均衡">客户端负载均衡</a></h5>
<p>要实现一个完整的负载均衡主要是实现以下功能：</p>
<ul>
<li>
<p>请求需要按照规则打散到各个集群的节点。</p>
</li>
<li>
<p>节点的宕机需要负载均衡器自我感知并且进行剔除，这样就避免节点都宕掉了还在向宕掉的节点发送请求，导致大量的请求失败。</p>
</li>
<li>
<p>节点的新增其实还好，可以自我感知并上线，也可以手动配置。</p>
</li>
<li>
<p>haproxy ip-hash</p>
<p>整型的Hash算法使用的是Thomas Wang's 32 Bit / 64 Bit Mix Function ，这是一种基于位移运算的散列方法。基于移位的散列是使用Key值进行移位操作。通常是结合左移和右移。每个移位过程的结果进行累加，最后移位的结果作为最终结果。这种方法的好处是避免了乘法运算，从 </p>
</li>
</ul>
<p>如果实现将请求打散到各个节点，负载均衡器需要遵循一定得规则，规则主要是一下几种：</p>
<ul>
<li>轮询：将请求轮流到发送到后端的机器，不关系节点的实际连接数和负载能力。</li>
<li>加权轮询：对轮询的优化，考虑每个节点的性能，配置高的机器分配较高的权重，配置低的机器分配较低的权重，并将请求按照权重分配到后端节点。</li>
<li>随机法：通过随机算法，在众多节点中随机挑选一个进行请求。随着客户端调用服务端的次数增多，其实际效果越接近轮询。</li>
<li>加权随机法：对随机的优化，根据机器性能分配权重，按照权重访问后端节点。</li>
<li>源地址哈希法：根据客户端的IP地址，通过hash函数获取一个数值，用这个数值对后端节点数进行取模，这样在后端节点数保持不变的情况下，同一个客户端访问的 后端节点也是同一个。</li>
<li>最小连接数：根据后端节点的连接情况，动态选举一个连接积压最小的节点进行访问，尽可能的提高节点的利用率。</li>
</ul>
<h5 id="haproxy实现负载均衡"><a class="header" href="#haproxy实现负载均衡">HAProxy实现负载均衡</a></h5>
<p><strong>简介</strong></p>
<ol>
<li>HAProxy 是一款提供高可用性、负载均衡以及基于TCP（第四层）和HTTP（第七层）应用的代理软件，支持虚拟主机，它是免费、快速并且可靠的一种解决方案。 HAProxy特别适用于那些负载特大的web站点，这些站点通常又需要会话保持或七层处理。HAProxy运行在时下的硬件上，完全可以支持数以万计的 并发连接。并且它的运行模式使得它可以很简单安全的整合进您当前的架构中， 同时可以保护你的web服务器不被暴露到网络上。</li>
<li>HAProxy 实现了一种事件驱动、单一进程模型，此模型支持非常大的并发连接数。多进程或多线程模型受内存限制 、系统调度器限制以及无处不在的锁限制，很少能处理数千并发连接。事件驱动模型因为在有更好的资源和时间管理的用户端(User-Space) 实现所有这些任务，所以没有这些问题。此模型的弊端是，在多核系统上，这些程序通常扩展性较差。这就是为什么他们必须进行优化以 使每个CPU时间片(Cycle)做更多的工作。</li>
<li>HAProxy 支持连接拒绝 : 因为维护一个连接的打开的开销是很低的，有时我们很需要限制攻击蠕虫（attack bots），也就是说限制它们的连接打开从而限制它们的危害。 这个已经为一个陷于小型DDoS攻击的网站开发了而且已经拯救了很多站点，这个优点也是其它负载均衡器没有的。</li>
<li>HAProxy 支持全透明代理（已具备硬件防火墙的典型特点）: 可以用客户端IP地址或者任何其他地址来连接后端服务器，这个特性仅在 Linux 2.4/2.6内核打了cttproxy补丁后才可以使用，这个特性也使得为某特殊服务器处理部分流量同时又不修改服务器的地址成为可能。</li>
</ol>
<p><strong>四层负载均衡与七层负载均衡</strong></p>
<ul>
<li>
<p><strong>四层负载均衡</strong></p>
<p>以常见的 TCP 应用为例，负载均衡器在接收到第一个来自客户端的 SYN 请求时，会通过设定的负载均衡算法选择一个最佳的后端服务器，同时将报文中目标 IP 地址修改为后端服务器 IP，然后直接转发给该后端服务器，这样一个负载均衡请求就完成了。从这个过程来看，一个 TCP 连接是客户端和服务器直接建立的，而负载均衡器只不过完成了一个类似路由器的转发动作。在某些负载均衡策略中，为保证后端服务器返回的报文可以正确传递给负载均衡器，在转发报文的同时可能还会对报文原来的源地址进行修改。</p>
</li>
<li>
<p><strong>七层负载均衡</strong></p>
<p>这里仍以常见的 TCP 应用为例，由于负载均衡器要获取到报文的内容，因此只能先代替后端服务器和客户端建立连接，接着，才能收到客户端发送过来的报文内容，然后再根据该报文中特定字段加上负载均衡器中设置的负载均衡算法来决定最终选择的内部服务器。纵观整个过程，七层负载均衡器在这种情况下类似于一个代理服务器。</p>
<p>对比四层负载均衡和七层负载均衡运行的整个过程，可以看出，在七层负载均衡模式下， 负载均衡器与客户端及后端的服务器会分别建立一次 TCP 连接，而在四层负载均衡模式下， 仅建立一次 TCP 连接。由此可知，七层负载均衡对负载均衡设备的要求更高，而七层负载均衡的处理能力也必然低于四层模式的负载均衡。</p>
</li>
</ul>
<p><strong>HAProxy配置详解</strong></p>
<p>HAProxy 配置文件根据功能和用途，主要有 5 个部分组成，但有些部分并不是必须的， 可以根据需要选择相应的部分进行配置。</p>
<ul>
<li>
<p><strong>global</strong> 部分</p>
<p>用来设定全局配置参数，属于进程级的配置，通常和操作系统配置有关。</p>
<ul>
<li><strong>log</strong>：全局的日志配置，local0 是日志设备，info 表示日志级别。其中日志级别有err、warning、info、debug 四种可选。这个配置表示使用 127.0.0.1 上的 rsyslog 服务中的local0 日志设备，记录日志等级为info。</li>
<li><strong>maxconn</strong>：设定每个 haproxy 进程可接受的最大并发连接数，此选项等同于 Linux命令行选项“ulimit -n”。</li>
<li><strong>user/ group</strong>：设置运行 haproxy 进程的用户和组，也可使用用户和组的 uid 和gid 值来替代。</li>
<li><strong>daemon</strong>：设置 HAProxy 进程进入后台运行。这是推荐的运行模式。</li>
<li><strong>nbproc</strong>：设置 HAProxy 启动时可创建的进程数，此参数要求将HAProxy 运行模式设置为“daemon”，默认只启动一个进程。根据使用经验，该值的设置应该小于服务器的 CPU 核数。创建多个进程，能够减少每个进程的任务队列，但是过多的进程可能会导致进程的崩溃。</li>
<li><strong>pidfile</strong>：指定 HAProxy 进程的 pid 文件。启动进程的用户必须有访问此文件的权限。</li>
</ul>
</li>
<li>
<p><strong>defaults</strong> 部分</p>
<p>默认参数的配置部分。在此部分设置的参数值，默认会自动被引用到下面的 frontend、backend 和 listen 部分中，因此，如果某些参数属于公用的配置，只需在 defaults 部分添加一次即可。而如果在 frontend、backend 和 listen 部分中也配置了与 defaults 部分一样的参数，那么defaults 部分参数对应的值自动被覆盖。</p>
<ul>
<li>
<p><strong>mode</strong>：设置 HAProxy 实例默认的运行模式，有 tcp、http、health 三个可选值。</p>
<ul>
<li>
<p><strong>tcp</strong> 模式</p>
<p>在此模式下，客户端和服务器端之间将建立一个全双工的连接，不会对七层报文做任何类型的检查，默认为 tcp 模式，经常用于 SSL、SSH、SMTP 等应用。</p>
</li>
<li>
<p><strong>http</strong> 模式</p>
<p>在此模式下，客户端请求在转发至后端服务器之前将会被深度分析，所有不与 RFC 格式兼容的请求都会被拒绝。</p>
</li>
<li>
<p><strong>health</strong> 模式</p>
<p>目前此模式基本已经废弃，不在多说。</p>
</li>
</ul>
</li>
<li>
<p><strong>retries</strong>：设置连接后端服务器的失败重试次数，连接失败的次数如果超过这里设置的值，HAProxy 会将对应的后端服务器标记为不可用。此参数也可在后面部分进行设置。</p>
</li>
<li>
<p><strong>timeout connect</strong>：设置成功连接到一台服务器的最长等待时间，默认单位是毫秒，但也可以使用其他的时间单位后缀。</p>
</li>
<li>
<p><strong>timeout client</strong>：设置连接客户端发送数据时最长等待时间，默认单位是毫秒，也可以使用其他的时间单位后缀。</p>
</li>
<li>
<p><strong>timeout server</strong>：设置服务器端回应客户度数据发送的最长等待时间，默认单位是毫秒，也可以使用其他的时间单位后缀。</p>
</li>
<li>
<p><strong>timeout check</strong>：设置对后端服务器的检测超时时间，默认单位是毫秒，也可以使用其他的时间单位后缀。</p>
</li>
</ul>
</li>
<li>
<p><strong>frontend</strong> 部分</p>
<p>此部分用于设置接收用户请求的前端虚拟节点。frontend 是在 HAProxy1.3 版本之后才引入的一个组件，同时引入的还有 backend 组件。通过引入这些组件，在很大程度上简化了 HAProxy 配置文件的复杂性。frontend 可以根据 ACL 规则直接指定要使用的后端。</p>
<ul>
<li><strong>bind</strong>：此选项只能在 frontend 和 listen 部分进行定义，用于定义一个或几个监听的套接字。bind 的使用格式为:bind [<address>:&lt;port_range&gt;] interface <interface>其中，address 为可选选项，其可以为主机名或IP 地址，如果将其设置为“*”或“0.0.0.0”，将监听当前系统的所有 IPv4 地址。port_range 可以是一个特定的 TCP 端口，也可是一个端口范围，小于 1024 的端口需要有特定权限的用户才能使用。interface 为可选选项，用来指定网络接口的名称，只能在 Linux 系统上使用。</li>
<li><strong>option httplog</strong>：在默认情况下，haproxy 日志是不记录 HTTP 请求的，这样很不方便 HAProxy 问题的排查与监控。通过此选项可以启用日志记录 HTTP 请求。</li>
<li><strong>option forwardfor</strong>：如果后端服务器需要获得客户端的真实  IP，就需要配置此参数。由于 HAProxy 工作于反向代理模式，因此发往后端真实服务器的请求中的客户端 IP 均为 HAProxy 主机的 IP，而非真正访问客户端的地址，这就导致真实服务器端无法记录客户端真正请求来源的 IP，而“X-Forwarded-For”则可用于解决此问题。通过使用“forwardfor”选项，HAProxy 就可以向每个发往后端真实服务器的请求添加“X-Forwarded-For”记录，这样后端真实服务器日志可以通过“X-Forwarded-For”信息来记录客户端来源 IP。</li>
<li><strong>option httpclose</strong>：此选项表示在客户端和服务器端完成一次连接请求后，HAProxy 将主动关闭此 TCP 连接。这是对性能非常有帮助的一个参数。</li>
<li><strong>log global</strong>：表示使用全局的日志配置，这里的“ global”表示引用在HAProxy 配置文件 global 部分中定义的 log 选项配置格式。</li>
<li><strong>default_backend</strong>：#指定默认的后端服务器池，也就是指定一组后端真实服务器，而这些真实服务器组将在 backend 段进行定义。这里的htmpool 就是一个后端服务器组。</li>
</ul>
</li>
<li>
<p><strong>backend</strong> 部分</p>
<p>此部分用于设置集群后端服务集群的配置，也就是用来添加一组真实服务器，以处理前端用户的请求。添加的真实服务器类似于 LVS 中的real server 节点。</p>
<ul>
<li>
<p>option redispatch：此参数用于 cookie 保持的环境中。在默认情况下，HAProxy会将其请求的后端服务器的 serverID 插入到 cookie 中，以保证会话的 SESSION 持久性。而如果后端的服务器出现故障，客户端的 cookie 是不会刷新的，这就出现了问题。此时，如果设置此参数，就会将客户的请求强制定向到另外一个健康的后端服务器上，以保证服务的正常。</p>
</li>
<li>
<p>option abortonclose：如果设置了此参数，可以在服务器负载很高的情况下， 自动结束掉当前队列中处理时间比较长的链接。</p>
</li>
<li>
<p>balance：此关键字用来定义负载均衡算法。目前 HAProxy 支持多种负载均衡算法，常用的有如下几种：</p>
<div class="table-wrapper"><table><thead><tr><th>算法</th><th>描述</th></tr></thead><tbody>
<tr><td>roundrobin</td><td>是基于权重进行轮询调度的算法，在服务器的性能分布比较均匀的时候，这是一种最公平的、最合理的算法。此算法经常使用。</td></tr>
<tr><td>static-rr</td><td>也是基于权重进行轮询调度的算法，不过此算法为静态方法，在运行时调整其服务器严重不会生效。</td></tr>
<tr><td>source</td><td>是基于请求源IP的算法。此算法先对请求的源IP 进行hash 运算，然后将结果与后端服务器的权重总数相除后转发至某个匹配的后端服务器。这种方式可以使同一客户端 IP的请求始终被转发到某特定的后端服务器。</td></tr>
<tr><td>leastconn</td><td>此算法会将新的连接请求转发到具有最少连接数目的后端服务器。在会话时间较长的场景中推荐使用此算法，例如数据库复杂均衡等。此算法不适合会话时间比较短的环境中，例如基于 HTTP 的应用。</td></tr>
<tr><td>url</td><td>此算法会对部分或整个 URL 进行 hash 运算，再经过与服务器的总权重相除，最后转发到某台匹配的后端服务器上。</td></tr>
<tr><td>url_param</td><td>此算法会根据 URL 路径中的参数进行转发，这样可保证在后端真实服务器数量不变时，同一个用户的请求始终分发到同一机器上。</td></tr>
<tr><td>hdr(<name>):</td><td>此算法根据 http 头进行转发，如果指定的 http 头名称不存在，则使用 roundrobin 算法进行策略转发。</td></tr>
</tbody></table>
</div></li>
<li>
<p>cookie：表示允许向 cookie 插入 SERVERID，每台服务器的 SERVERID 可在下面的 server 关键字中使用 cookie 关键字定义。</p>
</li>
<li>
<p>option httpchk：此选项表示启用 HTTP 的服务状态检测功能。HAProxy 作为一款专业的负载均衡器，它支持对 backend 部分指定的后端服务节点的健康检查，以保证在后端 backend 中某个节点不能服务时，把从 frotend 端进来的客户端请求分配至 backend 中其他健康节点上，从而保证整体服务的可用性。“option httpchk”的用法如下：</p>
<div class="table-wrapper"><table><thead><tr><th>参数</th><th>描述</th></tr></thead><tbody>
<tr><td>method</td><td>表示 http 请求的方式，常用的有 OPTIONS、GET、HEAD 几种方式， 一般的健康检查可以使用 HEAD 方式进行，而不是采用 GET 方式，这是因为 HEAD 方式没有数据返回，仅检查 response 的 HEAD 是不是 200 状态。因此相对 GET 方式，HEAD 方式更快，更简单。</td></tr>
<tr><td>uri</td><td>表示要检测的 URL 地址，通过执行此 URL ，可以获取后端服务器的运行状态。在正常情况下将返回状态码 200，返回其他状态码均为异常状态。</td></tr>
<tr><td>version</td><td>指定心跳检测时的 http 版本号。</td></tr>
</tbody></table>
</div></li>
<li>
<p>server：这个关键字用来定义多个后端真实服务器，不能用于 defaults 和frontend部分。使用格式为：server <name> <address>[:port] [param*] 其中，每个参数含义如下：</p>
<ul>
<li>
<p>check：表示启用对此后端服务器执行健康状态检查。</p>
</li>
<li>
<p>inter：设置健康状态检查的时间间隔，单位为毫秒。</p>
</li>
<li>
<p>rise：设置从故障状态转换至正常状态需要成功检查的次数，例如。“rise 2”表示 2 次检查正确就认为此服务器可用。</p>
</li>
<li>
<p>fall：设置后端服务器从正常状态转换为不可用状态需要检查的次数，例如，“fall 3”表示 3 次检查失败就认为此服务器不可用。</p>
</li>
<li>
<p>cookie：为指定的后端服务器设定 cookie 值，此处指定的值将在请求入站时被检查，第一次为此值挑选的后端服务器将在后</p>
<table>
<tr>
	<td>name</td>
	<td colspan="2">为后端真实服务器指定一个内部名称，随便定义一个即可。</td>
</tr>
<tr>
	<td>address</td>
	<td colspan="2">后端真实服务器的 IP 地址或主机名。</td>
</tr>
<tr>
	<td>port</td>
  <td colspan="2">指定连接请求发往真实服务器时的目标端口。在未设定时，将使用客户端请求时的同一端口。</td>
</tr>
  <td rowspan="8">[params*]</td>
  <td colspan="2">为后端服务器设定的一系列参数，可用参数较多，仅介绍常用的参数：</td>
</tr>
</tr>
  <td>check</td>
	<td>表示启用对此后端服务器执行健康状态检查。</td>
</tr>
</tr>
  <td>inter</td>
	<td>设置健康检查的时间间隔，单位为毫秒。</td>
</tr>
</tr>
  <td>rise</td>
	<td>设置从故障状态转化为正常状态需要成功检查的次数，例如：“rise：2”表示两次检查正确就认为此服务可用。</td>
</tr>
</tr>
  <td>fall</td>
	<td>设置后端服务器从正常状态转换为不可用状态需要检查的次数，例如：“fall：3”表示三次检查失败就认为此服务器不可用。</td>
</tr>
</tr>
  <td>cookie</td>
	<td>为指定的后端服务器设置 cookie 值，此处指定的值将在请求入站时被检查，第一次为此值挑选的后端服务器将在后续的请求中一直被选中，其目的在于实现持久连接的功能。上面的“cookie server1” 表示 web1 的 serverid 为 server1。同理，“cookie server2” 表示 web2 的 serverid 为 server2。</td>
</tr>
</tr>
  <td>weight</td>
	<td>设置后端真实服务器的权重，默认为 1，最大值为 256。设置为 0 表示不参与负载均衡。</td>
</tr>
</tr>
  <td>backup</td>
	<td>设置后端真实服务器的备份服务器，仅仅在后端真实服务器均不可用时才会启用。</td>
</tr>
</table>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>listen</strong> 部分</p>
<p>此部分是 frontend 部分和 backend 部分的结合体。在 HAProxy1.3 版本之前，HAProxy 的所有配置选项都在这个部分中设置。为了保持兼容性，HAProxy 新的版本仍然保留了 listen 组件的配置方式。目前在 HAProxy 中，两种配置方式任选其一即可。</p>
<p>这个部分通过listen 关键字定义了一个名为“admin_stats”的实例，其实就是定义了一个 HAProxy 的监控页面，每个选项的含义如下：</p>
<ul>
<li>stats refresh：设置 HAProxy 监控统计页面自动刷新的时间。</li>
<li>stats uri：设置 HAProxy 监控统计页面的URL 路径，可随意指定。例如、指定“stats uri /haproxy-status”，就可以过 http://IP:9188/haproxy-status  查看。</li>
<li>stats realm：设置登录 HAProxy 统计页面时密码框上的文本提示信息。</li>
<li>stats auth：设置登录 HAProxy 统计页面的用户名和密码。用户名和密码通过冒号分割。可为监控页面设置多个用户名和密码，每行一个。</li>
<li>stats hide-version：用来隐藏统计页面上 HAProxy 的版本信息。</li>
<li>stats admin if TRUE：通过设置此选项，可以在监控页面上手工启用或禁用后端真实服务器，仅在 haproxy1.4.9 以后版本有效。</li>
</ul>
</li>
</ul>
<p><strong>一份完整的配置</strong></p>
<pre><code class="language-c">global
    log 127.0.0.1 local0 info 
    maxconn 4096
    user nobody 
    group nobody 
    daemon 
    nbproc 1
    pidfile /usr/local/haproxy/logs/haproxy.pid
defaults
    mode http 
    retries 3
    timeout connect 10s 
    timeout client 20s 
    timeout server 30s
    timeout check 5s
frontend www
    bind *:80 
    mode	http
    option	httplog 
    option	forwardfor
    option	httpclose 
    log	global
    #acl host_www	hdr_dom(host)	-i	www.zb.com
    #acl host_img	hdr_dom(host)	-i	img.zb.com
 
    #use_backend htmpool	if	host_www 
    #use_backend imgpool	if	host_img 
    default_backend	htmpool
backend htmpool
    mode http 
    option	redispatch
    option	abortonclose 
    balance  static-rr 
    cookie	SERVERID
    option	httpchk GET /index.jsp
    server	237server 192.168.81.237:8080 cookie server1 weight 6 check inter 2000 rise 2 fall 3
    server	iivey234 192.168.81.234:8080 cookie server2 weight 3 check inter 2000 rise 2 fall 3
backend imgpool
    mode		http 
    option	redispatch
    option	abortonclose
     balance  static-rr 
    cookie  SERVERID
    option	httpchk GET /index.jsp
    server	host236 192.168.81.236:8080 cookie server1 weight 6 check inter 2000 rise 2 fall 3
 
listen admin_stats
    bind 0.0.0.0:9188
    mode http
    log 127.0.0.1 local0 err 
    stats refresh 30s
    stats uri /haproxy-status
    stats realm welcome login\ Haproxy 
    stats auth admin:admin123
    stats hide-version 
    stats admin if TRUE
   
</code></pre>
<p><strong>安装HAProxy</strong></p>
<p>下载HAProxy相关版本，这里下载haproxy-1.8.12.tar.gz，之后准备安装。</p>
<p>安装之前查看内核版本，根据内核版本选择编译参数</p>
<pre><code class="language-c">uname -r
</code></pre>
<p>解压HAProxy，并安装：</p>
<pre><code class="language-c">tar xf haproxy-1.8.12.tar.gz
cd haproxy-1.7.5
make TARGET=linux2628 PREFIX=/usr/local/haproxy
make install PREFIX=/usr/local/haproxy
</code></pre>
<p>安装成功之后，查看版本</p>
<pre><code class="language-c">/usr/local/haproxy/sbin/haproxy -v
</code></pre>
<p><strong>配置HAProxy</strong></p>
<p>配置启动文件，复制haproxy文件到/usr/sbin下 ，复制haproxy脚本，到/etc/init.d下</p>
<pre><code class="language-c">cp /usr/local/haproxy/sbin/haproxy /usr/sbin/
cp ./examples/haproxy.init /etc/init.d/haproxy
chmod 755 /etc/init.d/haproxy
</code></pre>
<p>创建系统账号</p>
<pre><code class="language-c">useradd -r haproxy
</code></pre>
<p>创建配置文件</p>
<pre><code class="language-c">mkdir /etc/haproxy
vi /etc/haproxy/haproxy.cfg
</code></pre>
<p>更改配置文件</p>
<pre><code class="language-c">#全局配置
global
    #设置日志
    log 127.0.0.1 local0 info
    #当前工作目录
    chroot /usr/local/haproxy
    #用户与用户组
    user haproxy
    group haproxy
    #运行进程ID
    uid 99
    gid 99
    #守护进程启动
    daemon
    #最大连接数
    maxconn 4096

#默认配置
defaults
    #应用全局的日志配置
    log global
    #默认的模式mode {tcp|http|health}
    #TCP是4层，HTTP是7层，health只返回OK
    mode tcp
    #日志类别tcplog
    option tcplog
    #不记录健康检查日志信息
    option dontlognull
    #3次失败则认为服务不可用
    retries 3
    #每个进程可用的最大连接数
    maxconn 2000
    #连接超时
    timeout connect 5s
    #客户端超时
    timeout client 120s
    #服务端超时
    timeout server 120s

#绑定配置
listen rabbitmq_cluster 
        bind 0.0.0.0:5671
        #配置TCP模式
        mode tcp
        #简单的轮询
        balance roundrobin
        #RabbitMQ集群节点配置
        server rmq_node1 10.110.8.34:5672 check inter 5000 rise 2 fall 3 weight 1
        server rmq_node2 10.110.8.38:5672 check inter 5000 rise 2 fall 3 weight 1

#haproxy监控页面地址
listen monitor 
        bind 0.0.0.0:8100
        mode http
        option httplog
        stats enable
        stats uri /stats
        stats refresh 5s
</code></pre>
<p><strong>启动haproxy</strong></p>
<pre><code class="language-c">service haproxy start
</code></pre>
<p>Haproxy 解决集群 session 共享问题，二种方法保持客户端 session 一致。</p>
<ul>
<li>
<p>用户 IP 识别</p>
<p>Haproxy 将用户 IP 经过 hash 计算后 指定到固定的真实服务器上（类似于 nginx 的 IP hash 指令）。</p>
<p>配置指令： balance source。</p>
<pre><code class="language-c">backend htmpool
        mode http
        option redispatch
        option abortonclose
        balance source
        cookie SERVERID
        option httpchk GET /index.jsp
        server 237server 192.168.81.237:8080 cookie server1 weight 6 check inter 2000 rise 2 fall 3
        server iivey234 192.168.81.234:8080 cookie server2 weight 3 check inter 2000 rise 2 fall 3
</code></pre>
</li>
<li>
<p>cookie 识别</p>
<p>haproxy 将WEB 服务端发送给客户端的 cookie 中插入(或添加加前缀)haproxy 定义的后端的服务器COOKIE ID。</p>
<p>配置指令例举 cookie SESSION_COOKIE insert indirect nocache。</p>
<pre><code class="language-c">backend htmpool
        mode http
        option    redispatch
        option    abortonclose
        balance  static-rr
        cookie    SERVERID   #cookie参数
        option    httpchk GET /index.jsp
        server    237server 192.168.81.237:8080 cookie server1 weight 6 check inter 2000 rise 2 fall 3   #server里面的cookie参数
        server    iivey234 192.168.81.234:8080 cookie server2 weight 3 check inter 2000 rise 2 fall 3   #server里面的cookie参数
</code></pre>
</li>
</ul>
<h3 id="activemq"><a class="header" href="#activemq">ActiveMQ</a></h3>
<p>ActiveMQ 介于 ZeroMQ 和 RabbitMQ 之间。类似于 ZeroMQ，它可以部署于代理模式和 P2P（点对点）模式。类似于 RabbitMQ，它易于实现高级场景，而且只需付出低消耗，被誉为消息中间件的“瑞士军刀”。</p>
<p>支持 OpenWire、Stomp、AMQP v1.0、MQTT v3.1、REST、Ajax、Webservice 等多种协议，完全支持 JMS1.1 和 J2EE 1.4规范（事务、持久化、XA消息），支持持久化到数据库。但是 ActiveMQ 不够轻巧，而且对于队列较多的情况支持不好，据说还有丢消息的情况。</p>
<h3 id="apollo"><a class="header" href="#apollo">Apollo</a></h3>
<p>Apache 称 Apollo 为最快、最强健的 STOMP（简单“流”文本定向消息协议，它提供了一个可互操作的连接模式，允许 STOMP 客户端与任意 STOMP 消息代理（Broker）进行交互。STOMP 协议由于设计简单，易于开发客户端，因此在多种语言和多种平台上得到广泛地应用）服务器。支持 STOMP、AMQP、MQTT、OpenWire 协议，支持 Topic、Queue、持久订阅等消费形式，支持对消息的多种处理，支持安全性处理，支持 REST 管理 API。</p>
<h3 id="kafka"><a class="header" href="#kafka">Kafka</a></h3>
<h4 id="简介-2"><a class="header" href="#简介-2">简介</a></h4>
<h5 id="kafka是什么"><a class="header" href="#kafka是什么">Kafka是什么</a></h5>
<p>Kafka是一种高吞吐量的分布式发布订阅消息系统（消息引擎系统），它可以处理消费者在网站中的所有动作流数据。 这种动作（网页浏览，搜索和其他用户的行动）是在现代网络上的许多社会功能的一个关键因素。 这些数据通常是由于吞吐量的要求而通过处理日志和日志聚合来解决。 对于像Hadoop一样的日志数据和离线分析系统，但又要求实时处理的限制，这是一个可行的解决方案。Kafka的目的是通过Hadoop的并行加载机制来统一线上和离线的消息处理，也是为了通过集群来提供实时的消息。</p>
<p>其实我们简单点理解就是系统A发送消息给kafka（消息引擎系统），系统B从kafka中读取A发送的消息。而kafka就是个中间商。</p>
<h5 id="消息系统简介"><a class="header" href="#消息系统简介">消息系统简介</a></h5>
<p>一个消息系统负责将数据从一个应用传递到另外一个应用，应用只需关注于数据，无需关注数据在两个或多个应用间是如何传递的。分布式消息传递基于可靠的消息队列，在客户端应用和消息系统之间异步传递消息。有两种主要的消息传递模式：<strong>点对点传递模式、发布-订阅模式。大部分的消息系统选用发布-订阅模式</strong>。<strong>Kafka就是一种发布-订阅模式</strong>。</p>
<p><strong>点对点消息传递模式</strong></p>
<p>在点对点消息系统中，消息持久化到一个队列中。此时，将有一个或多个消费者消费队列中的数据。但是一条消息只能被消费一次。当一个消费者消费了队列中的某条数据之后，该条数据则从消息队列中删除。该模式即使有多个消费者同时消费数据，也能保证数据处理的顺序。这种架构描述示意图如下：</p>
<p><img src="https://github.com/chou401/pic-md/raw/master/27da57a28c192b5f1b8eed58fd8765af.png" alt="img" /></p>
<p><strong>生产者发送一条消息到queue，只有一个消费者能收到</strong>。</p>
<p><strong>发布-订阅消息传递模式</strong></p>
<p>在发布-订阅消息系统中，消息被持久化到一个topic中。与点对点消息系统不同的是，消费者可以订阅一个或多个topic，消费者可以消费该topic中所有的数据，同一条数据可以被多个消费者消费，数据被消费后不会立马删除。在发布-订阅消息系统中，消息的生产者称为发布者，消费者称为订阅者。该模式的示例图如下：</p>
<p><img src="https://github.com/chou401/pic-md/raw/master/7de02b63e52a56b2e6b5288f5b249fca.png" alt="img" /></p>
<p><strong>发布者发送到topic的消息，只有订阅了topic的订阅者才会收到消息</strong>。</p>
<h5 id="kafka-简单理解"><a class="header" href="#kafka-简单理解">Kafka 简单理解</a></h5>
<p>上面我们提到kafka是个中间商，我们为什么不能去掉这个中间商呢，凭着我们的想象也会觉得去掉这些消息引擎系统会更好吧，那我们来谈谈消息引擎系统存在的意义：</p>
<p>原因就是“<strong>削峰填谷</strong>”。这四个字简直比消息引擎本身还要有名气。</p>
<p>所谓的“削峰填谷”就是指缓冲上下游瞬时突发流量，使其更平滑。特别是对于那种发送能力很强的上游系统，如果没有消息引擎的保护，“脆弱”的下游系统可能会直接被压垮导致全链路服务“雪崩”。但是，一旦有了消息引擎，它能够有效地对抗上游的流量冲击，真正做到将上游的“峰”填满到“谷”中，避免了流量的震荡。消息引擎系统的另一大好处在于发送方和接收方的松耦合，这也在一定程度上简化了应用的开发，减少了系统间不必要的交互。</p>
<p>我们想象一下在双11期间我们购物的情景来形象的理解一下削峰填谷，感受一下Kafka在这中间是怎么去“抗”峰值流量的吧：</p>
<p>当我们点击某个商品以后进入付费页面，可是这个简单的流程中就可能包含多个子服务，比如点击购买按钮会调用订单系统生成对应的订单，而处理该订单会依次调用下游的多个子系统服务 ，比如调用支付宝和微信支付的接口、查询你的登录信息、验证商品信息等。显然上游的订单操作比较简单，所以它的 TPS（每秒事务处理量） 要远高于处理订单的下游服务，因此如果上下游系统直接对接，势必会出现下游服务无法及时处理上游订单从而造成订单堆积的情形。特别是当出现类似于秒杀这样的业务时，上游订单流量会瞬时增加，可能出现的结果就是直接压跨下游子系统服务。</p>
<p>解决此问题的一个常见做法是我们对上游系统进行限速，但这种做法对上游系统而言显然是不合理的，毕竟问题并不出现在它那里。所以更常见的办法是引入像 Kafka 这样的消息引擎系统来对抗这种上下游系统 TPS 的错配以及瞬时峰值流量。</p>
<p>还是这个例子，当引入了 Kafka 之后。上游订单服务不再直接与下游子服务进行交互。当新订单生成后它仅仅是向 Kafka Broker 发送一条订单消息即可。类似地，下游的各个子服务订阅 Kafka 中的对应主题，并实时从该主题的各自分区（Partition）中获取到订单消息进行处理，从而实现了上游订单服务与下游订单处理服务的解耦。这样当出现秒杀业务时，Kafka 能够将瞬时增加的订单流量全部以消息形式保存在对应的主题中，既不影响上游服务的 TPS，同时也给下游子服务留出了充足的时间去消费它们。这就是 Kafka 这类消息引擎系统的最大意义所在。</p>
<h5 id="kafka-的优点特点"><a class="header" href="#kafka-的优点特点">Kafka 的优点特点</a></h5>
<ul>
<li>
<p>解耦</p>
<p>在项目启动之初来预测将来项目会碰到什么需求，是极其困难的。消息系统在处理过程中间插入了一个隐含的、基于数据的接口层，两边的处理过程都要实现这一接口。这允许你独立的扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束。</p>
</li>
<li>
<p>冗余（副本）</p>
<p>有些情况下，处理数据的过程会失败。除非数据被持久化，否则将造成丢失。消息队列把数据进行持久化直到它们已经被完全处理，通过这一方式规避了数据丢失风险。许多消息队列所采用的&quot;插入-获取-删除&quot;范式中，在把一个消息从队列中删除之前，需要你的处理系统明确的指出该消息已经被处理完毕，从而确保你的数据被安全的保存直到你使用完毕。</p>
</li>
<li>
<p>扩展性</p>
<p>因为消息队列解耦了你的处理过程，所以增大消息入队和处理的频率是很容易的，只要另外增加处理过程即可。不需要改变代码、不需要调节参数。扩展就像调大电力按钮一样简单。</p>
</li>
<li>
<p>灵活性&amp;峰值处理能力</p>
<p>在访问量剧增的情况下，应用仍然需要继续发挥作用，但是这样的突发流量并不常见；如果为以能处理这类峰值访问为标准来投入资源随时待命无疑是巨大的浪费。使用消息队列能够使关键组件顶住突发的访问压力，而不会因为突发的超负荷的请求而完全崩溃。</p>
</li>
<li>
<p>可恢复性</p>
<p>系统的一部分组件失效时，不会影响到整个系统。消息队列降低了进程间的耦合度，所以即使一个处理消息的进程挂掉，加入队列中的消息仍然可以在系统恢复后被处理。</p>
</li>
<li>
<p>顺序保证</p>
<p>在大多使用场景下，数据处理的顺序都很重要。大部分消息队列本来就是排序的，并且能保证数据会按照特定的顺序来处理。Kafka保证一个Partition内的消息的有序性。</p>
</li>
<li>
<p>缓冲</p>
<p>在任何重要的系统中，都会有需要不同的处理时间的元素。例如，加载一张图片比应用过滤器花费更少的时间。消息队列通过一个缓冲层来帮助任务最高效率的执行———写入队列的处理会尽可能的快速。该缓冲有助于控制和优化数据流经过系统的速度。</p>
</li>
<li>
<p>异步通信</p>
<p>很多时候，用户不想也不需要立即处理消息。消息队列提供了异步处理机制，允许用户把一个消息放入队列，但并不立即处理它。想向队列中放入多少消息就放多少，然后在需要的时候再去处理它们。</p>
</li>
</ul>
<h4 id="kafka中的术语解释概述"><a class="header" href="#kafka中的术语解释概述">Kafka中的术语解释概述</a></h4>
<p>下图展示了Kafka的相关术语以及之间的关系：</p>
<p><img src="https://github.com/chou401/pic-md/raw/master/dfef98a36bb160ddd779634de5e6c4b4.png" alt="dfef98a36bb160ddd779634de5e6c4b4" /></p>
<ul>
<li>上图中一个topic配置了3个partition。Partition1有两个offset：0和1。Partition2有4个offset。Partition3有1个offset。副本的id和副本所在的机器的id恰好相同。</li>
<li>如果一个topic的副本数为3，那么Kafka将在集群中为每个partition创建3个相同的副本。集群中的每个broker存储一个或多个partition。多个producer和consumer可同时生产和消费数据。</li>
</ul>
<h5 id="broker"><a class="header" href="#broker">broker</a></h5>
<ul>
<li>Kafka 集群包含一个或多个服务器，服务器节点称为broker。</li>
<li>broker存储topic的数据。如果某topic有N个partition，集群有N个broker，那么每个broker存储该topic的一个partition。</li>
<li>如果某topic有N个partition，集群有(N+M)个broker，那么其中有N个broker存储该topic的一个partition，剩下的M个broker不存储该topic的partition数据。</li>
<li>如果某topic有N个partition，集群中broker数目少于N个，那么一个broker存储该topic的一个或多个partition。在实际生产环境中，尽量避免这种情况的发生，这种情况容易导致Kafka集群数据不均衡。</li>
</ul>
<h5 id="topic"><a class="header" href="#topic">Topic</a></h5>
<ul>
<li>每条发布到Kafka集群的消息都有一个类别，这个类别被称为Topic。（物理上不同Topic的消息分开存储，逻辑上一个Topic的消息虽然保存于一个或多个broker上但用户只需指定消息的Topic即可生产或消费数据而不必关心数据存于何处）。</li>
<li>类似于数据库的表名。</li>
</ul>
<h5 id="partition"><a class="header" href="#partition">Partition</a></h5>
<ul>
<li>topic中的数据分割为一个或多个partition。每个topic至少有一个partition。每个partition中的数据使用多个segment文件存储。partition中的数据是有序的，不同partition间的数据丢失了数据的顺序。如果topic有多个partition，消费数据时就不能保证数据的顺序。在需要严格保证消息的消费顺序的场景下，需要将partition数目设为1。</li>
</ul>
<h5 id="producer"><a class="header" href="#producer">Producer</a></h5>
<ul>
<li>生产者即数据的发布者，该角色将消息发布到Kafka的topic中。broker接收到生产者发送的消息后，broker将该消息<strong>追加</strong>到当前用于追加数据的segment文件中。生产者发送的消息，存储到一个partition中，生产者也可以指定数据存储的partition。</li>
</ul>
<h5 id="consumer"><a class="header" href="#consumer">Consumer</a></h5>
<ul>
<li>消费者可以从broker中读取数据。消费者可以消费多个topic中的数据。</li>
</ul>
<h5 id="consumer-group"><a class="header" href="#consumer-group">Consumer Group</a></h5>
<ul>
<li>每个Consumer属于一个特定的Consumer Group（可为每个Consumer指定group name，若不指定group name则属于默认的group）。</li>
</ul>
<h5 id="leader"><a class="header" href="#leader">Leader</a></h5>
<ul>
<li>每个partition有多个副本，其中有且仅有一个作为Leader，Leader是当前负责数据的读写的partition。</li>
</ul>
<h5 id="follower"><a class="header" href="#follower">Follower</a></h5>
<ul>
<li>Follower跟随Leader，所有写请求都通过Leader路由，数据变更会广播给所有Follower，Follower与Leader保持数据同步。如果Leader失效，则从Follower中选举出一个新的Leader。当Follower与Leader挂掉、卡住或者同步太慢，leader会把这个follower从“in sync replicas”（ISR）列表中删除，重新创建一个Follower。</li>
</ul>
<h4 id="kafka架构"><a class="header" href="#kafka架构">Kafka架构</a></h4>
<p><img src="https://github.com/chou401/pic-md/raw/master/cb62ef93fb5ef2f406a1ed0fe3a079a8.png" alt="img" /></p>
<p>如上图所示，一个典型的Kafka集群中包含若干Producer（可以是web前端产生的Page View，或者是服务器日志，系统CPU、Memory等），若干broker（Kafka支持水平扩展，一般broker数量越多，集群吞吐率越高），若干Consumer Group，以及一个Zookeeper集群。Kafka通过Zookeeper管理集群配置，选举leader，以及在Consumer Group发生变化时进行rebalance。Producer使用push模式将消息发布到broker，Consumer使用pull模式从broker订阅并消费消息。</p>
<h5 id="topics和partition"><a class="header" href="#topics和partition">Topics和Partition</a></h5>
<p>Topic在逻辑上可以被认为是一个queue，每条消费都必须指定它的Topic，可以简单理解为必须指明把这条消息放进哪个queue里。为了使得Kafka的吞吐率可以线性提高，物理上把Topic分成一个或多个Partition，每个Partition在物理上对应一个文件夹，该文件夹下存储这个Partition的所有消息和索引文件。创建一个topic时，同时可以指定分区数目，分区数越多，其吞吐量也越大，但是需要的资源也越多，同时也会导致更高的不可用性，kafka在接收到生产者发送的消息之后，会根据均衡策略将消息存储到不同的分区中。<strong>因为每条消息都被append到该Partition中，属于顺序写磁盘</strong>，因此效率非常高（经验证，顺序写磁盘效率比随机写内存还要高，这是Kafka高吞吐率的一个很重要的保证）。</p>
<p><img src="https://github.com/chou401/pic-md/raw/master/ce47715713754188bd90492eaec2b67c.png" alt="img" /></p>
<p>对于传统的message queue而言，一般会删除已经被消费的消息，而Kafka集群会保留所有的消息，无论其被消费与否。当然，因为磁盘限制，不可能永久保留所有数据（实际上也没必要），因此Kafka提供两种策略删除旧数据。一是基于时间，二是基于Partition文件大小。例如可以通过配置$KAFKA_HOME/config/server.properties，让Kafka删除一周前的数据，也可在Partition文件超过1GB时删除旧数据，配置如下所示：</p>
<pre><code class="language-properties"> 符合删除条件的日志文件的最小时间
log.retention.hours=168
 日志段文件的最大大小。当达到这个大小时，将创建一个新的日志段。
log.segment.bytes=1073741824
 检查日志段的时间间隔，以确定它们是否可以根据保留策略被删除
log.retention.check.interval.ms=300000
 如果设置了log.cleaner.enable =true，则清理器将被启用，然后可以为日志压缩标记单个日志。
log.cleaner.enable=f
</code></pre>
<p>因为Kafka读取特定消息的<strong>时间复杂度为O(1)</strong>，即与文件大小无关，所以这里删除过期文件与提高Kafka性能无关。选择怎样的删除策略只与磁盘以及具体的需求有关。另外，Kafka会为每一个Consumer Group保留一些metadata信息——当前消费的消息的position，也即offset。这个offset由Consumer控制。正常情况下Consumer会在消费完一条消息后递增该offset。当然，Consumer也可将offset设成一个较小的值，重新消费一些消息。因为offset由Consumer控制，所以Kafka broker是无状态的，它不需要标记哪些消息被哪些消费过，也不需要通过broker去保证同一个Consumer Group只有一个Consumer能消费某一条消息，因此也就不需要锁机制，这也为Kafka的高吞吐率提供了有力保障。</p>
<h5 id="producer消息路由"><a class="header" href="#producer消息路由">Producer消息路由</a></h5>
<p>Producer发送消息到broker时，会根据Paritition机制选择将其存储到哪一个Partition。如果Partition机制设置合理，所有消息可以均匀分布到不同的Partition里，这样就实现了负载均衡。如果一个Topic对应一个文件，那这个文件所在的机器I/O将会成为这个Topic的性能瓶颈，而有了Partition后，不同的消息可以并行写入不同broker的不同Partition里，极大的提高了吞吐率。可以在$KAFKA_HOME/config/server.properties中通过配置项num.partitions来指定新建Topic的默认Partition数量，也可在创建Topic时通过参数指定，同时也可以在Topic创建之后通过Kafka提供的工具修改。</p>
<p>在发送一条消息时，可以指定这条消息的key，Producer根据这个key和Partition机制来判断应该将这条消息发送到哪个Partition。Paritition机制可以通过指定Producer的paritition.class这一参数来指定，该class必须实现kafka.producer.Partitioner接口。</p>
<h5 id="consumer-group-1"><a class="header" href="#consumer-group-1">Consumer Group</a></h5>
<p>使用Consumer high level API时，同一Topic的一条消息只能被同一个Consumer Group内的一个Consumer消费，但多个Consumer Group可同时消费这一消息。</p>
<p><img src="https://github.com/chou401/pic-md/raw/master/edd5bf39ad20cf985f45988c75446af7.png" alt="img" /></p>
<p>这是<strong>Kafka用来实现一个Topic消息的广播（发给所有的Consumer）和单播（发给某一个Consumer）的手段</strong>。一个Topic可以对应多个Consumer Group。如果需要实现广播，只要每个Consumer有一个独立的Group就可以了。要实现单播只要所有的Consumer在同一个Group里。用Consumer Group还可以将Consumer进行自由的分组而不需要多次发送消息到不同的Topic。</p>
<p>实际上，<strong>Kafka的设计理念之一就是同时提供离线处理和实时处理</strong>。根据这一特性，可以使用Storm这种实时流处理系统对消息进行实时在线处理，同时使用Hadoop这种批处理系统进行离线处理，还可以同时将数据实时备份到另一个数据中心，只需要保证这三个操作所使用的Consumer属于不同的Consumer Group即可。</p>
<h5 id="push与pull"><a class="header" href="#push与pull">Push与Pull</a></h5>
<p>作为一个消息系统，Kafka遵循了传统的方式，选择由<strong>Producer向broker push消息并由Consumer从broker pull消息</strong>。一些logging-centric system，比如Facebook的Scribe和Cloudera的Flume，采用push模式。事实上，push模式和pull模式各有优劣。</p>
<p>push模式很难适应消费速率不同的消费者，因为消息发送速率是由broker决定的。push模式的目标是尽可能以最快速度传递消息，但是这样很容易造成Consumer来不及处理消息，典型的表现就是拒绝服务以及网络拥塞。而pull模式则可以根据Consumer的消费能力以适当的速率消费消息。</p>
<p><strong>对于Kafka而言，pull模式更合适</strong>。pull模式可简化broker的设计，Consumer可自主控制消费消息的速率，同时Consumer可以自己控制消费方式——<strong>即可批量消费也可逐条消费</strong>，同时还能选择不同的提交方式从而实现不同的传输语义。</p>
<h5 id="kafka-delivery-guarantee"><a class="header" href="#kafka-delivery-guarantee">Kafka delivery guarantee</a></h5>
<p>有这么几种可能的delivery guarantee：</p>
<blockquote>
<p>At most once 　　消息可能会丢，但绝不会重复传输</p>
<p>At least one 　　  消息绝不会丢，但可能会重复传输</p>
<p>Exactly once 　　 每条消息肯定会被传输一次且仅传输一次，很多时候这是用户所想要的。</p>
</blockquote>
<p>当Producer向broker发送消息时，一旦这条消息被commit，因为replication的存在，它就不会丢。但是如果Producer发送数据给broker后，遇到网络问题而造成通信中断，那Producer就无法判断该条消息是否已经commit。虽然Kafka无法确定网络故障期间发生了什么，但是Producer可以生成一种类似于主键的东西，发生故障时幂等性的重试多次，这样就做到了Exactly once。</p>
<p>接下来讨论的是消息从broker到Consumer的delivery guarantee语义。（仅针对Kafka consumer high level API）。Consumer在从broker读取消息后，可以选择commit，该操作会在Zookeeper中保存该Consumer在该Partition中读取的消息的offset。该Consumer下一次再读该Partition时会从下一条开始读取。如未commit，下一次读取的开始位置会跟上一次commit之后的开始位置相同。当然可以将Consumer设置为autocommit，即Consumer一旦读到数据立即自动commit。如果只讨论这一读取消息的过程，那Kafka是确保了Exactly once。但实际使用中应用程序并非在Consumer读取完数据就结束了，而是要进行进一步处理，而数据处理与commit的顺序在很大程度上决定了消息从broker和consumer的delivery guarantee semantic。</p>
<p><strong>Kafka默认保证At least once</strong>，并且允许通过设置Producer异步提交来实现At most once。而Exactly once要求与外部存储系统协作，幸运的是Kafka提供的offset可以非常直接非常容易的使用这种方式。</p>
<h5 id="ack-机制"><a class="header" href="#ack-机制">ack 机制</a></h5>
<p>producer端设置<code>request.required.acks</code>。</p>
<ul>
<li><strong>request.required.acks = 0</strong>：只要请求已发送出去，就算是发送完了，不关心有没有写成功。性能很好，如果是对一些日志进行分析，可以承受丢数据的情况，用这个参数，性能会很好。吞吐量高。</li>
<li><strong>request.required.acks = 1（默认）</strong>：发送一条消息，当leader partition写入成功以后，才算写入成功。不过这种方式也有丢数据的可能。</li>
<li><strong>request.required.acks = -1/all</strong>：需要ISR列表里面，所有 replica 都写完以后，这条消息才算写入成功。这才是 ISR 的正确应用场景，可靠性最高。</li>
</ul>
<p><strong>ISR 的最坏情况</strong></p>
<p>排除所有 replica 全部故障，ISR 的最坏情况就是 ISR 中只剩 leader 自己一个了。退化成 ack=1 的情况了，甚至还不如 ack=1。ack=1，说的是 producer 不等服务器完全同步完 ISR，只要 leader 写入成功就行了，但是可没说不进行同步了。该有的同步过程还是会进行的，但凡能同步，kafka 肯定会同步的，而 ack=1 的最坏情况，也是 ISR 只剩下 leader 了。坏疽话说，producer 为了提高吞吐量，没等 ISR 全部同步，但是心里还是希望接口同步完成的。而这种 leader 孤家寡人的最坏情况，书上说“退化成 ack=1”，不足以说明问题的严重性。</p>
<p>ISR 的最坏情况，会使 ack=-1 退化成 ack=1 的最坏情况，完全背离我们设置-1 的初衷（因为特定是同步不了了）。</p>
<p>数据不丢失的方案：</p>
<ol>
<li>分区副本 &gt;= 2</li>
<li>acks = -1</li>
<li>min.insync.replicas &gt;= 2</li>
</ol>
<p>下面给出此时leader出现故障的情况，可以看出，此时数据可能重复。</p>
<p><img src="https://github.com/chou401/pic-md/raw/master/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5ZSP5ZmX,size_20,color_FFFFFF,t_70,g_se,x_16.jpeg" alt="img" /></p>
<p>Leader维护了⼀个动态的 in-sync replica set（ISR）：和 Leader 保持同步的 Follower 集合。当 ISR 集合中的 Follower 完成数据的同步之后，Leader 就会给 Follower 发送 ACK。如果 Follower ⻓时间未向 Leader 同步数据，则该 Follower 将被踢出 ISR 集合，该时间阈值由replica.lag.time.max.ms 参数设定。Leader 发⽣故障后，就会从 ISR 中选举出新的 Leader。
kafka服务端中min.insync.replicas。 如果我们不设置的话，默认这个值是1。一个leader partition会维护一个ISR列表，这个值就是限制ISR列表里面 至少得有几个副本，比如这个值是2，那么当ISR列表里面只有一个副本的时候，往这个分区插入数据的时候会报错。</p>
<h4 id="kafka高可用"><a class="header" href="#kafka高可用">Kafka高可用</a></h4>
<h5 id="高可用的由来"><a class="header" href="#高可用的由来">高可用的由来</a></h5>
<p><strong>为何需要Replication</strong></p>
<ul>
<li>Kafka在0.8以前的版本中，是没有Replication的，一旦某一个Broker宕机，则其上所有的Partition数据都不可被消费，这与Kafka数据持久性及Delivery Guarantee的设计目标相悖。同时Producer都不能再将数据存于这些Partition中。</li>
<li>如果Producer使用同步模式则Producer会在尝试重新发送message.send.max.retries（默认值为3）次后抛出Exception，用户可以选择停止发送后续数据也可选择继续选择发送。而前者会造成数据的阻塞，后者会造成本应发往该Broker的数据的丢失。</li>
<li>如果Producer使用异步模式，则Producer会尝试重新发送message.send.max.retries（默认值为3）次后记录该异常并继续发送后续数据，这会造成数据丢失并且用户只能通过日志发现该问题。同时，Kafka的Producer并未对异步模式提供callback接口。</li>
<li>由此可见，在没有Replication的情况下，一旦某机器宕机或者某个Broker停止工作则会造成整个系统的可用性降低。随着集群规模的增加，整个集群中出现该类异常的几率大大增加，因此对于生产系统而言Replication机制的引入非常重要。</li>
</ul>
<p><strong>Leader Election（选举机制）</strong></p>
<ul>
<li>引入Replication之后，同一个Partition可能会有多个Replica，而这时需要在这些Replication之间选出一个Leader，Producer和Consumer只与这个Leader交互，其它Replica作为Follower从Leader中复制数据。</li>
<li>因为需要保证同一个Partition的多个Replica之间的数据一致性（其中一个宕机后其它Replica必须要能继续服务并且即不能造成数据重复也不能造成数据丢失）。如果没有一个Leader，所有Replica都可同时读/写数据，那就需要保证多个Replica之间互相（N×N条通路）同步数据，数据的一致性和有序性非常难保证，大大增加了Replication实现的复杂性，同时也增加了出现异常的几率。而引入Leader后，只有Leader负责数据读写，Follower只向Leader顺序Fetch数据（N条通路），系统更加简单且高效。</li>
</ul>
<h5 id="kafka-ha设计解析"><a class="header" href="#kafka-ha设计解析">Kafka HA设计解析</a></h5>
<p><strong>如何将所有Replica均匀分布到整个集群</strong></p>
<p>为了更好的做负载均衡，Kafka尽量将所有的Partition均匀分配到整个集群上。一个典型的部署方式是一个Topic的Partition数量大于Broker的数量。同时为了提高Kafka的容错能力，也需要将同一个Partition的Replica尽量分散到不同的机器。实际上，如果所有的Replica都在同一个Broker上，那一旦该Broker宕机，该Partition的所有Replica都无法工作，也就达不到HA的效果。同时，如果某个Broker宕机了，需要保证它上面的负载可以被均匀的分配到其它幸存的所有Broker上。</p>
<p>Kafka分配Replica的算法如下：</p>
<ol>
<li>将所有Broker（假设共n个Broker）和待分配的Partition排序。</li>
<li>将第i个Partition分配到第（i mod n）个Broker上。</li>
<li>将第i个Partition的第j个Replica分配到第（(i + j) mode n）个Broker上。</li>
</ol>
<p><strong>Data Replication（副本策略）</strong></p>
<p>Kafka的高可靠性的保障来源于其健壮的副本（replication）策略。 </p>
<p><strong>1.消息传递同步策略</strong></p>
<p>Producer在发布消息到某个Partition时，先通过ZooKeeper找到该Partition的Leader，然后无论该Topic的Replication Factor为多少，Producer只将该消息发送到该Partition的Leader。Leader会将该消息写入其本地Log。每个Follower都从Leader pull数据。这种方式上，Follower存储的数据顺序与Leader保持一致。Follower在收到该消息并写入其Log后，向Leader发送ACK。一旦Leader收到了ISR中的所有Replica的ACK，该消息就被认为已经commit了，Leader将增加HW并且向Producer发送ACK。</p>
<p>为了提高性能，<strong>每个Follower在接收到数据后就立马向Leader发送ACK，而非等到数据写入Log中</strong>。因此，对于已经commit的消息，Kafka只能保证它被存于多个Replica的内存中，而不能保证它们被持久化到磁盘中，也就不能完全保证异常发生后该条消息一定能被Consumer消费。</p>
<p>Consumer读消息也是从Leader读取，<strong>只有被commit过的消息才会暴露给Consumer</strong>。</p>
<p>Kafka Replication的数据流如下图所示：</p>
<p><img src="https://github.com/chou401/pic-md/raw/master/image-20230703112926417.png" alt="image-20230703112926417" /></p>
<p><strong>2.ACK前需要保证有多少个备份</strong></p>
<p>对于Kafka而言，定义一个Broker是否“活着”包含两个条件：</p>
<ul>
<li>一是它必须维护与ZooKeeper的session（这个通过ZooKeeper的Heartbeat机制来实现）。</li>
<li>二是Follower必须能够及时将Leader的消息复制过来，不能“落后太多”。</li>
</ul>
<p>Leader会跟踪与其保持同步的Replica列表，该列表称为ISR（即in-sync Replica）。如果一个Follower宕机，或者落后太多，Leader将把它从ISR中移除。这里所描述的“落后太多”指Follower复制的消息落后于Leader后的条数超过预定值（该值可在$KAFKA_HOME/config/server.properties中通过replica.lag.max.messages配置，其默认值是4000）或者Follower超过一定时间（该值可在$KAFKA_HOME/config/server.properties中通过replica.lag.time.max.ms来配置，其默认值是10000）未向Leader发送fetch请求。</p>
<p>Kafka的复制机制既不是完全的同步复制，也不是单纯的异步复制。事实上，完全同步复制要求所有能工作的Follower都复制完，这条消息才会被认为commit，这种复制方式极大的影响了吞吐率（高吞吐率是Kafka非常重要的一个特性）。而异步复制方式下，Follower异步的从Leader复制数据，数据只要被Leader写入log就被认为已经commit，这种情况下如果Follower都复制完都落后于Leader，而如果Leader突然宕机，则会丢失数据。而Kafka的这种使用ISR的方式则很好的均衡了确保数据不丢失以及吞吐率。Follower可以批量的从Leader复制数据，这样极大的提高复制性能（批量写磁盘），极大减少了Follower与Leader的差距。</p>
<p>需要说明的是，Kafka只解决fail/recover，不处理“Byzantine”（“拜占庭”）问题。一条消息只有被ISR里的所有Follower都从Leader复制过去才会被认为已提交。这样就避免了部分数据被写进了Leader，还没来得及被任何Follower复制就宕机了，而造成数据丢失（Consumer无法消费这些数据）。而对于Producer而言，它可以选择是否等待消息commit，这可以通过request.required.acks来设置。这种机制确保了只要ISR有一个或以上的Follower，一条被commit的消息就不会丢失。</p>
<p><strong>3.Leader Election算法</strong></p>
<p>Leader选举本质上是一个分布式锁，有两种方式实现基于ZooKeeper的分布式锁：</p>
<ul>
<li>节点名称唯一性：多个客户端创建一个节点，只有成功创建节点的客户端才能获得锁。</li>
<li>临时顺序节点：所有客户端在某个目录下创建自己的临时顺序节点，只有序号最小的才获得锁。</li>
</ul>
<p>一种非常常用的选举leader的方式是“Majority Vote”（“少数服从多数”），但Kafka并未采用这种方式。这种模式下，如果我们有2f+1个Replica（包含Leader和Follower），那在commit之前必须保证有f+1个Replica复制完消息，为了保证正确选出新的Leader，fail的Replica不能超过f个。因为在剩下的任意f+1个Replica里，至少有一个Replica包含有最新的所有消息。这种方式有个很大的优势，系统的latency只取决于最快的几个Broker，而非最慢那个。Majority Vote也有一些劣势，为了保证Leader Election的正常进行，它所能容忍的fail的follower个数比较少。如果要容忍1个follower挂掉，必须要有3个以上的Replica，如果要容忍2个Follower挂掉，必须要有5个以上的Replica。也就是说，在生产环境下为了保证较高的容错程度，必须要有大量的Replica，而大量的Replica又会在大数据量下导致性能的急剧下降。这就是这种算法更多用在ZooKeeper这种共享集群配置的系统中而很少在需要存储大量数据的系统中使用的原因。例如HDFS的HA Feature是基于majority-vote-based journal，但是它的数据存储并没有使用这种方式。</p>
<p>Kafka在ZooKeeper中动态维护了一个ISR（in-sync replicas），这个ISR里的所有Replica都跟上了leader，只有ISR里的成员才有被选为Leader的可能。在这种模式下，对于f+1个Replica，一个Partition能在保证不丢失已经commit的消息的前提下容忍f个Replica的失败。在大多数使用场景中，这种模式是非常有利的。事实上，为了容忍f个Replica的失败，Majority Vote和ISR在commit前需要等待的Replica数量是一样的，但是ISR需要的总的Replica的个数几乎是Majority Vote的一半。</p>
<p>虽然Majority Vote与ISR相比有不需等待最慢的Broker这一优势，但是Kafka作者认为Kafka可以通过Producer选择是否被commit阻塞来改善这一问题，并且节省下来的Replica和磁盘使得ISR模式仍然值得。</p>
<p><strong>4.如何处理所有Replica都不工作</strong></p>
<p>在ISR中至少有一个follower时，Kafka可以确保已经commit的数据不丢失，但如果某个Partition的所有Replica都宕机了，就无法保证数据不丢失了。这种情况下有两种可行的方案：</p>
<ol>
<li>等待ISR中的任一个Replica“活”过来，并且选它作为Leader</li>
<li>选择第一个“活”过来的Replica（不一定是ISR中的）作为Leader</li>
</ol>
<p>这就需要在可用性和一致性当中作出一个简单的折衷。如果一定要等待ISR中的Replica“活”过来，那不可用的时间就可能会相对较长。而且如果ISR中的所有Replica都无法“活”过来了，或者数据都丢失了，这个Partition将永远不可用。选择第一个“活”过来的Replica作为Leader，而这个Replica不是ISR中的Replica，那即使它并不保证已经包含了所有已commit的消息，它也会成为Leader而作为consumer的数据源（前文有说明，所有读写都由Leader完成）。Kafka0.8.*使用了第二种方式。根据Kafka的文档，在以后的版本中，Kafka支持用户通过配置选择这两种方式中的一种，从而根据不同的使用场景选择高可用性还是强一致性。</p>
<p><strong>5.选举Leader</strong></p>
<p>最简单最直观的方案是，所有Follower都在ZooKeeper上设置一个Watch，一旦Leader宕机，其对应的ephemeral znode会自动删除，此时所有Follower都尝试创建该节点，而创建成功者（ZooKeeper保证只有一个能创建成功）即是新的Leader，其它Replica即为Follower。</p>
<p>但是该方法会有3个问题：</p>
<ul>
<li><strong>split-brain</strong>： 这是由ZooKeeper的特性引起的，虽然ZooKeeper能保证所有Watch按顺序触发，但并不能保证同一时刻所有Replica“看”到的状态是一样的，这就可能造成不同Replica的响应不一致</li>
<li><strong>herd effect</strong>： 如果宕机的那个Broker上的Partition比较多，会造成多个Watch被触发，造成集群内大量的调整</li>
<li><strong>ZooKeeper负载过重</strong>： 每个Replica都要为此在ZooKeeper上注册一个Watch，当集群规模增加到几千个Partition时ZooKeeper负载会过重。</li>
</ul>
<p>Kafka 0.8.*的<strong>Leader Election</strong>方案解决了上述问题，它在所有broker中选出一个controller，所有Partition的Leader选举都由controller决定。controller会将Leader的改变直接通过RPC的方式（比ZooKeeper Queue的方式更高效）通知需为此作为响应的Broker。同时controller也负责增删Topic以及Replica的重新分配。</p>
<h5 id="arisrleohw"><a class="header" href="#arisrleohw">AR、ISR、LEO、HW</a></h5>
<ul>
<li><strong>AR</strong>：  Assigned Replicas的缩写，是每个partition下所有副本（replicas）的统称；</li>
<li><strong>ISR</strong>： 副本同步队列（In-Sync Replicas）的缩写，是指副本同步队列，ISR是AR中的一个子集；</li>
<li><strong>LEO</strong>：日志末端位移（Log End Offset）的缩写，表示每个partition的log最后一条Message的位置。新消息写入时将分配的偏移量（Offset）值，从0开始，随着消息不断写入递增。</li>
<li><strong>HW</strong>： 高水位（High Watermark）的缩写，是指consumer能够看到的此partition的位置。 取一个partition对应的ISR中最小的LEO作为HW，consumer最多只能消费到HW所在的位置。</li>
</ul>
<p>kafka 中为了防止 log 文件过大导致数据定位效率低下而采取了分片和索引机制，将每个物理上的 partition 分为多个 segment。每个 segment 对应两个文件--“.index&quot;文件和”.log“文件。”.index“ 文件存储大量的索引信息，”.log&quot; 文件存储大量的数据，索引文件中的元数据指向对应数据文件中 message 的物理偏移地址。</p>
<p>但是对于上层应用来说，可以将partition看成最小的存储单元（一个由多个segment文件拼接而成的“巨型”文件），每个partition都由一些列有序的、不可变的消息组成，这些消息被连续的追加到partition中。</p>
<p><img src="https://github.com/chou401/pic-md/raw/master/image-20230703112608060.png" alt="image-20230703112608060" /></p>
<p><strong>ISR和AR</strong></p>
<p>ISR (In-Sync Replicas)，这个是指副本同步队列。副本数对Kafka的吞吐率是有一定的影响，但极大的增强了可用性。默认情况下Kafka的replica数量为1，即每个partition都有一个唯一的leader，为了确保消息的可靠性，通常应用中将其值(由broker的参数offsets.topic.replication.factor指定)大小设置为大于1，比如3。 所有的副本（replicas）统称为Assigned Replicas，即AR。ISR是AR中的一个子集，由leader维护ISR列表，follower从leader同步数据有一些延迟（包括延迟时间replica.lag.time.max.ms和延迟条数replica.lag.max.messages两个维度, 从 0.9.0.0 版本后中只支持replica.lag.time.max.ms这个维度），任意一个超过阈值都会把follower剔除出ISR, 存入OSR（Outof-Sync Replicas）列表，新加入的follower也会先存放在OSR中。<strong>AR=ISR+OSR</strong>。</p>
<p><img src="https://github.com/chou401/pic-md/raw/master/image202304051925825.png" alt="image-20210918150431039" /></p>
<p><strong>为什么在Kafka 0.9.0.0版本后移除了replica.lag.max.messages参数而只保留了replica.lag.time.max.ms作为ISR中副本管理的参数呢？</strong></p>
<p>replica.lag.max.messages表示当前某个副本落后leader的消息数量超过了这个参数的值，那么leader就会把follower从ISR中删除。假设设置replica.lag.max.messages=4，那么如果producer一次传送至broker的消息数量都小于4条时，因为在leader接受到producer发送的消息之后而follower副本开始拉取这些消息之前，follower落后leader的消息数不会超过4条消息，故此没有follower移出ISR，所以这时候replica.lag.max.message的设置似乎是合理的。但是producer发起瞬时高峰流量，producer一次发送的消息超过4条时，也就是超过replica.lag.max.messages，此时follower都会被认为是与leader副本不同步了，从而被踢出了ISR。但实际上这些follower都是存活状态的且没有性能问题。那么在之后追上leader,并被重新加入了ISR。于是就会出现它们不断地剔出ISR然后重新回归ISR，这无疑增加了无谓的性能损耗。而且这个参数是broker全局的。设置太大了，影响真正“落后”follower的移除；设置的太小了，导致follower的频繁进出。无法给定一个合适的replica.lag.max.messages的值，故此，新版本的Kafka移除了这个参数。</p>
<p><strong>HW和LEO</strong></p>
<p>上面有简单说到HW是HighWatermark的缩写，是指consumer能够看到的此partition的位置；而LEO是LogEndOffset的缩写，表示每个partition的log最后一条Message的位置。也就是，我们取一个partition对应的ISR中最小的LEO作为HW，consumer最多只能消费到HW所在的位置。<strong>消费者能消费的数据 = [LW，HW）</strong>。</p>
<p>每个replica都有自己的HW，leader和follower各自负责更新自己的HW的状态。对于leader新写入的消息，consumer不能立刻消费，leader会等待该消息被所有ISR中的replicas同步后更新HW，此时消息才能被consumer消费。这样就保证了如果leader所在的broker失效，该消息仍然可以从新选举的leader中获取。对于来自内部broker的读取请求，没有HW的限制。</p>
<p><img src="https://github.com/chou401/pic-md/raw/master/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzIzMDY4Mg==,size_16,color_FFFFFF,t_70.png" alt="img" /></p>
<p><strong>由此可见，Kafka的复制机制既不是完全的同步复制，也不是单纯的异步复制。</strong></p>
<p>事实上，同步复制要求所有能工作的follower都复制完，这条消息才会被commit，这种复制方式极大的影响了吞吐率。而异步复制方式下，follower异步的从leader复制数据，数据只要被leader写入log就被认为已经commit，这种情况下如果follower都还没有复制完，落后于leader时，突然leader宕机，则会丢失数据。而Kafka的这种使用ISR的方式则很好的均衡了确保数据不丢失以及吞吐率。</p>
<p>Kafka的ISR的管理最终都会反馈到Zookeeper节点上。具体位置为：<strong>/brokers/topics/[topic]/partitions/[partition]/state</strong></p>
<p><strong>目前有两个地方会对这个Zookeeper的节点进行维护：</strong></p>
<ol>
<li>Controller来维护：Kafka集群中的其中一个Broker会被选举为Controller，主要负责Partition管理和副本状态管理，也会执行类似于重分配partition之类的管理任务。在符合某些特定条件下，Controller下的LeaderSelector会选举新的leader，ISR和新的leader_epoch及controller_epoch写入Zookeeper的相关节点中。同时发起LeaderAndIsrRequest通知所有的replicas。</li>
<li>leader来维护：leader有单独的线程定期检测ISR中follower是否脱离ISR, 如果发现ISR变化，则会将新的ISR的信息返回到Zookeeper的相关节点中。</li>
</ol>
<h4 id="ha相关zookeeper结构"><a class="header" href="#ha相关zookeeper结构">HA相关ZooKeeper结构</a></h4>
<p><img src="https://github.com/chou401/pic-md/raw/master/c9a549eafe1ef71c22152b41c728bb58.png" alt="img" /></p>
<h5 id="admin"><a class="header" href="#admin">admin</a></h5>
<ul>
<li>该目录下znode只有在有相关操作时才会存在，操作结束时会将其删除</li>
<li>/admin/reassign_partitions用于将一些Partition分配到不同的broker集合上。对于每个待重新分配的Partition，Kafka会在该znode上存储其所有的Replica和相应的Broker id。该znode由管理进程创建并且一旦重新分配成功它将会被自动移除。</li>
</ul>
<h5 id="broker-1"><a class="header" href="#broker-1">broker</a></h5>
<ul>
<li>即/brokers/ids/[brokerId]）存储“活着”的broker信息。</li>
<li>topic注册信息（/brokers/topics/[topic]），存储该topic的所有partition的所有replica所在的broker id，第一个replica即为preferred replica，对一个给定的partition，它在同一个broker上最多只有一个replica,因此broker id可作为replica id。</li>
</ul>
<h5 id="controller"><a class="header" href="#controller">controller</a></h5>
<ul>
<li>/controller -&gt; int (broker id of the controller)存储当前controller的信息</li>
<li>/controller_epoch -&gt; int (epoch)直接以整数形式存储controller epoch，而非像其它znode一样以JSON字符串形式存储。</li>
</ul>
<h4 id="producer发布消息"><a class="header" href="#producer发布消息">producer发布消息</a></h4>
<h5 id="写入方式"><a class="header" href="#写入方式">写入方式</a></h5>
<p>producer 采用 push 模式将消息发布到 broker，每条消息都被 append 到 patition 中，属于顺序写磁盘（顺序写磁盘效率比随机写内存要高，保障 kafka 吞吐率）。</p>
<h5 id="消息路由"><a class="header" href="#消息路由">消息路由</a></h5>
<p>producer 发送消息到 broker 时，会根据分区算法选择将其存储到哪一个 partition。其路由机制为：</p>
<ul>
<li>指定了 patition，则直接使用；</li>
<li>未指定 patition 但指定 key，通过对 key 的 value 进行hash 选出一个</li>
<li>patition 和 key 都未指定，使用轮询选出一个 patition。</li>
</ul>
<h5 id="写入流程"><a class="header" href="#写入流程">写入流程</a></h5>
<p>producer 写入消息序列图如下所示：</p>
<p><img src="https://github.com/chou401/pic-md/raw/master/3b45ec04ecea8ba94ca092b4de195fa5.png" alt="img" /></p>
<p>流程说明：</p>
<ul>
<li>producer 先从 zookeeper 的 &quot;/brokers/.../state&quot; 节点找到该 partition 的 leader。</li>
<li>producer 将消息发送给该 leader。</li>
<li>leader 将消息写入本地 log。</li>
<li>followers 从 leader pull 消息，写入本地 log 后 leader 发送 ACK。</li>
<li>leader 收到所有 ISR 中的 replica 的 ACK 后，增加 HW（high watermark，最后 commit 的 offset） 并向 producer 发送 ACK。</li>
</ul>
<h4 id="broker保存消息"><a class="header" href="#broker保存消息">broker保存消息</a></h4>
<h5 id="存储方式"><a class="header" href="#存储方式">存储方式</a></h5>
<p>物理上把 topic 分成一个或多个 patition（对应 server.properties 中的 num.partitions=3 配置），每个 patition 物理上对应一个文件夹（该文件夹存储该 patition 的所有消息和索引文件），如下：</p>
<p><img src="https://github.com/chou401/pic-md/raw/master/90540631f5560f08b643d73401e9e73e.png" alt="img" /></p>
<h5 id="存储策略"><a class="header" href="#存储策略">存储策略</a></h5>
<p>无论消息是否被消费，kafka 都会保留所有消息。有两种策略可以删除旧数据：</p>
<blockquote>
<p>基于时间：log.retention.hours=168</p>
<p>基于大小：log.retention.bytes=1073741824</p>
</blockquote>
<h4 id="topic的创建和删除"><a class="header" href="#topic的创建和删除">Topic的创建和删除</a></h4>
<h5 id="创建topic"><a class="header" href="#创建topic">创建topic</a></h5>
<p>创建 topic 的序列图如下所示：</p>
<p><img src="https://github.com/chou401/pic-md/raw/master/83e7411c3ebbb7c7c0d84a758d22e184.png" alt="img" /></p>
<p>流程说明：</p>
<ul>
<li>controller 在 ZooKeeper 的 /brokers/topics 节点上注册 watcher，当 topic 被创建，则 controller 会通过 watch 得到该 topic 的 partition/replica 分配。</li>
<li>controller从 /brokers/ids 读取当前所有可用的 broker 列表，对于 set_p 中的每一个 partition：
<ul>
<li>从分配给该 partition 的所有 replica（称为AR）中任选一个可用的 broker 作为新的 leader，并将AR设置为新的 ISR</li>
<li>将新的 leader 和 ISR 写入 /brokers/topics/[topic]/partitions/[partition]/state</li>
</ul>
</li>
<li>controller 通过 RPC 向相关的 broker 发送 LeaderAndISRRequest</li>
</ul>
<h5 id="删除topic"><a class="header" href="#删除topic">删除topic</a></h5>
<p>删除 topic 的序列图如下所示：</p>
<p><img src="https://github.com/chou401/pic-md/raw/master/e0d44eb05a13c1e59b00b7d39ecee0c8.png" alt="img" /></p>
<p>流程说明：</p>
<ul>
<li>controller 在 zooKeeper 的 /brokers/topics 节点上注册 watcher，当 topic 被删除，则 controller 会通过 watch 得到该 topic 的 partition/replica 分配。</li>
<li>若 delete.topic.enable=false，结束；否则 controller 注册在 /admin/delete_topics 上的 watch 被 fire，controller 通过回调向对应的 broker 发送 StopReplicaRequest。</li>
</ul>
<h4 id="broker-failover"><a class="header" href="#broker-failover">broker failover</a></h4>
<p>kafka broker failover 序列图如下所示：</p>
<p><img src="https://github.com/chou401/pic-md/raw/master/6725b09c54e9183071e778ba1805928b.png" alt="img" /></p>
<p>流程说明：</p>
<ul>
<li>controller 在 zookeeper 的 /brokers/ids/[brokerId] 节点注册 Watcher，当 broker 宕机时 zookeeper 会 fire watch</li>
<li>controller 从 /brokers/ids 节点读取可用broker</li>
<li>controller决定set_p，该集合包含宕机 broker 上的所有 partition</li>
<li>对 set_p 中的每一个 partition
<ul>
<li>从/brokers/topics/[topic]/partitions/[partition]/state 节点读取 ISR</li>
<li>决定新 leader</li>
<li>将新 leader、ISR、controller_epoch 和 leader_epoch 等信息写入 state 节点</li>
</ul>
</li>
<li>通过 RPC 向相关 broker 发送 leaderAndISRRequest 命令</li>
</ul>
<h4 id="controller-failover"><a class="header" href="#controller-failover">controller failover</a></h4>
<p>当 controller 宕机时会触发 controller failover。每个 broker 都会在 zookeeper 的 &quot;/controller&quot; 节点注册 watcher，当 controller 宕机时 zookeeper 中的临时节点消失，所有存活的 broker 收到 fire 的通知，每个 broker 都尝试创建新的 controller path，只有一个竞选成功并当选为 controller。</p>
<p>当新的 controller 当选时，会触发 KafkaController.onControllerFailover 方法，在该方法中完成如下操作：</p>
<ol>
<li>读取并增加 Controller Epoch。</li>
<li>在 reassignedPartitions Patch(/admin/reassign_partitions) 上注册 watcher。</li>
<li>在 preferredReplicaElection Path(/admin/preferred_replica_election) 上注册 watcher。</li>
<li>通过 partitionStateMachine 在 broker Topics Patch(/brokers/topics) 上注册 watcher。</li>
<li>若 delete.topic.enable=true（默认值是 false），则 partitionStateMachine 在 Delete Topic Patch(/admin/delete_topics) 上注册 watcher。</li>
<li>通过 replicaStateMachine在 Broker Ids Patch(/brokers/ids)上注册Watch。</li>
<li>初始化 ControllerContext 对象，设置当前所有 topic，“活”着的 broker 列表，所有 partition 的 leader 及 ISR等。</li>
<li>启动 replicaStateMachine 和 partitionStateMachine。</li>
<li>将 brokerState 状态设置为 RunningAsController。</li>
<li>将每个 partition 的 Leadership 信息发送给所有“活”着的 broker。</li>
<li>若 auto.leader.rebalance.enable=true（默认值是true），则启动 partition-rebalance 线程。 </li>
<li>若 delete.topic.enable=true 且Delete Topic Patch(/admin/delete_topics)中有值，则删除相应的Topic。</li>
</ol>
<h4 id="kafka在zookeeper中存储结构图"><a class="header" href="#kafka在zookeeper中存储结构图">Kafka在zookeeper中存储结构图</a></h4>
<p><img src="https://github.com/chou401/pic-md/raw/master/e577bb59a08c0b336dac332039d5bb6f.png" alt="img" /></p>
<h5 id="topic注册信息"><a class="header" href="#topic注册信息">topic注册信息</a></h5>
<ul>
<li>/brokers/topics/[topicName] :</li>
<li>存储某个topic的partitions所有分配信息。</li>
</ul>
<p>我们输入zkCli.sh进入zookeeper客户端。</p>
<p>使用：get /brokers/topics/topic-test，可以看到某个topic的存储信息。</p>
<h5 id="partition状态信息"><a class="header" href="#partition状态信息">partition状态信息</a></h5>
<ul>
<li>/brokers/topics/[topicName]/partitions/[0...N]  其中[0..N]表示partition索引号</li>
<li>/brokers/topics/[topicName]/partitions/[partitionId]/state</li>
</ul>
<blockquote>
<p>&quot;controller_epoch&quot;: 表示kafka集群中的中央控制器选举次数,</p>
<p>&quot;leader&quot;: 表示该partition选举leader的brokerId,</p>
<p>&quot;version&quot;: 版本编号默认为1,</p>
<p>&quot;leader_epoch&quot;: 该partition leader选举次数,</p>
<p>&quot;isr&quot;: [同步副本组brokerId列表]</p>
</blockquote>
<h5 id="broker注册信息"><a class="header" href="#broker注册信息">Broker注册信息</a></h5>
<ul>
<li>/brokers/ids/[0...N]</li>
<li>每个broker的配置文件中都需要指定一个数字类型的id(全局不可重复),此节点为临时znode(EPHEMERAL)</li>
</ul>
<blockquote>
<p>&quot;jmx_port&quot;: jmx端口号,</p>
<p>&quot;timestamp&quot;: kafka broker初始启动时的时间戳,</p>
<p>&quot;host&quot;: 主机名或ip地址,</p>
<p>&quot;version&quot;: 版本编号默认为1,</p>
<p>&quot;port&quot;: kafka broker的服务端端口号,由server.properties中参数port确定</p>
</blockquote>
<h5 id="controller-epoch"><a class="header" href="#controller-epoch">Controller epoch</a></h5>
<ul>
<li>/controller_epoch --&gt; int (epoch)</li>
<li>此值为一个数字,kafka集群中第一个broker第一次启动时为1，以后只要集群中center controller中央控制器所在broker变更或挂掉，就会重新选举新的center controller，每次center controller变更controller_epoch值就会 + 1;</li>
</ul>
<h5 id="controller注册信息"><a class="header" href="#controller注册信息">Controller注册信息</a></h5>
<ul>
<li>/controller -&gt; int (broker id of the controller)  存储center controller中央控制器所在kafka broker的信息</li>
</ul>
<blockquote>
<p>&quot;version&quot;: 版本编号默认为1,
&quot;brokerid&quot;: kafka集群中broker唯一编号,
&quot;timestamp&quot;: kafka broker中央控制器变更时的时间戳</p>
</blockquote>
<h3 id="rocketmq"><a class="header" href="#rocketmq">RocketMQ</a></h3>
<p>RocketMQ 是阿里巴巴在 2012 年开源的消息队列产品，用<strong>纯 Java 语言</strong>实现，在设计时参考了 Kafka，并做出了自己的一些改进，后来捐赠给 Apache 软件基金会，2017 正式毕业，成为 Apache 的顶级项目。RocketMQ 在阿里内部被广泛应用在订单，交易，充值，流计算，消息推送，日志流式处理，Binglog 分发等场景。经历过多次双十一考验，它的性能、稳定性和可靠性都是值得信赖的。</p>
<p>RocketMQ 有着不错的性能，稳定性和可靠性，具备一个现代的消息队列应该有的几乎全部功能和特性，并且它还在持续的成长中。</p>
<p>RocketMQ 有非常活跃的中文社区，大多数问题可以找到中文的答案。RocketMQ 使用 Java 语言开发，源代码相对比较容易读懂，容易对 RocketMQ 进行扩展或者二次开发。</p>
<p>RocketMQ 对在线业务的响应时延做了很多的优化，大多数情况下可以做到毫秒级的响应，如果你的应用场景很在意响应时延，那应该选择使用 RocketMQ。</p>
<p>RocketMQ 的性能比 RabbitMQ 要高一个数量级，每秒钟大概能处理几十万条消息。</p>
<p>RocketMQ 的劣势是与周边生态系统的集成和兼容程度不够。</p>
<h4 id="基础概念"><a class="header" href="#基础概念">基础概念</a></h4>
<ul>
<li><strong>Producer</strong>： 消息生产者，负责产生消息，一般由业务系统负责产生消息。</li>
<li><strong>Producer Group</strong>：消息生产者组，简单来说就是多个发送同一类消息的生产者称之为一个生产者。</li>
<li><strong>Consumer</strong>：消息消费者，负责消费消息，一般是后台系统负责异步消费。</li>
<li><strong>Consumer Group</strong>：消费者组，和生产者类似，消费同一类消息的多个 Consumer 实例组成一个消费者组。</li>
<li><strong>Topic</strong>：主题，用于将消息按主题做划分，Producer将消息发往指定的Topic，Consumer订阅该Topic就可以收到这条消息。</li>
<li><strong>Message</strong>：消息，每个message必须指定一个topic，Message 还有一个可选的 Tag 设置，以便消费端可以基于 Tag 进行过滤消息。</li>
<li><strong>Tag</strong>：标签，子主题（二级分类）对topic的进一步细化,用于区分同一个主题下的不同业务的消息。</li>
<li><strong>Broker</strong>：Broker是RocketMQ的核心模块，负责接收并存储消息，同时提供Push/Pull接口来将消息发送给Consumer。Broker同时提供消息查询的功能，可以通过MessageID和MessageKey来查询消息。Borker会将自己的Topic配置信息实时同步到NameServer。</li>
<li><strong>Queue</strong>：Topic和Queue是1对多的关系，一个Topic下可以包含多个Queue，主要用于负载均衡，Queue数量设置建议不要比消费者数少。发送消息时，用户只指定Topic，Producer会根据Topic的路由信息选择具体发到哪个Queue上。Consumer订阅消息时，会根据负载均衡策略决定订阅哪些Queue的消息。</li>
<li><strong>Offset</strong>：RocketMQ在存储消息时会为每个Topic下的每个Queue生成一个消息的索引文件，每个Queue都对应一个Offset记录当前Queue中消息条数。</li>
<li><strong>NameServer</strong>：NameServer可以看作是RocketMQ的注册中心，它管理两部分数据：集群的Topic-Queue的路由配置；Broker的实时配置信息。其它模块通过Nameserv提供的接口获取最新的Topic配置和路由信息；各 NameServer 之间不会互相通信， 各 NameServer 都有完整的路由信息，即无状态。
<ul>
<li><strong>Producer/Consumer</strong> ：通过查询接口获取Topic对应的Broker的地址信息和Topic-Queue的路由配置</li>
<li><strong>Broker</strong> ： 注册配置信息到NameServer， 实时更新Topic信息到NameServer</li>
</ul>
</li>
</ul>
<h4 id="rocketmq-消费模式"><a class="header" href="#rocketmq-消费模式">RocketMQ 消费模式</a></h4>
<h5 id="广播模式"><a class="header" href="#广播模式">广播模式</a></h5>
<p>一条消息被多个Consumer消费，即使这些Consumer属于同一个Consumer Group，消息也会被Consumer Group中的每一个Consumer都消费一次。</p>
<pre><code class="language-java">// 设置广播模式
consumer.setMessageModel(MessageModel.BROADCASTING);
</code></pre>
<h5 id="集群模式"><a class="header" href="#集群模式">集群模式</a></h5>
<p>一个Consumer Group中的所有Consumer平均分摊消费消息(组内负载均衡)。</p>
<pre><code class="language-java">// 设置集群模式 也就是负载均衡模式
consumer.setMessageModel(MessageModel.CLUSTERING);
</code></pre>
<h4 id="基础架构"><a class="header" href="#基础架构">基础架构</a></h4>
<p>RocketMq 使用轻量级的NameServer服务进行服务的协调和治理工作，NameServer多节点部署时相互独立互不干扰。每一个rocketMq服务节点（broker节点）启动时都会遍历配置的NameServer列表并建立长链接，broker节点每30秒向NameServer发送一次心跳信息、NameServer每10秒会检查一次连接的broker是否存活。消费者和生产者会随机选择一个NameServer建立长连接，通过定期轮训更新的方式获取最新的服务信息。架构简图如下：</p>
<p><img src="https://img-blog.csdnimg.cn/b6c77636a91a422893e3be52a1cdb111.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA572X5b-X5a6P,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="img" /></p>
<ol>
<li><strong>NameServer</strong>：启动，监听端口，等待producer，consumer，broker连接上来。</li>
<li><strong>Broker</strong>：启动，与nameserver保持长链接，定期向nameserver发送心跳信息，包含broker的ip，端口，当前broker上topic的信息。</li>
<li><strong>producer</strong>：启动，随机选择一个NameServer建立长连接，拿到broker的信息，然后就可以给broker发送消息了。</li>
<li><strong>consumer</strong>：启动，随机选择一个NameServer建立长连接，拿到broker的信息，然后就可以建立通道，消费消息。</li>
</ol>
<h5 id="broker-的存储结构"><a class="header" href="#broker-的存储结构">Broker 的存储结构</a></h5>
<p>RocketMQ 存储用的是<strong>本地文件存储系统</strong>，将所有topic的消息全部写入同一个文件中（commit log），这样保证了IO写入的绝对顺序性，最大限度利用IO系统顺序读写带来的优势提升写入速度。</p>
<p>由于消息混合存储在一起，需要将每个消费者组消费topic最后的<strong>偏移量</strong>记录下来。这个文件就是consumer queue（索引文件）。所以消息在写入commit log 文件的同时还需将偏移量信息写入consumer queue文件。在索引文件中会记录消息的物理位置、偏移量offse，消息size等，消费者消费时根据上述信息就可以从commit log文件中快速找到消息信息。</p>
<p>Broker 存储结构如下：</p>
<p><img src="https://img-blog.csdnimg.cn/4d4f6c0165fc40e1866af2f46d112a74.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA572X5b-X5a6P,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="img" /></p>
<h5 id="存储文件简介"><a class="header" href="#存储文件简介">存储文件简介</a></h5>
<ul>
<li><strong>Commit log</strong>：消息存储文件，RocketMQ会对commit log文件进行分割（默认大小1GB），新文件以消息最后一条消息的偏移量命名。（比如 00000000000000000000 代表了第一个文件，第二个文件名就是 00000000001073741824，表明起始偏移量为 1073741824）。</li>
<li><strong>Consumer queue</strong>：消息消费队列（也是个文件），可以根据消费者数量设置多个，一个Topic 下的某个 Queue，每个文件约 5.72M，由 30w 条数据组成；ConsumeQueue 存储的条目是固定大小，只会存储 8 字节的 commitlog 物理偏移量，4 字节的消息长度和 8 字节 Tag 的哈希值，固定 20 字节；消费者是先从 ConsumeQueue 来得到消息真实的物理地址，然后再去 CommitLog 获取消息。</li>
<li><strong>IndexFile</strong>：索引文件，是额外提供查找消息的手段，通过 Key 或者时间区间来查询对应的消息。</li>
</ul>
<p><strong>整个流程简介</strong></p>
<p>Producer 使用轮询的方式分别向每个 Queue 中发送消息。</p>
<p>Consumer 启动的时候会在 Topic，Consumer group 维度发生负载均衡，为每个客户端分配需要处理的 Queue。负载均衡过程中每个客户端都获取到全部的的 ConsumerID 和所有 Queue 并进行排序，每个客户端使用相同负责均衡算法，例如平均分配的算法，这样每个客户端都会计算出自己需要消费那些 Queue，每当 Consumer 增加或减少就会触发负载均衡，所以我们可以通过 RocketMQ 负载均衡机制实现动态扩容，提升客户端收发消息能力。客户端负责均衡为客户端分配好 Queue 后，客户端会不断向 Broker 拉取消息，在客户端进行消费。</p>
<p><strong>可以一直增加客户端的数量提升消费能力吗</strong>？</p>
<p>当然不可以，因为 Queue 数量有限，客户端数量一旦达到 Queue 数量，再扩容新节点无法提升消费能力，因为会有节点分配不到 Queue 而无法消费。</p>
<h5 id="consumer-端的负载均衡机制"><a class="header" href="#consumer-端的负载均衡机制">Consumer 端的负载均衡机制</a></h5>
<p>topic 在创建之处可以设置 comsumer queue数量。而 comsumer 在启动时会和comsumer queue绑定，这个绑定策略是咋样的？</p>
<p><img src="https://img-blog.csdnimg.cn/0466d1dbc23440d4bffb60adb710bad1.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA572X5b-X5a6P,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="img" /></p>
<ul>
<li><strong>默认策略</strong>：
<ul>
<li>queue 个数大于 Consumer个数， 那么 Consumer 会平均分配 queue，不够平均，会根据clientId排序来拿取余数</li>
<li>queue个数小于Consumer个数，那么会有Consumer闲置，就是浪费掉了，其余Consumer平均分配到queue</li>
</ul>
</li>
<li><strong>一致性hash算法</strong></li>
<li><strong>就近元则，离的近的消费</strong></li>
<li><strong>每个消费者依次消费一个queue，环状</strong></li>
<li><strong>自定义方式</strong></li>
</ul>
<p><strong>天然弊端</strong>：</p>
<p>RocketMQ 采用一个 consumer 绑定一个或者多个 Queue 模式，假如某个消费者服务器挂了，则会造成部分Queue消息堆积。</p>
<h5 id="消息刷盘机制"><a class="header" href="#消息刷盘机制">消息刷盘机制</a></h5>
<ul>
<li><strong>同步刷盘</strong>：当消息持久化完成后，Broker才会返回给Producer一个ACK响应，可以保证消息的可靠性，但是性能较低。</li>
<li><strong>异步刷盘</strong>：只要消息写入PageCache即可将成功的ACK返回给Producer端。消息刷盘采用后台异步线程提交的方式进行，降低了读写延迟，提高了RocketMQ的性能和吞吐量。</li>
</ul>
<h5 id="mmap--pagecache"><a class="header" href="#mmap--pagecache">Mmap + pageCache</a></h5>
<p>RocketMQ 底层对 commitLog、consumeQueue 之类的磁盘文件的读写操作都采用了 mmap 技术。</p>
<p><strong>传统 IO</strong></p>
<p>传统 I/O 的工作方式是，数据读取和写入是从用户空间到内核空间来回复制，而内核空间的数据是通过操作系统层面的 I/O 接口从磁盘读取或写入。</p>
<p>传统IO<strong>发生了 4 次用户态与内核态的上下文切换</strong>，因为发生了两次系统调用，一次是 <code>read()</code> ，一次是 <code>write()</code>，每次系统调用都得先从用户态切换到内核态，等内核完成任务后，再从内核态切换回用户态。</p>
<p>其次，还<strong>发生了 4 次数据拷贝</strong>，其中两次是 DMA 的拷贝，另外两次则是通过 CPU 拷贝的。</p>
<p><strong>传统IO，write() 过程是怎样？</strong></p>
<p>wirte() 写请求 和 read()，需要先写入用户缓存区，然后通过系统调用，CPU 拷贝数据从用户缓存区到内核缓存区，再从内核缓存区拷贝到磁盘文件！</p>
<ul>
<li>第一次拷贝，把磁盘上的数据拷贝到操作系统内核的缓冲区里，这个拷贝的过程是通过 DMA 搬运的。</li>
<li>第二次拷贝，把内核缓冲区的数据拷贝到用户的缓冲区里，于是我们应用程序就可以使用这部分数据了，这个拷贝到过程是由 CPU 完成的（用户态不能直接操作内核态缓存区，所以需要拷贝到用户态才能使用）。</li>
<li>第三次拷贝，把刚才拷贝到用户的缓冲区里的数据，再拷贝到内核的 socket 的缓冲区里，这个过程依然还是由 CPU 搬运的。</li>
<li>第四次拷贝，把内核的 socket 缓冲区里的数据，拷贝到网卡的缓冲区里，这个过程又是由 DMA 搬运的。</li>
</ul>
<p>我们回过头看这个文件传输的过程，我们只是搬运一份数据，结果却搬运了 4 次，过多的数据拷贝无疑会消耗 CPU 资源，大大降低了系统性能。</p>
<p>这种简单又传统的文件传输方式，存在冗余的上文切换和数据拷贝，在高并发系统里是非常糟糕的，多了很多不必要的开销，会严重影响系统性能。</p>
<p>所以，要想提高文件传输的性能，就需要<strong>减少「用户态与内核态的上下文切换」和「内存拷贝」的次数</strong>。</p>
<p><strong>如何优化文件传输的性能？</strong>
先来看看，如何减少「用户态与内核态的上下文切换」的次数呢？</p>
<p>读取磁盘数据的时候，之所以要发生上下文切换，这是因为用户空间没有权限操作磁盘或网卡，内核的权限最高，这些操作设备的过程都需要交由操作系统内核来完成，所以一般要通过内核去完成某些任务的时候，就需要使用操作系统提供的系统调用函数。</p>
<p>而一次系统调用必然会发生 2 次上下文切换：首先从用户态切换到内核态，当内核执行完任务后，再切换回用户态交由进程代码执行。</p>
<p>所以，要想减少上下文切换到次数，就要减少系统调用的次数。</p>
<p><strong>再来看看，如何减少「数据拷贝」的次数？</strong></p>
<p>在前面我们知道了，传统的文件传输方式会历经 4 次数据拷贝，而且这里面，「从内核的读缓冲区拷贝到用户的缓冲区里，再从用户的缓冲区里拷贝到 socket 的缓冲区里」，这个过程是没有必要的。</p>
<p>因为文件传输的应用场景中，在用户空间我们并不会对数据「再加工」，所以数据实际上可以不用搬运到用户空间，因此<strong>用户的缓冲区是没有必要存在的</strong>。</p>
<p><strong>Mmap（内存映射）</strong></p>
<p><code>read()</code> 系统调用的过程中会把内核缓冲区的数据拷贝到用户的缓冲区里，于是为了减少这一步开销，我们可以用 <code>mmap()</code> 替换 <code>read()</code> 系统调用函数。</p>
<p><code>mmap()</code> 系统调用函数会把文件磁盘地址「<strong>映射</strong>」到内核缓存区（page cache），而内核缓存区会 「<strong>映射</strong>」到用户空间（虚拟地址）。这样，操作系统内核与用户空间就不需要再进行任何的数据拷贝。</p>
<blockquote>
<p>注意，这里用户空间（虚拟地址）不是直接映射到文件磁盘地址，而是文件对应的 page cache，用户虚拟地址一般是和用户内存地址「映射」的，如果使用内存映射技术，则用户虚拟地址可以和内核内存地址「映射」。
根据维基百科给出的定义：在大多数操作系统中，映射的内存区域实际上是内核的page cache，这意味着不需要在用户空间创建副本。多个进程之间也可以通过同时映射 page cache，来进行进程通信）</p>
</blockquote>
<p><strong>mmap() 函数简介</strong></p>
<pre><code class="language-java">void * mmap(void *start, size_t length, int prot , int flags, int fd, off_t offset)
</code></pre>
<ul>
<li><strong>start</strong>：要映射到的内存区域的起始地址，通常都是用NULL（NULL即为0）。NULL表示由内核来指定该内存地址</li>
<li><strong>offset</strong>：以文件开始处的偏移量, 必须是分页大小的整数倍, 通常为0, 表示从文件头开始映射</li>
<li><strong>length</strong>：将文件的多大长度映射到内存（每次创建新 commitlog 会默认指定长度 1GB）</li>
<li><strong>prot</strong>： 映射区的保护方式（PROT_EXEC: 映射区可被执行、PROT_READ: 映射区可被读取、PROT_WRITE: 映射区可被写入、PROT_NONE: 映射区不能存取）</li>
<li><strong>flags</strong>： 映射区的特性</li>
<li><strong>fd</strong>：文件描述符（由open函数返回）</li>
</ul>
<p>从磁盘拷贝到内核空间的页缓存 (page cache)，然后将用户空间的虚拟地址映射到内核的page cache，这样不需要再将页面从内核空间拷贝到用户空间了。</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/6e9223b86e2fad24b14e5a31df1879e0.png" alt="img" /></p>
<p>简述上述过程</p>
<ol>
<li>应用进程调用了 mmap() 后，DMA 会把磁盘的数据拷贝到内核的缓冲区里。接着，应用进程跟操作系统内核「共享」这个缓冲区；</li>
<li>应用进程再调用 write()，操作系统直接将内核缓冲区的数据拷贝到 socket 缓冲区中，这一切都发生在内核态，由 CPU 来搬运数据；</li>
<li>应用进程再调用 write()，操作系统直接将内核缓冲区的数据拷贝到 socket 缓冲区中，这一切都发生在内核态，由 CPU 来搬运数据；</li>
<li>最后，把内核的 socket 缓冲区里的数据，拷贝到网卡的缓冲区里，这个过程是由 DMA 搬运的。</li>
</ol>
<p><strong>使用 mmap() 写数据到磁盘文件会怎样？</strong></p>
<p>mmap() 将用户虚拟地址映射内核缓存区（内存物理地址）后，写数据直接将数据写入内核缓存区，只需要经过一次CPU拷贝，将数据从内核缓存区拷贝到磁盘文件；比传统 IO 的 write() 操作少了一次数据拷贝的过程！</p>
<p>但这还不是最理想的零拷贝，因为仍然需要通过 CPU 把内核缓冲区的数据拷贝到 socket 缓冲区里，而且仍然需要 4 次上下文切换，因为系统调用还是 2 次。</p>
<p><strong>pageCache</strong></p>
<p>在传统IO过程中，其中第一步都是先需要先把磁盘文件数据拷贝「内核缓冲区」里，这个「内核缓冲区」实际上是<strong>磁盘高速缓存（PageCache）</strong>。</p>
<p><strong>预映射机制 + 文件预热机制</strong></p>
<p>Broker针对上述的磁盘文件高性能读写机制做的一些优化：</p>
<ul>
<li>
<p>内存预映射机制：Broker 会针对磁盘上的各种 CommitLog、ConsumeQueue 文件预先分配好MappedFile，也就是提前对一些可能接下来要读写的磁盘文件，提前使用 MappedByteBuffer 执行 mmap() 函数完成内存映射，这样后续读写文件的时候，就可以直接执行了（减少一次 CPU 拷贝）。</p>
</li>
<li>
<p>文件预热：在提前对一些文件完成内存映射之后，因为内存映射不会直接将数据从磁盘加载到内存里来，那么后续在读，取尤其是 CommitLog、ConsumeQueue 文件时候，其实有可能会频繁的从磁盘里加载数据到内存中去。所以，在执行完 mmap() 函数之后，还会进行 madvise() 系统调用，就是提前尽可能将磁盘文件加载到内存里去。(读磁盘 -&gt; 读内存)。</p>
</li>
</ul>
<h5 id="topic-分片"><a class="header" href="#topic-分片">Topic 分片</a></h5>
<p>为了突破单个机器容量上限和单个机器读写性能，RocketMQ 支持 topic 数据分片。</p>
<p>架构图如下：</p>
<p><img src="https://img-blog.csdnimg.cn/6dda18d3001c4db5b2fc0f84f7a8ba88.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA572X5b-X5a6P,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="img" /></p>
<h5 id="查缺补漏"><a class="header" href="#查缺补漏">查缺补漏</a></h5>
<p><strong>消息的全局顺序和局部顺序</strong></p>
<ul>
<li><strong>全局顺序</strong>：一个 Topic 一个队列，Producer 和 Consuemr 的并发都为一。</li>
<li><strong>局部顺序</strong>：某个队列消息是顺序的。</li>
</ul>
<p><strong>零拷贝（Zero-copy）</strong></p>
<p>sendfile：</p>
<p>在 Linux 内核版本 2.1 中，提供了一个专门发送文件的系统调用函数 <code>sendfile()</code>，函数形式如下：</p>
<pre><code class="language-cpp">#include &lt;sys/socket.h&gt;
ssize_t sendfile(int out_fd, int in_fd, off_t *offset, size_t count);
</code></pre>
<p>它的前两个参数分别是目的端和源端的文件描述符，后面两个参数是源端的偏移量和复制数据的长度，返回值是实际复制数据的长度。</p>
<p>首先，它可以替代前面的 read() 和 write() 这两个系统调用，这样就可以减少一次系统调用，也就减少了 2 次上下文切换的开销。</p>
<p>其次，该系统调用，可以直接把内核缓冲区里的数据拷贝到 socket 缓冲区里，不再拷贝到用户态，这样就只有 2 次上下文切换，和 3 次数据拷贝。如下图：</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/87c6530cba656a8139b6def9b0db570b.png" alt="img" /></p>
<p>但是这还不是真正的零拷贝技术，如果网卡支持 SG-DMA（The Scatter-Gather Direct Memory Access）技术（和普通的 DMA 有所不同），我们可以进一步减少通过 CPU 把内核缓冲区里的数据拷贝到 socket 缓冲区的过程。</p>
<p>你可以在你的 Linux 系统通过下面这个命令，查看网卡是否支持 scatter-gather 特性：</p>
<pre><code class="language-cobol">$ ethtool -k eth0 | grep scatter-gather
scatter-gather: on
</code></pre>
<p>于是，从 Linux 内核 2.4 版本开始起，对于支持网卡支持 SG-DMA 技术的情况下， sendfile() 系统调用的过程发生了点变化，具体过程如下：</p>
<ol>
<li>第一步，通过 DMA 将磁盘上的数据拷贝到内核缓冲区里；</li>
<li>第二步，缓冲区描述符和数据长度传到 socket 缓冲区，这样网卡的 SG-DMA 控制器就可以直接将内核缓存中的数据拷贝到网卡的缓冲区里，此过程不需要将数据从操作系统内核缓冲区拷贝到 socket 缓冲区中，这样就减少了一次数据拷贝；</li>
</ol>
<p>所以，这个过程之中，只进行了 2 次数据拷贝，如下图：</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/971767ef19a202042cdefcd3be6b4fa7.png" alt="img" /></p>
<p>这就是所谓的<strong>零拷贝（Zero-copy）技术，因为我们没有在内存层面去拷贝数据，也就是说全程没有通过 CPU 来搬运数据，所有的数据都是通过 DMA 来进行传输的</strong>。</p>
<p>零拷贝技术的文件传输方式相比传统文件传输的方式，减少了 2 次上下文切换和数据拷贝次数，<strong>只需要 2 次上下文切换和数据拷贝次数，就可以完成文件的传输，而且 2 次的数据拷贝过程，都不需要通过 CPU，2 次都是由 DMA 来搬运</strong>。</p>
<p>所以，总体来看，<strong>零拷贝技术可以把文件传输的性能提高至少一倍以上</strong>。</p>
<p><strong>使用零拷贝技术的项目</strong></p>
<p>事实上，Kafka 这个开源项目，就利用了「零拷贝」技术，从而大幅提升了 I/O 的吞吐率，这也是 Kafka 在处理海量数据为什么这么快的原因之一。</p>
<p>如果你追溯 Kafka 文件传输的代码，你会发现，最终它调用了 Java NIO 库里的 <code>transferTo</code>方法：</p>
<pre><code class="language-java">@Overridepublic 
long transferFrom(FileChannel fileChannel, long position, long count) throws IOException { 
    return fileChannel.transferTo(position, count, socketChannel);
}
</code></pre>
<p>如果 Linux 系统支持 <code>sendfile()</code> 系统调用，那么 <code>transferTo()</code> 实际上最后就会使用到 <code>sendfile()</code> 系统调用函数。</p>
<p>另外，Nginx 也支持零拷贝技术，一般默认是开启零拷贝技术，这样有利于提高文件传输的效率，是否开启零拷贝技术的配置如下：</p>
<pre><code class="language-cobol">http {
...
    sendfile on
...
}
</code></pre>
<p>sendfile 配置的具体意思: </p>
<ul>
<li>设置为 on 表示，使用零拷贝技术来传输文件：sendfile ，这样只需要 2 次上下文切换，和 2 次数据拷贝。</li>
<li>设置为 off 表示，使用传统的文件传输技术：read + write，这时就需要 4 次上下文切换，和 4 次数据拷贝。</li>
</ul>
<p>当然，要使用 sendfile，Linux 内核版本必须要 2.1 以上的版本。</p>
<p><strong>PageCache 有什么作用？</strong></p>
<p>回顾前面说道文件传输过程，其中第一步都是先需要先把磁盘文件数据拷贝「内核缓冲区」里，这个「内核缓冲区」实际上是磁盘高速缓存（PageCache）。</p>
<p>由于零拷贝使用了 PageCache 技术，可以使得零拷贝进一步提升了性能，我们接下来看看 PageCache 是如何做到这一点的。</p>
<p>读写磁盘相比读写内存的速度慢太多了，所以我们应该想办法把「读写磁盘」替换成「读写内存」。于是，我们会通过 DMA 把磁盘里的数据搬运到内存里，这样就可以用读内存替换读磁盘。</p>
<p>但是，内存空间远比磁盘要小，内存注定只能拷贝磁盘里的一小部分数据。</p>
<p>那问题来了，选择哪些磁盘数据拷贝到内存呢？</p>
<p>我们都知道程序运行的时候，具有「局部性」，所以通常，刚被访问的数据在短时间内再次被访问的概率很高，于是我们可以用 PageCache 来缓存最近被访问的数据，当空间不足时淘汰最久未被访问的缓存。</p>
<p>所以，读磁盘数据的时候，优先在 PageCache 找，如果数据存在则可以直接返回；如果没有，则从磁盘中读取，然后缓存 PageCache 中。</p>
<p>还有一点，读取磁盘数据的时候，需要找到数据所在的位置，但是对于机械磁盘来说，就是通过磁头旋转到数据所在的扇区，再开始「顺序」读取数据，但是旋转磁头这个物理动作是非常耗时的，为了降低它的影响，PageCache 使用了「预读功能」。</p>
<p>比如，假设 read 方法每次只会读 32 KB 的字节，虽然 read 刚开始只会读 0 ～ 32 KB 的字节，但内核会把其后面的 32～64 KB 也读取到 PageCache，这样后面读取 32～64 KB 的成本就很低，如果在 32～64 KB 淘汰出 PageCache 前，进程读取到它了，收益就非常大。</p>
<p>所以，PageCache 的优点主要是两个：</p>
<ul>
<li>缓存最近被访问的数据；</li>
<li>预读功能；</li>
</ul>
<p>这两个做法，将大大提高读写磁盘的性能。</p>
<p>但是，在传输大文件（GB 级别的文件）的时候，PageCache 会不起作用，那就白白浪费多做的一次数据拷贝，造成性能的降低，即使使用了 PageCache 的零拷贝也会损失性能</p>
<p>这是因为如果你有很多 GB 级别文件需要传输，每当用户访问这些大文件的时候，内核就会把它们载入 PageCache 中，于是 PageCache 空间很快被这些大文件占满。</p>
<p>另外，由于文件太大，可能某些部分的文件数据被再次访问的概率比较低，这样就会带来 2 个问题：</p>
<ul>
<li>PageCache 由于长时间被大文件占据，其他「热点」的小文件可能就无法充分使用到 PageCache，于是这样磁盘读写的性能就会下降了；</li>
<li>PageCache 中的大文件数据，由于没有享受到缓存带来的好处，但却耗费 DMA 多拷贝到 PageCache 一次；</li>
</ul>
<p>所以，针对大文件的传输，不应该使用 PageCache，也就是说不应该使用零拷贝技术，因为可能由于 PageCache 被大文件占据，而导致「热点」小文件无法利用到 PageCache，这样在高并发的环境下，会带来严重的性能问题。</p>
<p><strong>大文件传输用什么方式实现？</strong></p>
<p>那针对大文件的传输，我们应该使用什么方式呢？</p>
<p>我们先来看看最初的例子，当调用 read 方法读取文件时，进程实际上会阻塞在 read 方法调用，因为要等待磁盘数据的返回，如下图：</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/de0ebc5fe89fb2999683504f3cca815b.png" alt="img" /></p>
<p>具体过程：</p>
<ul>
<li>当调用 read 方法时，会阻塞着，此时内核会向磁盘发起 I/O 请求，磁盘收到请求后，便会寻址，当磁盘数据准备好后，就会向内核发起 I/O 中断，告知内核磁盘数据已经准备好；</li>
<li>内核收到 I/O 中断后，就将数据从磁盘控制器缓冲区拷贝到 PageCache 里；</li>
<li>最后，内核再把 PageCache 中的数据拷贝到用户缓冲区，于是 read 调用就正常返回了。</li>
</ul>
<p>对于阻塞的问题，可以用异步 I/O 来解决，它工作方式如下图：</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/138296dc824bf3e5ab8576bdfb0be80b.png" alt="img" /></p>
<p>它把读操作分为两部分：</p>
<ul>
<li>前半部分，内核向磁盘发起读请求，但是可以<strong>不等待数据就位就可以返回</strong>，于是进程此时可以处理其他任务；</li>
<li>后半部分，当内核将磁盘中的数据拷贝到进程缓冲区后，进程将接收到内核的<strong>通知</strong>，再去处理数据；</li>
</ul>
<p>而且，我们可以发现，异步 I/O 并没有涉及到 PageCache，所以使用异步 I/O 就意味着要绕开 PageCache。</p>
<p>绕开 PageCache 的 I/O 叫直接 I/O，使用 PageCache 的 I/O 则叫缓存 I/O。通常，对于磁盘，异步 I/O 只支持直接 I/O。</p>
<p>前面也提到，大文件的传输不应该使用 PageCache，因为可能由于 PageCache 被大文件占据，而导致「热点」小文件无法利用到 PageCache。</p>
<p>于是，在高并发的场景下，针对大文件的传输的方式，应该使用「异步 I/O + 直接 I/O」来替代零拷贝技术。</p>
<p>直接 I/O 应用场景常见的两种：</p>
<ul>
<li>应用程序已经实现了磁盘数据的缓存，那么可以不需要 PageCache 再次缓存，减少额外的性能损耗。在 MySQL 数据库中，可以通过参数设置开启直接 I/O，默认是不开启；</li>
<li>传输大文件的时候，由于大文件难以命中 PageCache 缓存，而且会占满 PageCache 导致「热点」文件无法充分利用缓存，从而增大了性能开销，因此，这时应该使用直接 I/O。</li>
</ul>
<p>另外，由于直接 I/O 绕过了 PageCache，就无法享受内核的这两点的优化：</p>
<ul>
<li>内核的 I/O 调度算法会缓存尽可能多的 I/O 请求在 PageCache 中，最后「<strong>合并</strong>」成一个更大的 I/O 请求再发给磁盘，这样做是为了减少磁盘的寻址操作；</li>
<li>内核也会「<strong>预读</strong>」后续的 I/O 请求放在 PageCache 中，一样是为了减少对磁盘的操作；</li>
</ul>
<p>于是，传输大文件的时候，使用「异步 I/O + 直接 I/O」了，就可以无阻塞地读取文件了。</p>
<p>所以，传输文件的时候，我们要根据文件的大小来使用不同的方式：</p>
<ul>
<li>传输大文件的时候，使用「异步 I/O + 直接 I/O」；</li>
<li>传输小文件的时候，则使用「零拷贝技术」；</li>
</ul>
<p>在 nginx 中，我们可以用如下配置，来根据文件的大小来使用不同的方式：</p>
<pre><code class="language-cobol">location /video/ { 
    sendfile on; 
    aio on; 
    directio 1024m; 
}
</code></pre>
<p>当文件大小大于 <code>directio</code> 值后，使用「异步 I/O + 直接 I/O」，否则使用「零拷贝技术」。</p>
<h5 id="总结-1"><a class="header" href="#总结-1">总结</a></h5>
<p>早期 I/O 操作，内存与磁盘的数据传输的工作都是由 CPU 完成的，而此时 CPU 不能执行其他任务，会特别浪费 CPU 资源。</p>
<p>于是，为了解决这一问题，DMA 技术就出现了，每个 I/O 设备都有自己的 DMA 控制器，通过这个 DMA 控制器，CPU 只需要告诉 DMA 控制器，我们要传输什么数据，从哪里来，到哪里去，就可以放心离开了。后续的实际数据传输工作，都会由 DMA 控制器来完成，CPU 不需要参与数据传输的工作。</p>
<p>传统 IO 的工作方式，从硬盘读取数据，然后再通过网卡向外发送，我们需要进行 4 上下文切换，和 4 次数据拷贝，其中 2 次数据拷贝发生在内存里的缓冲区和对应的硬件设备之间，这个是由 DMA 完成，另外 2 次则发生在内核态和用户态之间，这个数据搬移工作是由 CPU 完成的。</p>
<p>为了提高文件传输的性能，于是就出现了零拷贝技术，它通过一次系统调用（sendfile 方法）合并了磁盘读取与网络发送两个操作，降低了上下文切换次数。另外，拷贝数据都是发生在内核中的，天然就降低了数据拷贝的次数。</p>
<p>Kafka 和 Nginx 都有实现零拷贝技术，这将大大提高文件传输的性能。</p>
<p>零拷贝技术是基于 PageCache 的，PageCache 会缓存最近访问的数据，提升了访问缓存数据的性能，同时，为了解决机械硬盘寻址慢的问题，它还协助 I/O 调度算法实现了 IO 合并与预读，这也是顺序读比随机读性能好的原因。这些优势，进一步提升了零拷贝的性能。</p>
<p>需要注意的是，零拷贝技术是不允许进程对文件内容作进一步的加工的，比如压缩数据再发送。</p>
<p>另外，当传输大文件时，不能使用零拷贝，因为可能由于 PageCache 被大文件占据，而导致「热点」小文件无法利用到 PageCache，并且大文件的缓存命中率不高，这时就需要使用「异步 IO + 直接 IO 」的方式。</p>
<p>在 Nginx 里，可以通过配置，设定一个文件大小阈值，针对大文件使用异步 IO 和直接 IO，而对小文件使用零拷贝。</p>
<p><strong>Kafka为什么那么快？</strong></p>
<ul>
<li>顺序读写+mmap，使用linux内核提供的mmap api，mmap将磁盘文件（设备内存）映射到内存，支持读和写，对内存的操作就会反映在磁盘文件上，但这不是实时写入磁盘的，操作系统会在程序主动调用flush的时候才真正的把数据写到硬盘（kafka也提供了一个参数——producer.type来控制是不是主动flush，如果kafaka写入到mmap之后立即flush然后返回producer叫同步，写入mmap之后立即返回producer叫异步）。</li>
<li>零拷贝，使用linux内核提供的sendfile api，sendfile是将读到内核空间的数据，直接转到socket buffer，进行网络发送。 </li>
</ul>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cDovL2ltZy5ibG9nLmNzZG4ubmV0LzIwMTYwMTE0MTk1MDMzNTA5?x-oss-process=image/format,png" alt="img" /></p>
<p><strong>什么事mmap？</strong></p>
<p>mmap是操作这些设备的一种方法，所谓操作设备，比如IO端口（点亮一个LED）、LCD控制器、磁盘控制器，实际上就是往设备的物理地址读写数据。</p>
<p>但是，由于应用程序不能直接操作设备硬件地址，所以操作系统提供了这样的一种机制——内存映射，把设备地址映射到进程虚拟地址，mmap就是实现内存映射的接口。</p>
<p>mmap的好处是，mmap把设备内存映射到虚拟内存，则用户操作虚拟内存相当于直接操作设备了，省去了用户空间到内核空间的复制过程，相对IO操作来说，增加了数据的吞吐量。</p>
<p><strong>什么是内存映射？</strong></p>
<p>既然mmap是实现内存映射的接口，那么内存映射是什么呢？看下图：</p>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cDovL2ltZy5ibG9nLmNzZG4ubmV0LzIwMTYwMTE0MjAwMTMxODE1?x-oss-process=image/format,png" alt="img" /></p>
<p>每个进程都有独立的进程地址空间，通过页表和MMU，可将虚拟地址转换为物理地址，每个进程都有独立的页表数据，这可解释为什么两个不同进程相同的虚拟地址，却对应不同的物理地址。</p>
<p><strong>什么是虚拟地址空间？</strong></p>
<p>每个进程都有4G的虚拟地址空间，其中3G用户空间，1G内核空间（linux），每个进程共享内核空间，独立的用户空间，下图形象地表达了这点</p>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cDovL2ltZy5ibG9nLmNzZG4ubmV0LzIwMTYwMTE0MjAwNzU5MTc0?x-oss-process=image/format,png" alt="img" /></p>
<p>驱动程序运行在内核空间，所以驱动程序是面向所有进程的。</p>
<p>用户空间切换到内核空间有两种方法：</p>
<p>（1）系统调用，即软中断</p>
<p>（2）硬件中断</p>
<p><strong>虚拟地址空间里面是什么？</strong></p>
<p>了解了什么是虚拟地址空间，那么虚拟地址空间里面装的是什么？看下图</p>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cDovL2ltZy5ibG9nLmNzZG4ubmV0LzIwMTYwMTE0MjAxMzAzMzkx?x-oss-process=image/format,png" alt="img" /></p>
<p>虚拟空间装的大概是上面那些数据了，内存映射大概就是把设备地址映射到上图的红色段了，暂且称其为“内存映射段”，至于映射到哪个地址，是由操作系统分配的，操作系统会把进程空间划分为三个部分：</p>
<p>（1）未分配的，即进程还未使用的地址</p>
<p>（2）缓存的，缓存在ram中的页</p>
<p>（3）未缓存的，没有缓存在ram中</p>
<p>操作系统会在未分配的地址空间分配一段虚拟地址，用来和设备地址建立映射。</p>
<p>页缓存是linux内核一种重要的磁盘高速缓存，它通过软件机制实现。但页缓存和硬件cache的原理基本相同，将容量大而低速设备中的部分数据存放到容量小而快速的设备中，这样速度快的设备将作为低速设备的缓存，当访问低速设备中的数据时，可以直接从缓存中获取数据而不需再访问低速设备，从而节省了整体的访问时间。</p>
<p>页缓存以页为大小进行数据缓存，它将磁盘中最常用和最重要的数据存放到部分物理内存中，使得系统访问块设备时可以直接从主存中获取块设备数据，而不需从磁盘中获取数据。</p>
<p>在大多数情况下，内核在读写磁盘时都会使用页缓存。内核在读文件时，首先在已有的页缓存中查找所读取的数据是否已经存在。如果该页缓存不存在，则一个新的页将被添加到高速缓存中，然后用从磁盘读取的数据填充它。如果当前物理内存足够空闲，那么该页将长期保留在高速缓存中，使得其他进程再使用该页中的数据时不再访问磁盘。写操作与读操作时类似，直接在页缓存中修改数据，但是页缓存中修改的数据(该页此时被称为Dirty Page)并不是马上就被写入磁盘，而是延迟几秒钟，以防止进程对该页缓存中的数据再次修改。</p>
<h2 id="主流消息中间件的对比"><a class="header" href="#主流消息中间件的对比">主流消息中间件的对比</a></h2>
<div class="table-wrapper"><table><thead><tr><th><strong>特性</strong></th><th>ActiveMQ</th><th><strong>RabbitMQ</strong></th><th><strong>RocketMQ</strong></th><th>Kafka</th></tr></thead><tbody>
<tr><td>单机吞吐量</td><td>万级，比 RocketMQ、Kafka 低一个数量级</td><td>同 ActiveMQ</td><td>10 万级，支撑高吞吐</td><td>10 万级，高吞吐，一般配合大数据类的系统来进行实时数据计算、日志采集等场景</td></tr>
<tr><td>topic 数量对吞吐量的影响</td><td></td><td></td><td>topic 可以达到几百/几千的级别，吞吐量会有较小幅度的下降，这是 RocketMQ 的一大优势，在同等机器下，可以支撑大量的 topic</td><td>topic 从几十到几百个时候，吞吐量会大幅度下降，在同等机器下，Kafka 尽量保证 topic 数量不要过多，如果要支撑大规模的 topic，需要增加更多的机器资源</td></tr>
<tr><td>时效性</td><td>ms 级</td><td>微秒级，这是 RabbitMQ 的一大特点，延迟最低</td><td>ms 级</td><td>延迟在 ms 级以内</td></tr>
<tr><td>可用性</td><td>高，基于主从架构实现高可用</td><td>同 ActiveMQ</td><td>非常高，分布式架构</td><td>非常高，分布式，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用</td></tr>
<tr><td>消息可靠性</td><td>有较低的概率丢失数据</td><td>基本不丢</td><td>经过参数优化配置，可以做到 0 丢失</td><td>同 RocketMQ</td></tr>
<tr><td>功能支持</td><td>MQ 领域的功能极其完备</td><td>基于 erlang 开发，并发能力很强，性能极好，延时很低</td><td>MQ 功能较为完善，还是分布式的，扩展性好</td><td>功能较为简单，主要支持简单的 MQ 功能，在大数据领域的实时计算以及日志采集被大规模使用</td></tr>
</tbody></table>
</div><div style="break-before: page; page-break-before: always;"></div><h1 id="mybatis"><a class="header" href="#mybatis">Mybatis</a></h1>
<h2 id="mybatis使用"><a class="header" href="#mybatis使用">Mybatis使用</a></h2>
<p>ORM框架：Object Relational Mapping。用于实现面向对象编程语言里不同类型系统的数据之间的转换。</p>
<ul>
<li>
<p>添加依赖</p>
<ul>
<li>
<pre><code class="language-java">&lt;dependency&gt;
    &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt;
    &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt;
    &lt;version&gt;2.0.1&lt;/version&gt;
&lt;/dependency&gt;
</code></pre>
</li>
</ul>
</li>
<li>
<p>配置文件中配置mybatis的mapper文件位置。</p>
<ul>
<li>
<pre><code class="language-java">mybatis.mapper-locations=classpath:mapper/*.xml
</code></pre>
</li>
</ul>
</li>
<li>
<p>pom.xml 设置springboot在包中扫描xml文件。</p>
</li>
<li>
<p>启动类添加注解用于给出需要扫描的mapper文件路径@MapperScan(&quot;xxx.xxx.xxx.xxx&quot;)。</p>
</li>
<li>
<p>逆向工程依赖</p>
<pre><code class="language-java">&lt;plugin&gt;
    &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt;
    &lt;artifactId&gt;mybatis-generator-maven-plugin&lt;/artifactId&gt;
    &lt;version&gt;1.4.1&lt;/version&gt;
    &lt;configuration&gt;
        &lt;!--允许移动生成的文件 --&gt;
        &lt;verbose&gt;true&lt;/verbose&gt;
        &lt;!-- 是否覆盖 --&gt;
        &lt;overwrite&gt;true&lt;/overwrite&gt;
        &lt;!-- 自动生成的配置文件路径。启动插件时，插件会根据这里配置的路径去找到generatorConfig.xml配置文件，
        根据配置文件里的配置，去自动生成Mapper接口（可以理解为Dao层）、实体类、Mapper.xml文件
        --&gt;
        &lt;configurationFile&gt;src/main/resources/GeneratorConfig.xml&lt;/configurationFile&gt;
    &lt;/configuration&gt;
    &lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;mysql&lt;/groupId&gt;
            &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;
            &lt;version&gt;8.0.29&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt;
            &lt;artifactId&gt;mybatis-generator-core&lt;/artifactId&gt;
            &lt;version&gt;1.4.1&lt;/version&gt;
        &lt;/dependency&gt;

    &lt;/dependencies&gt;
    &lt;executions&gt;
        &lt;execution&gt;
            &lt;id&gt;Generate MyBatis Artifacts&lt;/id&gt;
            &lt;phase&gt;package&lt;/phase&gt;
            &lt;goals&gt;
                &lt;goal&gt;generate&lt;/goal&gt;
            &lt;/goals&gt;
        &lt;/execution&gt;
    &lt;/executions&gt;
&lt;/plugin&gt;
</code></pre>
<p>generatorConfig.xml</p>
<pre><code class="language-java">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;!DOCTYPE generatorConfiguration
        PUBLIC &quot;-//mybatis.org//DTD MyBatis Generator Configuration 1.0//EN&quot;
        &quot;http://mybatis.org/dtd/mybatis-generator-config_1.0.dtd&quot;&gt;
&lt;generatorConfiguration&gt;

    &lt;!-- 数据库驱动:选择你的本地硬盘上面的数据库驱动包 --&gt;
    &lt;!--    因为已经在pom.xml添加逆向工程插件时添加了驱动依赖，所以省略这一步--&gt;
    &lt;!--    &lt;classPathEntry  location=&quot;C:\Users\lenovo\Desktop\Software_project\java\mysql-connector-java-8.0.28/mysql-connector-java-8.0.28.jar&quot;/&gt;--&gt;

    &lt;context id=&quot;DB2Tables&quot; targetRuntime=&quot;MyBatis3&quot;&gt;
        &lt;!-- 实体类生成序列化属性--&gt;
        &lt;plugin type=&quot;org.mybatis.generator.plugins.SerializablePlugin&quot;/&gt;
        &lt;!-- 实体类重写HashCode()和equals()--&gt;
        &lt;plugin type=&quot;org.mybatis.generator.plugins.EqualsHashCodePlugin&quot;/&gt;
        &lt;!-- 实体类重写toString() --&gt;
        &lt;plugin type=&quot;org.mybatis.generator.plugins.ToStringPlugin&quot;/&gt;

        &lt;commentGenerator&gt;
            &lt;!-- 是否去除自动生成的注释 --&gt;
            &lt;property name=&quot;suppressAllComments&quot; value=&quot;true&quot;/&gt;
            &lt;!-- 生成注释是否带时间戳--&gt;
            &lt;property name=&quot;suppressDate&quot; value=&quot;true&quot;/&gt;
            &lt;!-- 生成的Java文件的编码格式 --&gt;
            &lt;property name=&quot;javaFileEncoding&quot; value=&quot;utf-8&quot;/&gt;
            &lt;!-- 数据库注释支持 --&gt;
            &lt;property name=&quot;addRemarkComments&quot; value=&quot;true&quot;/&gt;
            &lt;!-- 时间格式设置 --&gt;
            &lt;property name=&quot;dateFormat&quot; value=&quot;yyyy-MM-dd HH:mm:ss&quot;/&gt;
            &lt;!-- 格式化java代码--&gt;
            &lt;property name=&quot;javaFormatter&quot; value=&quot;org.mybatis.generator.api.dom.DefaultJavaFormatter&quot;/&gt;
            &lt;!-- 格式化XML代码--&gt;
            &lt;property name=&quot;xmlFormatter&quot; value=&quot;org.mybatis.generator.api.dom.DefaultXmlFormatter&quot;/&gt;
        &lt;/commentGenerator&gt;

        &lt;!-- 数据库连接驱动类,URL，用户名、密码 --&gt;
        &lt;jdbcConnection driverClass=&quot;com.mysql.cj.jdbc.Driver&quot;
                        connectionURL=&quot;jdbc:mysql://119.45.27.47:3306/dms_usp?useSSL=false&amp;amp;useUnicode=true&amp;amp;characterEncoding=utf-8&quot;
                        userId=&quot;FordDms&quot;
                        password=&quot;FordDms.1234&quot;&gt;
            &lt;property name=&quot;nullCatalogMeansCurrent&quot; value=&quot;true&quot;/&gt;
        &lt;/jdbcConnection&gt;

        &lt;!-- java类型处理器：处理DB中的类型到Java中的类型 --&gt;
        &lt;javaTypeResolver type=&quot;org.mybatis.generator.internal.types.JavaTypeResolverDefaultImpl&quot;&gt;
            &lt;!-- 是否有效识别DB中的BigDecimal类型 --&gt;
            &lt;property name=&quot;forceBigDecimals&quot; value=&quot;true&quot;/&gt;
        &lt;/javaTypeResolver&gt;

        &lt;!-- 生成Domain模型：包名(targetPackage)、位置(targetProject) --&gt;
        &lt;javaModelGenerator targetPackage=&quot;com.yonyou.dms.web.entity&quot; targetProject=&quot;E:\workspace\Parent\Login\src\main\java&quot;&gt;
            &lt;!-- 在targetPackage的基础上，根据数据库的schema再生成一层package，最终生成的类放在这个package下，默认为false --&gt;
            &lt;property name=&quot;enableSubPackages&quot; value=&quot;true&quot;/&gt;
            &lt;!-- 设置是否在getter方法中，对String类型字段调用trim()方法--&gt;
            &lt;property name=&quot;trimStrings&quot; value=&quot;true&quot;/&gt;
        &lt;/javaModelGenerator&gt;

        &lt;!-- 生成xml映射文件：包名(targetPackage)、位置(targetProject) --&gt;
        &lt;sqlMapGenerator targetPackage=&quot;mapper&quot; targetProject=&quot;E:\workspace\Parent\Login\src\main\resources&quot;&gt;
            &lt;property name=&quot;enableSubPackages&quot; value=&quot;true&quot;/&gt;
        &lt;/sqlMapGenerator&gt;

        &lt;!-- 生成DAO接口：包名(targetPackage)、位置(targetProject) --&gt;
        &lt;javaClientGenerator type=&quot;XMLMAPPER&quot; targetPackage=&quot;com.yonyou.dms.web.dao&quot;
                             targetProject=&quot;E:\workspace\Parent\Login\src\main\java&quot;&gt;
            &lt;property name=&quot;enableSubPackages&quot; value=&quot;true&quot;/&gt;
        &lt;/javaClientGenerator&gt;

        &lt;table tableName=&quot;tc_menu_action&quot; domainObjectName=&quot;MenuAction&quot;&gt;
            &lt;!--            若数据库中某个属性类型为text或类似类型，可能会发生无法生成这个属性，此时可以在这里指定转换类型为VARCHAR--&gt;
            &lt;!--            &lt;columnOverride column=&quot;teacher_name&quot; jdbcType=&quot;VARCHAR&quot; /&gt;--&gt;
&lt;!--        　　table标签下的设置属性useActualColumnNames用于指定生成实体类时是否使用实际的列名作为实体类的属性名，取值true或false。--&gt;
&lt;!--        　　true：MyBatis Generator会使用数据库中实际的字段名字作为生成的实体类的属性名。--&gt;
&lt;!--        　　false：这是默认值。如果设置为false,则MyBatis Generator会将数据库中实际的字段名字转换为Camel Case风格作为生成的实体类的属性名。--&gt;
            &lt;property name=&quot;useActualColumnNames&quot; value=&quot;false&quot; /&gt;
        &lt;/table&gt;
    &lt;/context&gt;
&lt;/generatorConfiguration&gt;
</code></pre>
</li>
</ul>
<p>先执行二级缓存，再执行一级缓存。</p>
<pre><code class="language-java">public &lt;E&gt; List&lt;E&gt; query(MappedStatement ms, Object parameterObject, RowBounds rowBounds, ResultHandler resultHandler) throws SQLException {
    BoundSql boundSql = ms.getBoundSql(parameterObject);
    CacheKey key = this.createCacheKey(ms, parameterObject, rowBounds, boundSql);
    return this.query(ms, parameterObject, rowBounds, resultHandler, key, boundSql);
}
</code></pre>
<p>mybatis调用query时如何使用缓存，createCacheKey生成key。</p>
<pre><code class="language-java">public CacheKey createCacheKey(MappedStatement ms, Object parameterObject, RowBounds rowBounds, BoundSql boundSql) {
    if (this.closed) {
        throw new ExecutorException(&quot;Executor was closed.&quot;);
    } else {
        CacheKey cacheKey = new CacheKey();
        cacheKey.update(ms.getId());
        cacheKey.update(rowBounds.getOffset());
        cacheKey.update(rowBounds.getLimit());
        cacheKey.update(boundSql.getSql());
        List&lt;ParameterMapping&gt; parameterMappings = boundSql.getParameterMappings();
        TypeHandlerRegistry typeHandlerRegistry = ms.getConfiguration().getTypeHandlerRegistry();
        Iterator var8 = parameterMappings.iterator();

        while(var8.hasNext()) {
            ParameterMapping parameterMapping = (ParameterMapping)var8.next();
            if (parameterMapping.getMode() != ParameterMode.OUT) {
                String propertyName = parameterMapping.getProperty();
                Object value;
                if (boundSql.hasAdditionalParameter(propertyName)) {
                    value = boundSql.getAdditionalParameter(propertyName);
                } else if (parameterObject == null) {
                    value = null;
                } else if (typeHandlerRegistry.hasTypeHandler(parameterObject.getClass())) {
                    value = parameterObject;
                } else {
                    MetaObject metaObject = this.configuration.newMetaObject(parameterObject);
                    value = metaObject.getValue(propertyName);
                }

                cacheKey.update(value);
            }
        }

        if (this.configuration.getEnvironment() != null) {
            cacheKey.update(this.configuration.getEnvironment().getId());
        }

        return cacheKey;
    }
}
</code></pre>
<p>执行查询方法。</p>
<pre><code class="language-java">public &lt;E&gt; List&lt;E&gt; query(MappedStatement ms, Object parameterObject, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql) throws SQLException {
    // 查询时先从二级缓存中获取数据
    Cache cache = ms.getCache();
    if (cache != null) {
        this.flushCacheIfRequired(ms);
        if (ms.isUseCache() &amp;&amp; resultHandler == null) {
            this.ensureNoOutParams(ms, boundSql);
            List&lt;E&gt; list = (List)this.tcm.getObject(cache, key);
            if (list == null) {
                list = this.delegate.query(ms, parameterObject, rowBounds, resultHandler, key, boundSql);
                this.tcm.putObject(cache, key, list);
            }

            return list;
        }
    }

    return this.delegate.query(ms, parameterObject, rowBounds, resultHandler, key, boundSql);
}
</code></pre>
<pre><code class="language-java">public &lt;E&gt; List&lt;E&gt; query(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql) throws SQLException {
    ErrorContext.instance().resource(ms.getResource()).activity(&quot;executing a query&quot;).object(ms.getId());
    if (this.closed) {
        throw new ExecutorException(&quot;Executor was closed.&quot;);
    } else {
        if (this.queryStack == 0 &amp;&amp; ms.isFlushCacheRequired()) {
            this.clearLocalCache();
        }

        List list;
        try {
            ++this.queryStack;
            // 根据key获取缓存中是否存在数据，存在数据从缓存中查询数据，否则从数据库查询数据
            list = resultHandler == null ? (List)this.localCache.getObject(key) : null;
            if (list != null) {
                this.handleLocallyCachedOutputParameters(ms, key, parameter, boundSql);
            } else {
                list = this.queryFromDatabase(ms, parameter, rowBounds, resultHandler, key, boundSql);
            }
        } finally {
            --this.queryStack;
        }

        if (this.queryStack == 0) {
            Iterator var8 = this.deferredLoads.iterator();

            while(var8.hasNext()) {
                DeferredLoad deferredLoad = (DeferredLoad)var8.next();
                deferredLoad.load();
            }

            this.deferredLoads.clear();
            if (this.configuration.getLocalCacheScope() == LocalCacheScope.STATEMENT) {
                this.clearLocalCache();
            }
        }

        return list;
    }
}
</code></pre>
<pre><code class="language-java">private &lt;E&gt; List&lt;E&gt; queryFromDatabase(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql) throws SQLException {
    this.localCache.putObject(key, ExecutionPlaceholder.EXECUTION_PLACEHOLDER);

    List list;
    try {
        list = this.doQuery(ms, parameter, rowBounds, resultHandler, boundSql);
    } finally {
        this.localCache.removeObject(key);
    }

    this.localCache.putObject(key, list);
    if (ms.getStatementType() == StatementType.CALLABLE) {
        this.localOutputParameterCache.putObject(key, parameter);
    }

    return list;
}
</code></pre>
<pre><code class="language-java">public RoutingStatementHandler(Executor executor, MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) {
    switch (ms.getStatementType()) {
            // 普通类型
        case STATEMENT:
            this.delegate = new SimpleStatementHandler(executor, ms, parameter, rowBounds, resultHandler, boundSql);
            break;
            // 预编译
        case PREPARED:
            this.delegate = new PreparedStatementHandler(executor, ms, parameter, rowBounds, resultHandler, boundSql);
            break;
            // 存储过程
        case CALLABLE:
            this.delegate = new CallableStatementHandler(executor, ms, parameter, rowBounds, resultHandler, boundSql);
            break;
        default:
            throw new ExecutorException(&quot;Unknown statement type: &quot; + ms.getStatementType());
    }

}
</code></pre>
<pre><code class="language-java">public ResultSetWrapper(ResultSet rs, Configuration configuration) throws SQLException {
    this.typeHandlerRegistry = configuration.getTypeHandlerRegistry();
    this.resultSet = rs;
    ResultSetMetaData metaData = rs.getMetaData();
    // 获取表行数
    int columnCount = metaData.getColumnCount();

    for(int i = 1; i &lt;= columnCount; ++i) {
        // columnNames 字段名称
        this.columnNames.add(configuration.isUseColumnLabel() ? metaData.getColumnLabel(i) : metaData.getColumnName(i));
        // jdbcTypes 数据库字段类型
        this.jdbcTypes.add(JdbcType.forCode(metaData.getColumnType(i)));
        // classNames java 字段类型
        this.classNames.add(metaData.getColumnClassName(i));
    }
}
</code></pre>
<p><strong>spring整合mybatis 实现</strong></p>
<pre><code class="language-java">@Autowired
private UserMapper userMapper; // Mybatis生成的UserMapper代理对象 --&gt; Bean对象
</code></pre>
<h2 id="sqlsessionfactorybean的底层原理"><a class="header" href="#sqlsessionfactorybean的底层原理">SqlSessionFactoryBean的底层原理</a></h2>
<p>SqlSessionFactoryBean是MyBatis框架中的一个重要组件，它的主要作用是创建SqlSessionFactory对象，SqlSessionFactory是MyBatis框架中的核心对象，它负责管理MyBatis的所有配置信息，并且提供了创建SqlSession对象的方法。SqlSessionFactoryBean的底层原理是通过读取MyBatis的配置文件，解析其中的配置信息，然后根据配置信息创建SqlSessionFactory对象。在创建SqlSessionFactory对象的过程中，SqlSessionFactoryBean会使用MyBatis框架中的多个组件，包括Configuration、MapperRegistry、TypeHandlerRegistry等，这些组件都是MyBatis框架中的核心组件，它们负责管理MyBatis的各种配置信息，并且提供了各种功能的实现。SqlSessionFactoryBean的底层原理比较复杂，需要深入了解MyBatis框架的各个组件之间的关系和作用，才能更好地理解它的实现原理。</p>
<pre><code class="language-java">@Bean
public SqlSessionFactory sqlSessionFactory() throws IOException{
    InputStream inputStream = Resources.getResourceAsStream(&quot;mybatis-config.xml&quot;);
    return new SqlSessionFactoryBuilder().build(inputStream);
}

@Bean
public UserMapper userMapper(SqlSessionFactory sqlSessionFactory) {
    // Mybatis 代理对象
    sqlSessionFactory.getConfiguration().addMapper(UserMapper.class);
    SqlSession sqlSession = sqlSessionFactory.openSession();
    return sqlSession.getMapper(UserMapper.class);
}
</code></pre>
<h2 id="factorybean的作用和底层工作原理"><a class="header" href="#factorybean的作用和底层工作原理">FactoryBean的作用和底层工作原理</a></h2>
<p>FactoryBean是Spring框架中的一个接口，它的作用是用于创建和管理Bean对象。FactoryBean可以将复杂的Bean对象的创建过程封装起来，使得应用程序只需要通过FactoryBean获取Bean对象即可，而不需要关心Bean对象的创建过程。FactoryBean的底层工作原理是通过实现getObject()方法来创建Bean对象，同时还可以通过实现其他方法来控制Bean对象的生命周期和行为。</p>
<pre><code class="language-java">@Component
public class TestFactoryBean implements FactoryBean {
    // 实现FactoryBean接口会生成两个Bean对象 1、TestFactoryBean 2、getObject
    // 先生成TestFactoryBean 之后再生成 getObject
    
    @Autowired
    private SqlSessionFactory sqlSessionFactory;
    
    @Override
    public Object getObject() throws Exception {
        sqlSessionFactory.getConfiguration().addMapper(UserMapper.class);
        SqlSession sqlSession = sqlSessionFactory.openSession();
        return sqlSession.getMapper(UserMapper.class);
    }

    @Override
    public Class&lt;?&gt; getObjectType() {
        return UserMapper.class;
    }
}
</code></pre>
<p>FactoryBean复用</p>
<pre><code class="language-java">AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext();
applicationContext.register(DegreeApplication.class);

// 与@Component 一样的作用
AbstractBeanDefinition beanDefinition = BeanDefinitionBuilder.genericBeanDefinition().getBeanDefinition();
beanDefinition.setBeanClass(TestFactoryBean.class);
beanDefinition.getConstructorArgumentValues().addGenericArgumentValue(UserMapper.class);
applicationContext.registerBeanDefinition(&quot;userMapper&quot;, beanDefinition);
</code></pre>
<pre><code class="language-java">@Component
public class TestFactoryBean implements FactoryBean {

  @Autowired
  private SqlSessionFactory sqlSessionFactory;

  private final Class mapperClass;

  public TestFactoryBean(Class mapperClass) {
    this.mapperClass = mapperClass;
  }

  @Override
  public Object getObject() throws Exception {
    sqlSessionFactory.getConfiguration().addMapper(mapperClass);
    SqlSession sqlSession = sqlSessionFactory.openSession();
    return sqlSession.getMapper(mapperClass);
  }

  @Override
  public Class&lt;?&gt; getObjectType() {
    return User.class;
  }
}
</code></pre>
<h2 id="importbeandefinitionregistrar底层原理"><a class="header" href="#importbeandefinitionregistrar底层原理">ImportBeanDefinitionRegistrar底层原理</a></h2>
<ol>
<li>ImportBeanDefinitionRegistrar实现类重写registerBeanDefinitions方法。</li>
<li>在registerBeanDefinitions方法中，通过BeanDefinitionRegistry接口注册bean定义。</li>
</ol>
<pre><code class="language-java">public class TestImportBeanDefinitionRegistrar implements ImportBeanDefinitionRegistrar {

    @Override
    public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) {
        ArrayList&lt;Class&gt; list = new ArrayList&lt;&gt;();
        list.add(UserMapper.class);

        for (Class mapperClass : list) {
            AbstractBeanDefinition beanDefinition = BeanDefinitionBuilder.genericBeanDefinition().getBeanDefinition();
            beanDefinition.setBeanClass(TestFactoryBean.class);
            beanDefinition.getConstructorArgumentValues().addGenericArgumentValue(mapperClass);
            registry.registerBeanDefinition(mapperClass.getName(), beanDefinition);
        }
    }
}
</code></pre>
<pre><code class="language-java">// 使用@Import 导入配置的类
@Import(TestImportBeanDefinitionRegistrar.class)
public class DegreeApplication {
    
}
</code></pre>
<h2 id="mapperscannerconfigurer底层源码分析"><a class="header" href="#mapperscannerconfigurer底层源码分析">MapperScannerConfigurer底层源码分析</a></h2>
<ul>
<li>MapperScannerConfigurer底层源码分析。</li>
<li>MapperScannerConfigurer是MyBatis提供的一个BeanFactoryPostProcessor，用于扫描指定包下的Mapper接口，并将其注册到Spring容器中。</li>
<li>在MyBatis中，Mapper接口是通过MapperProxyFactory来创建代理对象的，而MapperScannerConfigurer的作用就是将Mapper接口的代理对象注册到Spring容器中，以便在需要使用Mapper接口时，可以直接从Spring容器中获取代理对象。</li>
<li>MapperScannerConfigurer的实现原理是通过Spring的ClassPathBeanDefinitionScanner来扫描指定包下的所有类，然后判断是否是Mapper接口，如果是，则将其注册到Spring容器中。</li>
<li>在注册Mapper接口时，MapperScannerConfigurer会为每个Mapper接口创建一个MapperFactoryBean，MapperFactoryBean是一个FactoryBean，用于创建Mapper接口的代理对象。</li>
<li>MapperFactoryBean的实现原理是通过MapperProxyFactory来创建Mapper接口的代理对象，然后将其返回给Spring容器。</li>
<li>总结一下，MapperScannerConfigurer的作用是将Mapper接口的代理对象注册到Spring容器中，以便在需要使用Mapper接口时，可以直接从Spring容器中获取代理对象。MapperScannerConfigurer的实现原理是通过Spring的ClassPathBeanDefinitionScanner来扫描指定包下的所有类，然后判断是否是Mapper接口，如果是，则将其注册到Spring容器中，并为每个Mapper接口创建一个MapperFactoryBean，用于创建Mapper接口的代理对象。</li>
</ul>
<pre><code class="language-java">public class TestMapperScanner extends ClassPathBeanDefinitionScanner {

    @Override
    protected boolean isCandidateComponent(MetadataReader metadataReader) throws IOException {
        // 是否 @component 注解
        return true;
    }

    @Override
    protected boolean isCandidateComponent(AnnotatedBeanDefinition beanDefinition) {
        // 是否 接口类
        return beanDefinition.getMetadata().isInterface();
    }

    public TestMapperScanner(BeanDefinitionRegistry registry) {
        super(registry);
    }

    @Override
    protected Set&lt;BeanDefinitionHolder&gt; doScan(String... basePackages) {
        // 重写 doScan 方法 
        Set&lt;BeanDefinitionHolder&gt; beanDefinitionHolders = super.doScan(basePackages);
        for (BeanDefinitionHolder beanDefinitionHolder : beanDefinitionHolders) {
            GenericBeanDefinition genericBeanDefinition = (GenericBeanDefinition) beanDefinitionHolder.getBeanDefinition();
            genericBeanDefinition.getConstructorArgumentValues().addGenericArgumentValue(Objects.requireNonNull(genericBeanDefinition.getBeanClassName()));
            genericBeanDefinition.setBeanClass(TestFactoryBean.class);
        }

        return beanDefinitionHolders;
    }
}
</code></pre>
<p>使用MapperScanner自定义扫描mapper。</p>
<pre><code class="language-java">public class TestImportBeanDefinitionRegistrar implements ImportBeanDefinitionRegistrar {

    @Override
    public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) {
        TestMapperScanner testMapperScanner = new TestMapperScanner(registry);
        testMapperScanner.scan(&quot;com.second.degree.java.mybatis.mapper&quot;);
    }
}
</code></pre>
<h2 id="mapperscan注解的底层源码分析"><a class="header" href="#mapperscan注解的底层源码分析">@MapperScan注解的底层源码分析</a></h2>
<p>@MapperScan注解是MyBatis框架提供的一个注解，用于扫描Mapper接口并将其注册到Spring容器中。其底层源码分析可以从以下几个方面入手：</p>
<ol>
<li>@MapperScan注解的定义：可以查看该注解的定义，了解其属性和作用。</li>
<li>扫描器的实现：@MapperScan注解的底层实现是通过扫描器实现的，可以查看扫描器的源码，了解其扫描的规则和实现方式。</li>
<li>注册Mapper接口：扫描器扫描到Mapper接口后，需要将其注册到Spring容器中，可以查看注册的源码，了解其实现方式和注册的规则。</li>
<li>与Spring集成：@MapperScan注解是与Spring集成的，可以查看其与Spring集成的源码，了解其实现方式和与Spring的交互方式。</li>
</ol>
<pre><code class="language-java">@Target(ElementType.TYPE)
@Retention(RetentionPolicy.RUNTIME)
@Import(TestImportBeanDefinitionRegistrar.class)
public @interface TestMapperScan {
    String value();
}
</code></pre>
<pre><code class="language-java">@TestMapperScan(&quot;com.second.degree.java.mybatis.mapper&quot;)
public class DegreeApplication {}
</code></pre>
<pre><code class="language-java">public class TestImportBeanDefinitionRegistrar implements ImportBeanDefinitionRegistrar {

    @Override
    public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) {

        Map&lt;String, Object&gt; annotationAttributes = importingClassMetadata.getAnnotationAttributes(TestMapperScan.class.getName());
        String path = (String) annotationAttributes.get(&quot;value&quot;);

        TestMapperScanner testMapperScanner = new TestMapperScanner(registry);
        testMapperScanner.scan(path);
    }
}
</code></pre>
<h2 id="spring整合mybatis的底层源码分析"><a class="header" href="#spring整合mybatis的底层源码分析">Spring整合Mybatis的底层源码分析</a></h2>
<p>mybaits 2.0.6 以下版本直接在registerBeanDefinitions 中实现 Scanner 扫描器，使用注解@MapperScan。</p>
<pre><code class="language-java">@MapperScan
public class DegreeApplication {}
</code></pre>
<pre><code class="language-java">void registerBeanDefinitions(AnnotationAttributes annoAttrs, BeanDefinitionRegistry registry) {
        ClassPathMapperScanner scanner = new ClassPathMapperScanner(registry);
	...
}
</code></pre>
<p>mybaits 2.0.6 以上版本 是通过另一个Bean MapperScannerConfigurer 实现Scanner 扫描器，可以不使用@MapperScan，通过注册MapperScannerConfigurer 实现扫描。</p>
<pre><code class="language-java">void registerBeanDefinitions(AnnotationMetadata annoMeta, AnnotationAttributes annoAttrs, BeanDefinitionRegistry registry, String beanName) {
        BeanDefinitionBuilder builder = BeanDefinitionBuilder.genericBeanDefinition(MapperScannerConfigurer.class);
	...
}
</code></pre>
<pre><code class="language-java">public class DegreeApplication {

    @Bean
    public MapperScannerConfigurer mapperScannerConfigurer() {
        MapperScannerConfigurer configurer = new MapperScannerConfigurer();
        configurer.setBasePackage(&quot;com.second.degree.java.mybatis.mapper&quot;);
        return configurer;
    }
}
</code></pre>
<h2 id="springboot整合mybatis的底层源码分析"><a class="header" href="#springboot整合mybatis的底层源码分析">SpringBoot整合Mybatis的底层源码分析</a></h2>
<ol>
<li>
<p>使用@MapperScan，会扫到很多无用的类，效率会差点。mybatis-spring包。</p>
</li>
<li>
<p>自动配置类MybatisAutoConfiguration。mybatis-spring-boot-autoconfigure包。</p>
<pre><code class="language-java">public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) {
    if (!AutoConfigurationPackages.has(this.beanFactory)) {
        MybatisAutoConfiguration.logger.debug(&quot;Could not determine auto-configuration package, automatic mapper scanning disabled.&quot;);
    } else {
        MybatisAutoConfiguration.logger.debug(&quot;Searching for mappers annotated with @Mapper&quot;);
        // 扫描的包路径 为 springboot 启动 run 方法的路径
        List&lt;String&gt; packages = AutoConfigurationPackages.get(this.beanFactory);
        if (MybatisAutoConfiguration.logger.isDebugEnabled()) {
            packages.forEach((pkg) -&gt; {
                MybatisAutoConfiguration.logger.debug(&quot;Using auto-configuration base package '{}'&quot;, pkg);
            });
        }

        BeanDefinitionBuilder builder = BeanDefinitionBuilder.genericBeanDefinition(MapperScannerConfigurer.class);
        builder.addPropertyValue(&quot;processPropertyPlaceHolders&quot;, true);
        // 只识别@Mapper 注解定义的接口类
        builder.addPropertyValue(&quot;annotationClass&quot;, Mapper.class);
        builder.addPropertyValue(&quot;basePackage&quot;, StringUtils.collectionToCommaDelimitedString(packages));
        BeanWrapper beanWrapper = new BeanWrapperImpl(MapperScannerConfigurer.class);
        Set&lt;String&gt; propertyNames = (Set)Stream.of(beanWrapper.getPropertyDescriptors()).map(FeatureDescriptor::getName).collect(Collectors.toSet());
        if (propertyNames.contains(&quot;lazyInitialization&quot;)) {
            builder.addPropertyValue(&quot;lazyInitialization&quot;, &quot;${mybatis.lazy-initialization:false}&quot;);
        }

        if (propertyNames.contains(&quot;defaultScope&quot;)) {
            builder.addPropertyValue(&quot;defaultScope&quot;, &quot;${mybatis.mapper-default-scope:}&quot;);
        }

        boolean injectSqlSession = (Boolean)this.environment.getProperty(&quot;mybatis.inject-sql-session-on-mapper-scan&quot;, Boolean.class, Boolean.TRUE);
        if (injectSqlSession &amp;&amp; this.beanFactory instanceof ListableBeanFactory) {
            ListableBeanFactory listableBeanFactory = (ListableBeanFactory)this.beanFactory;
            Optional&lt;String&gt; sqlSessionTemplateBeanName = Optional.ofNullable(this.getBeanNameForType(SqlSessionTemplate.class, listableBeanFactory));
            Optional&lt;String&gt; sqlSessionFactoryBeanName = Optional.ofNullable(this.getBeanNameForType(SqlSessionFactory.class, listableBeanFactory));
            if (!sqlSessionTemplateBeanName.isPresent() &amp;&amp; sqlSessionFactoryBeanName.isPresent()) {
                builder.addPropertyValue(&quot;sqlSessionFactoryBeanName&quot;, sqlSessionFactoryBeanName.get());
            } else {
                builder.addPropertyValue(&quot;sqlSessionTemplateBeanName&quot;, sqlSessionTemplateBeanName.orElse(&quot;sqlSessionTemplate&quot;));
            }
        }

        builder.setRole(2);
        registry.registerBeanDefinition(MapperScannerConfigurer.class.getName(), builder.getBeanDefinition());
    }
}
</code></pre>
</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="mysql"><a class="header" href="#mysql">Mysql</a></h1>
<h2 id="mysql-innodb"><a class="header" href="#mysql-innodb">Mysql InnoDB</a></h2>
<p>MYSQL InnoDB二级索引存储主键值而不是存储行指针的优点与缺点。</p>
<blockquote>
<p>优点：</p>
<ul>
<li>减少了出现行移动或者数据页分裂时二级索引的维护工作（当数据需要更新的时候，二级索引不需要修改，只需要修改聚簇索引，一个表只能有一个聚簇索引，其他的都是二级索引，这样只需要修改聚簇索引就可以了，不需要重新构建二级索引）</li>
</ul>
<p>缺点：</p>
<ul>
<li>二级索引体积可能会变大，因为二级索引中存储了主键的信息</li>
<li>二级索引的访问需要两次索引查找。第一次通过查找 <em>二级索引</em> 找二级索引中叶子节点存储的 <em>主键的值</em>；第二次通过这个主键的值去
<em><strong>聚簇索引</strong></em> 中查找对应的行</li>
</ul>
</blockquote>
<h3 id="innodb-简介"><a class="header" href="#innodb-简介">InnoDB 简介</a></h3>
<p>InnoDB是一个将表中的数据存储到磁盘上的存储引擎。而真正处理数据的过程是发生在内存中的，所以需要把磁盘中的数据加载到内存中，如果是处理写入或修改请求的话，还需要把内存中的内容刷新到磁盘上。而我们知道读写磁盘的速度非常慢，和内存读写差了几个数量级。所以当我们想从表中获取某些记录时，InnoDB存储引擎需要一条一条的把记录从磁盘上读出来么？想要了解这个问题，我们首先需要了解InnoDB的存储结构是怎样的。</p>
<p><img src="https://github.com/chou401/pic-md/raw/master/image-20230703165807448.png" alt="image-20230703165807448" /></p>
<p>InnoDB采取的方式是：将数据划分为若干个页，以页作为磁盘和内存之间交互的基本单位innodb_page_size选项指定了MySQL实例的所有InnoDB表空间的页面大小。这个值是在创建实例时设置的，之后保持不变。有效值为64KB，32KB，16KB(默认值 )，8kB和4kB。也就是在一般情况下，一次最少从磁盘中读取16KB的内容到内存中，一次最少把内存中的16KB内容刷新到磁盘中。</p>
<h3 id="innodb-的行格式"><a class="header" href="#innodb-的行格式">InnoDB 的行格式</a></h3>
<p>我们平时是以记录为单位来向表中插入数据的，这些记录在磁盘上的存放方式也被称为行格式或者记录格式。一行记录可以以不同的格式存在InnoDB中，行格式分别是compact、redundant、dynamic和compressed行格式。可以在创建或修改的语句中指定行格式：</p>
<blockquote>
<p>-- 创建数据表时,显示指定行格式CREATE TABLE 表名 (列的信息) ROW_FORMAT=行格式名称;</p>
<p>-- 创建数据表时,修改行格式ALTER TABLE 表名 ROW_FORMAT=行格式名称;</p>
<p>-- 查看数据表的行格式show table status like '';</p>
</blockquote>
<p>mysql5.0之前默认的行格式是redundant，mysql5.0之后的默认行格式为compact ， 5.7之后的默认行格式为dynamic。</p>
<h4 id="compact-格式"><a class="header" href="#compact-格式">compact 格式</a></h4>
<p><img src="https://github.com/chou401/pic-md/raw/master/859ab55da7e84b9da3ec34cd4ca9d611.png" alt="img" /></p>
<h5 id="变长字段长度列表"><a class="header" href="#变长字段长度列表">变长字段长度列表</a></h5>
<p>我们知道 MySQL 支持一些变长的数据类型，比如 VARCHAR(M) 、 VARBINARY(M) 、各种 TEXT 类型，各种 BLOB 类型，我们也可以把拥有这些数据类型的列称为 变长字段 ，变长字段中存储多少字节的数据是不固定的，所以我们在存储真实数据的时候需要顺便把这些数据占用的字节数也存起来，这样才不至于把 MySQL 服务器搞懵，所以这些变长字段占用的存储空间分为两部分：</p>
<ol>
<li>真正的数据内容</li>
<li>占用的字节数</li>
</ol>
<p>在 Compact 行格式中，把所有变长字段的真实数据占用的字节长度都存放在记录的开头部位，从而形成一个变长字段长度列表，各变长字段数据占用的字节数按照列的顺序逆序存放。</p>
<p>举个例子：</p>
<blockquote>
<p>一个表中有c1、c2、c3三列数据为varchar，其中有一行数据存储了(“1234”,“123”,“1”)，它们分别的字符长度就为04、03、01，若其使用ascii字符集存储，则每个的字节大小为，04、03、01（ascii用一字节表示一个字符，utf-8为3字节），则这一行在”变长字段长度列表“中存储的则为”01 03 04“（实际存储为二进制且没有空格）</p>
</blockquote>
<p>由于上面的字符串都比较短，也就是说内容占用的字节数比较小，用1个字节就可以表示，但是如果变长列的内容占用的字节数比较多，可能就需要用2个字节来表示。具体用1个还是2个字节来表示真实数据占用的字节数， InnoDB 有它的一套规则，首先我们声明一下 W 、 M 和 L 的意思：</p>
<blockquote>
<p>假设某个字符集中表示一个字符最多需要使用的字节数为 W ，比方说 utf8 字符集中的 W 就是 1-3 ， ascii 字符集中的 W 就是1 。
对于 VARCHAR(M) 来说，表示此列最多能储存 M 个字符，所以这个类型能表示的字符串最多占用的字节数就是 M×W 。（比如：对于一个字符串”aaa“使用ascii表示则占用1<em>3个字节，而对于utf-8则为3</em>3个字节）
假设某字符串实际占用的字节数是 L 。</p>
</blockquote>
<p>基于以上的声明，则使用1字节还是2 字节来表示变长字段长度的规则为： </p>
<ul>
<li>如果一个字段最长可以储存的字节数小于等于255 B，即<code>W*M &lt;= 255</code>: 使用一个字节表示</li>
<li>如果W*M &gt; 255 B，则分为两种情况：
<ul>
<li>若L &lt;= 127 B 则用1字节表示</li>
<li>若L &gt; 127 B 则用2字节表示</li>
</ul>
</li>
</ul>
<p>此外，innoDB使用 字节的第一位作为标志位，如果第一位为0，则此字节就是一个单独的字段长度。如果为1，则该字节为半个字段长度。</p>
<p>对于一些占用字节数非常多的字段，比方说某个字段长度大于了16KB，那么如果该记录在单个页面中无法存储时，InnoDB会把一部分数据存放到所谓的溢出页中，在变长字段长度列表处只存储留在本页面中的长度，所以使用两个字节也可以存放下来。</p>
<p>另外需要注意的一点是，变长字段长度列表中只存储值为 非NULL 的列内容占用的长度，值为 NULL 的列的长度是不储存的 。</p>
<p>字符集utf-8，英文字符占用1个字节，中文字符3字节，对于char类型来说，若使用utf-8字符集，则char也属于 可变长字段</p>
<h5 id="null值列表"><a class="header" href="#null值列表">NULL值列表</a></h5>
<p>我们知道表中的某些列可能存储 NULL 值，如果把这些 NULL 值都放到记录的真实数据中存储会很占地方，所以 Compact 行格式把这些值为 NULL 的列统一管理起来，存储到 NULL 值列表中，它的处理过程是这样的：</p>
<ol>
<li>
<p>首先统计表中允许存储 NULL 的列有哪些。我们前边说过，主键列、被 NOT NULL 修饰的列都是不可以存储 NULL 值的，所以在统计的时候不会把这些列算进去。</p>
</li>
<li>
<p>如果表中没有允许存储 NULL 的列，则 NULL值列表不存在。若允许，则将每个允许存储 NULL 的列对应一个二进制位，二进制位按照列的顺序逆序排列：二进制位的值为 1 时，代表该列的值为 NULL 。二进制位的值为 0 时，代表该列的值不为 NULL 。</p>
</li>
<li>
<p>MySQL 规定 NULL值列表 必须用整数个字节的位表示，如果使用的二进制位个数不是整数个字节，则在字节的高位补 0 。即若一个表有9个值允许为null，则这个记录null值列表的部分需要用 2 字节表示。</p>
</li>
</ol>
<p><strong>举个例子</strong>： 若有一张表，有c1 c2 c3 c4四个字段，其中c2 被NOT NULL修饰，则其NULL值列表 表示如下：</p>
<p><img src="https://github.com/chou401/pic-md/raw/master/4f4a765331f84efda30d2ae165f45707.png" alt="img" /></p>
<h5 id="记录头信息"><a class="header" href="#记录头信息">记录头信息</a></h5>
<p>记录头信息部分如下图所示：</p>
<p><img src="https://github.com/chou401/pic-md/raw/master/d35c888d876641768d782acb0e6668d3.png" alt="img" /></p>
<p><img src="https://github.com/chou401/pic-md/raw/master/9fac7f2392674842aba39dc969dfa126.png" alt="img" /></p>
<p><img src="https://github.com/chou401/pic-md/raw/master/aef632ad1be7455ab7e23909f68255f1.png" alt="img" /></p>
<p>我们使用如下的sql语句插入几行数据：</p>
<pre><code class="language-mysql">INSERT INTO page_demo 
VALUES
(1, 100, 'aaaa'), 
(2, 200, 'bbbb'), 
(3, 300, 'cccc'),
(4, 400, 'dddd');
</code></pre>
<p>则它们这几条数据记录在 页 的 User Records 部分为：</p>
<p><img src="https://github.com/chou401/pic-md/raw/master/ae0a8a7826e4429683f2c12de76760a1.png" alt="img" /></p>
<p><strong>delete_mask</strong></p>
<p>这个属性标记着当前记录是否被删除，占用1个二进制位，值为 0 的时候代表记录并没有被删除，为 1 的时候代表记录被删除掉了。</p>
<p>被删除的记录还在页中。这些被删除的记录之所以不立即从磁盘上移除，是因为移除它们之后把其他的记录在磁盘上重新排列需要性能消耗，所以只是打一个删除标记而已，所有被删除掉的记录都会组成一个所谓的 <strong>垃圾链表</strong> ，在这个链表中的记录占用的空间称之为所谓的 <strong>可重用空间</strong> ，之后如果有新记录插入到表中的话，可能把这些被删除的记录占用的存储空间覆盖掉。</p>
<p>将这个delete_mask位设置为1和将被删除的记录加入到垃圾链表中其实是两个阶段。</p>
<p><strong>min_rec_mask</strong></p>
<p>B+树的每层非叶子节点中的最小记录都会添加该标记。上方插入的四条记录的 min_rec_mask 值都是 0 ，意味着它们都不是 B+ 树的非叶子节点中的最小记录。</p>
<p><strong>n_owned</strong></p>
<p>当前组的最大记录，记录当前组有几个元素的字段。</p>
<p><strong>heap_no</strong></p>
<p>在数据页的User Records中插入的记录是一条一条紧凑的排列的，这种紧凑排列的结构又被称为<strong>堆</strong>。为了便于管理这个堆，把记录在堆中的相对位置给定一个编号——heap_no。所以heap_no这个属性表示当前记录在本页中的位置。</p>
<p>在例子中，插入的4条记录在本页中的位置分别是： 2 、3 、4 、5。为什么没有0和1呢？</p>
<p>是因为每个页里面加了两个记录，这两个记录并不是我们自己插入的，所以有时候也称为<strong>伪记录</strong>或者<strong>虚拟记录</strong>。这两个伪记录一个代表<strong>最小记录</strong> Infimum，一个代表**最大记录 **Supremum，对应的heap_no分别为0和1。</p>
<p>记录可以比较大小，对于一条完整的记录来说，比较记录的大小就是比较主键的大小。</p>
<p>不管我们向页中插入了多少记录，InnoDB 规定任何用户记录都要比最小记录大，比最大记录小。这两条记录的构造，都是由5字节大小的记录头信息和8字节大小的固定部分组成的，如图：</p>
<p><img src="https://github.com/chou401/pic-md/raw/master/image-20230703174800471.png" alt="image-20230703174800471" /></p>
<p>最大最小记录不是自己定义的记录，所以它们并不存放在页的User Records 部分，而是被单独放在一个称为Infimum + Supremum 的部分，如图所示：</p>
<p><img src="https://github.com/chou401/pic-md/raw/master/image-20230703174836315.png" alt="image-20230703174836315" /></p>
<p>从图中可以看出来，最小记录和最大记录的heap_no 值分别是0 和1 ，也就是说它们的位置也在Uesr Records前面。</p>
<p><strong>record_type</strong></p>
<p>这个属性表示当前记录的类型，一共有4种类型的记录， 0 表示普通用户记录， 1 表示B+树非叶节点记录， 2 表示最小记录， 3 表示最大记录。</p>
<p><strong>next_record</strong></p>
<p>这个属性非常重要！！它表示从当前记录的真实数据到下一条记录的真实数据的地址偏移量，可以理解为指向下一条记录地址的指针。值为正数说明下一条记录在当前记录后面，为负数说明下一条记录在当前记录的前面。比方说第1条记录的next_record 值为32 ，意味着从第1条记录的真实数据的地址处向后找32 个字节便是下一条记录的真实数据。这里的下一条记录指得并不是按照我们插入顺序的下一条记录，而是按照主键值由小到大的顺序的下一条记录。</p>
<p><img src="https://github.com/chou401/pic-md/raw/master/image-20230703175113161.png" alt="image-20230703175113161" /></p>
<p>从图中可以看出来，我们的记录按照主键从小到大的顺序形成了一个单链表。最大记录的next_record 的值为0 ，这也就是说最大记录是没有下一条记录了，它是这个单链表中的最后一个节点。</p>
<p>如果从中删除掉一条记录，这个链表也是会跟着变化的，比如我们把第2条记录删掉：</p>
<pre><code class="language-mysql">DELETE FROM page_demo WHERE c1 = 2;
</code></pre>
<p>删掉第2条记录后的示意图就是：</p>
<p><img src="https://github.com/chou401/pic-md/raw/master/image-20230703175303142.png" alt="image-20230703175303142" /></p>
<p>从图中可以看出来，删除第2条记录前后主要发生的变化：</p>
<ul>
<li>被删记录没有从存储空间中移除，而是把该记录的delete_mask 设置为1 ，next_record 变为0；</li>
<li>被删记录的前一条记录的next_record 指向后一条记录：第1条记录的next_record 指向了第3条记录；</li>
<li>最大记录的n_owned 值减1。</li>
</ul>
<p>所以，不论我们怎么对页中的记录做增删改操作，InnoDB始终会维护一条记录的单链表，链表中的各个节点是按照主键值由小到大的顺序连接起来的。并规定 Infimum记录（也就是最小记录） 的下一条记录就是本页中主键值最小的用户记录，而本页中主键值最大的用户记录的下一条记录就是 Supremum记录（也就是最大记录）。</p>
<p>而当我们再次插入第二条记录的时候 不会申请新的空间，而是直接连接被删的记录的next_record。</p>
<h5 id="默认隐藏列信息"><a class="header" href="#默认隐藏列信息">默认隐藏列信息</a></h5>
<p>MySQL 会为每个记录默认的添加一些列（也称为 隐藏列 ）</p>
<p><img src="https://github.com/chou401/pic-md/raw/master/e3ed90eaaf7747c49acfc2c59225a1d2.png" alt="img" /></p>
<p>实际上这几个列的真正名称其实是：DB_ROW_ID、DB_TRX_ID、DB_ROLL_PTR，我们为了美观才写成了row_id、transaction_id和roll_pointer。</p>
<p>row_id是可选的，表中没有主键的，则选取一个 Unique 键作为主键。如果表中连 Unique 键都没有定义的话，则 InnoDB 会为表默认添加一个名为row_id 的隐藏列作为主键。</p>
<p>roll_pointer 是一个指向记录对应的 undo日志 的一个指针。</p>
<p><img src="https://github.com/chou401/pic-md/raw/master/05aa65d74e8e4f1481eb7409fca14f96.png" alt="img" /></p>
<h5 id="行溢出的数据"><a class="header" href="#行溢出的数据">行溢出的数据</a></h5>
<p>我们知道对于 VARCHAR(M) 类型的列最多可以占用 65535 个字节。其中的 M 代表该类型最多存储的字符数量，如果我们使用 ascii 字符集的话，一个字符就代表一个字节。但是实际上，创建一张表并设置一个字段为<code>VARCHAR(65535)</code>则会报错。</p>
<pre><code class="language-mysql">CREATE TABLE varchar_size_demo(
    c VARCHAR(65535)
) CHARSET=ascii ROW_FORMAT=Compact;

ERROR 1118 (42000): Row size too large. The maximum row size for the used table type, not
counting BLOBs, is 65535. This includes storage overhead, check the manual. You have to c
hange some columns to TEXT or BLOBs
</code></pre>
<p>从报错信息里可以看出， MySQL 对一条记录占用的最大存储空间是有限制的，除了 BLOB 或者 TEXT 类型的列之外，其他所有的列（不包括隐藏列和记录头信息）占用的字节长度加起来不能超过 65535 个字节。所以 MySQL 服务器建议我们把存储类型改为 TEXT 或者 BLOB 的类型。这个 65535 个字节除了列本身的数据之外，还包括一些其他的数据（ storage overhead ），比如说我们为了存储一个 VARCHAR(M) 类型的列，其实需要占用3部分存储空间：</p>
<ul>
<li>真实数据</li>
<li>真实数据占用字节的长度</li>
<li>NULL 值标识，如果该列有 NOT NULL 属性则可以没有这部分存储空间</li>
</ul>
<p>如果该 VARCHAR 类型的列没有 NOT NULL 属性，那最多只能存储 65532 个字节的数据，因为真实数据的长度可能占用2个字节， NULL 值标识需要占用1个字节。</p>
<p>如果 VARCHAR 类型的列有 NOT NULL 属性，那最多只能存储 65533 个字节的数据，因为真实数据的长度可能占用2个字节，不需要 NULL 值标识。</p>
<p>相应的，如果不使用ascii字符集，而使用utf-8的话，则要按照3个字节一个字符来计算。</p>
<blockquote>
<p>另外，这里我们只讨论了一张表只有一个字段的情况，实际上是一行数据最多只能储存上面那些字节。</p>
</blockquote>
<h5 id="记录中的数据太多产生的溢出"><a class="header" href="#记录中的数据太多产生的溢出">记录中的数据太多产生的溢出</a></h5>
<p>我们知道，一页最大为16KB也就是16384字节，而一个varchar类型的列最多可以储存65532字节，这样就可能造成一张数据页放不了一行数据的情况。</p>
<p>在 Compact 和 Reduntant 行格式中，对于占用存储空间非常大的列，在记录的真实数据处只会存储该列的一部分数据，把剩余的数据分散存储在几个其他的页中，然后 记录的真实数据 处用20个字节存储指向这些页的地址（当然这20个字节中还包括这些分散在其他页面中的数据的占用的字节数），从而可以找到剩余数据所在的页。</p>
<p>对于 Compact 和 Reduntant 行格式来说，如果某一列中的数据非常多的话，在本记录的真实数据处只会存储该列的前 768 个字节的数据和一个指向其他页的地址，然后把剩下的数据存放到其他页中，这个过程也叫做 行溢出 ，存储超出 768 字节的那些页面也被称为 溢出页 。</p>
<p><img src="https://github.com/chou401/pic-md/raw/master/285d9c00300a45af94c31b74e5a9df19.png" alt="img" /></p>
<h5 id="行溢出的临界点"><a class="header" href="#行溢出的临界点">行溢出的临界点</a></h5>
<p>首先，MySQL 中规定一个页中至少存放两行记录。其次，以创建只有一个varchar(65532) 字段的表为例，的我们分析一下 一个页面的空间是如何利用的：</p>
<ul>
<li>除了用户储存的真实信息外，储存文件头、文件尾、页面头等信息，需要136个字节。</li>
<li>每条记录需要的额外信息是27字节，这27字节包括：
<ul>
<li>2个字节用于存储真实数据的长度</li>
<li>1个字节用于存储列是否是NULL值</li>
<li>5个字节大小的头信息</li>
<li>6个字节的 row_id 列</li>
<li>6个字节的 transaction_id 列</li>
<li>7个字节的 roll_pointer 列</li>
</ul>
</li>
</ul>
<p>假设一个列中存储的数据字节数为n，那么发生行溢出现象时需要满足这个式子：136 + 2×(27 + n) &gt; 16384。</p>
<p>求解这个式子得出的解是： n &gt; 8098 。也就是说如果一个列中存储的数据不大于 8098 个字节，那就不会发生行溢出 ，否则就会发生 行溢出 。</p>
<p>不过这个 8098 个字节的结论只是针对只有一个<code>varchar(65532) </code>列的表来说的，如果表中有多个列，那上边的式子和结论都需要改一改了，所以重点就是: 不用关注这个临界点是什么，只要知道如果我们想一个行中存储了很大的数据时，可能发生 行溢出 的现象。</p>
<h4 id="redundant-格式"><a class="header" href="#redundant-格式">redundant 格式</a></h4>
<p>与compact 格式相比，没有了变长字段列表以及 NULL值列表，取而代之的是记录了所有真实数据的偏移地址表，偏移地址表是倒序排放的，但是计算偏移量却还是正序开始的从row_id作为第一个， 第一个从0开始累加字段对应的字节数。在记录头信息中, 大部分字段和compact 中的相同，但是对比compact多了。</p>
<p>n_field(记录列的数量)、1byte_offs_flag(字段长度列表每一列占用的字节数)，少了record_type字段。</p>
<p>因为redundant是mysql 5.0 以前就在使用的一种格式，已经非常古老，使用频率非常的低，这里就不过多表述。</p>
<h4 id="dynamic-格式"><a class="header" href="#dynamic-格式">dynamic 格式</a></h4>
<p>在现在 mysql 5.7 的版本中，使用的格式就是 dynamic。</p>
<p>dynamic 和 compact 基本是相同的，只有在溢出页的处理上面，有所不同。</p>
<p>在compact行格式中，对于占用存储空间非常大的列，在记录的真实数据处只会存储该列的前768个字节的数据，把剩余的数据分散存储在几个其他的页中，然后记录的真实数据处用20个字节存储指向这些页的地址，从而可以找到剩余数据所在的页。</p>
<p>这种在本记录的真实数据处只会存储该列的前768个字节的数据和一个指向其他页的地址，然后把剩下的数据存放到其他页中的情况就叫做行溢出，存储超出768字节的那些页面也被称为溢出页（uncompresse blob page）。</p>
<p>dynamic中会直接在真实数据区记录 20字节 的溢出页地址，而不再去额外记录一部分的数据了。</p>
<h4 id="compressed-格式"><a class="header" href="#compressed-格式">compressed 格式</a></h4>
<p>compressed 格式将会在Dynamic 的基础上面进行压缩处理特别是对溢出页的压缩处理，存储在其中的行数据会以zlib的算法进行压缩，因此对于blob、text这类大长度类型的数据能够进行非常有效的存储。但compressed格式其实也是以时间换空间，性能并不友好，并不推荐在常见的业务中使用。</p>
<h3 id="page-directory页目录"><a class="header" href="#page-directory页目录">Page Directory（页目录）</a></h3>
<p>记录在页中按照主键值由小到大顺序串联成一个单链表，那如果我们想根据主键值查找页中的某条记录该咋办呢？比如说这样的查询语句：</p>
<pre><code class="language-mysql">SELECT * FROM page_demo WHERE c1 = 3;
</code></pre>
<p>可以采用遍历链表的方式，从Infimum 记录（最小记录）开始，向后查找，因为是按照主键值从小到大存放的，当找到或找到大于查找的主键值的时候，就结束了。但这种方法效率太低了。</p>
<p>为了解决直接遍历查询缓慢的问题，设计了类似于课本目录的<strong>页目录</strong>：</p>
<ul>
<li><strong>记录分组</strong>：将所有正常的记录（包括最大和最小记录，不包括标记为已删除的记录）划分为几个组。</li>
<li><strong>组内最大记录的n_owned 属性记录记录条数</strong>：每个组的最后一条记录（也就是组内最大的那条记录）的头信息中的n_owned 属性表示该记录拥有多少条记录，也就是该组内共有几条记录。</li>
<li><strong>根据最大最小记录的地址偏移量构造页目录</strong>：将每个组的最后一条记录的地址偏移量单独提取出来按顺序存储到靠近页的尾部的地方，这个地方就是所谓的Page Directory ，也就是页目录（此时应该返回头看看页面各个部分的图）。页面目录中的这些地址偏移量被称为槽（英文名： Slot ），所以这个页面目录就是由槽组的。</li>
</ul>
<p><img src="https://github.com/chou401/pic-md/raw/master/image-20230703181623066.png" alt="image-20230703181623066" /></p>
<p>页目录里面有两个槽，说明分为了两个组，分别是最小记录为一组，四条用户记录与最大记录为一组。所以<strong>最小记录的n_owned 属性为1，最大记录的n_owned 属性为5。</strong></p>
<p>对于分组规定的规则：</p>
<ul>
<li>对于最小记录所在的分组只能有 1 条记录，最大记录所在的分组拥有的记录条数只能在 1~8 条之间，剩下的分组中记录的条数范围只能在是 4~8 条之间。</li>
<li>初始情况下一个数据页里只有最小记录和最大记录两条记录，它们分属于两个分组。</li>
<li>之后每插入一条记录，都会从页目录中找到主键值比本记录的主键值大并且差值最小的槽，然后把该槽中对应的最大记录的n_owned 值加1，表示本组内又添加了一条记录，直到该组中的记录数等于8个。</li>
<li>在一个组中的记录数等于8个后再插入一条记录时，会将组中的记录拆分成两个组，一个组中4条记录，另一个5条记录。这个过程会在页目录中新增一个槽来记录这个新增分组中最大的那条记录的偏移量。</li>
</ul>
<p>往表里继续插入数据</p>
<pre><code class="language-mysql">INSERT INTO page_demo VALUES(5, 500, 'eeee'), (6, 600, 'ffff'), (7, 700, 'gggg'),(8, 800, 'hhhh'), (9, 900, 'iiii'), (10, 1000, 'jjjj'), (11, 1100, 'kkkk'), (12, 1200, 'llll'), (13, 1300, 'mmmm'), (14, 1400, 'nnnn'), (15, 1500, 'oooo'), (16, 1600, 'pppp');
</code></pre>
<p>注意看，最小记录始终是在用户最小记录之前，最大记录始终是在用户最大记录之后。</p>
<p><img src="https://github.com/chou401/pic-md/raw/master/image-20230703181828283.png" alt="image-20230703181828283" /></p>
<p>可以看到，每个槽点都记录了每组中最大记录的地址偏移量。</p>
<p>当我们需要在一个数据页中查找指定主键值的记录的过程分为两步：</p>
<ul>
<li>通过<strong>二分法</strong>确定该记录所在的槽，并找到该槽中主键值最小的那条记录。</li>
<li>通过记录的next_record 属性遍历该槽所在的组中的各个记录。</li>
</ul>
<h3 id="page-header页面头部"><a class="header" href="#page-header页面头部">Page Header（页面头部）</a></h3>
<p>为了能得到一个数据页中存储的记录的状态信息，比如本页中已经存储了多少条记录，第一条记录的地址是什么，页目录中存储了多少个槽等等，特意在页中定义了一个叫Page Header 的部分，它是页结构的第二部分，这个部分占用固定的56 个字节，专门存储各种状态信息，具体各个字节都是干嘛的看下表：</p>
<div class="table-wrapper"><table><thead><tr><th>名称</th><th>占用空间（字节）</th><th>描述</th></tr></thead><tbody>
<tr><td>PAGE_N_DIR_SLOTS</td><td>2</td><td>在页目录中的槽数量</td></tr>
<tr><td>PAGE_HEAP_TOP</td><td>2</td><td>还未使用的空间最小地址，也就是说从该地址之后就是Free Space</td></tr>
<tr><td>PAGE_BTR_SEG_TOP</td><td>10</td><td>本页中的记录的数量（包括最小和最大记录以及标记为删除的记录）</td></tr>
<tr><td>PAGE_N_HEAP</td><td>2</td><td>第一个已经标记为删除的记录地址（各个已删除的记录通过next_record 也会组成一个单链表，单链表中的记录可以被重新利用）</td></tr>
<tr><td>PAGE_FREE</td><td>2</td><td>已删除记录占用的字节数</td></tr>
<tr><td>PAGE_GARBAGE</td><td>2</td><td>最后插入记录的位置</td></tr>
<tr><td>PAGE_LAST_INSERT</td><td>2</td><td>记录插入的方向</td></tr>
<tr><td>PAGE_DIRECTION</td><td>2</td><td>一个方向连续插入的记录数量</td></tr>
<tr><td>PAGE_N_DIRECTION</td><td>2</td><td>该页中记录的数量（不包括最小和最大记录以及被标记为删除的记录）</td></tr>
<tr><td>PAGE_N_RECS</td><td>2</td><td>修改当前页的最大事务ID，该值仅在二级索引中定义</td></tr>
<tr><td>PAGE_MAX_TRX_ID</td><td>8</td><td>当前页在B+树中所处的层级</td></tr>
<tr><td>PAGE_LEVEL</td><td>2</td><td>索引ID，表示当前页属于哪个索引</td></tr>
<tr><td>PAGE_INDEX_ID</td><td>8</td><td>B+树叶子段的头部信息，仅在B+树的Root页定义</td></tr>
<tr><td>PAGE_BTR_SEG_LEAF</td><td>10</td><td>B+树非叶子段的头部信息，仅在B+树的Root页定义</td></tr>
</tbody></table>
</div>
<ul>
<li>
<p>PAGE_DIRECTION</p>
<ul>
<li>假如新插入的一条记录的主键值比上一条记录的主键值大，我们说这条记录的插入方向是右边，反之则是左边。用来表示最后一条记录插入方向的状态就是PAGE_DIRECTION 。</li>
</ul>
</li>
<li>
<p>PAGE_N_DIRECTION</p>
<ul>
<li>假设连续几次插入新记录的方向都是一致的， InnoDB 会把沿着同一个方向插入记录的条数记下来，这个条数就用PAGE_N_DIRECTION 这个状态表示。当然，如果最后一条记录的插入方向改变了的话，这个状态的值会被清零重新统计。</li>
</ul>
</li>
</ul>
<h3 id="file-header文件头部"><a class="header" href="#file-header文件头部">File Header（文件头部）</a></h3>
<p>Page Header 是专门针对数据页记录的各种状态信息，比方说页里头有多少个记录，有多少个槽等信息。</p>
<p>而File Header 是针对各种类型的页都通用，也就是说不同类型的页都会以File Header 作为第一个组成部分，它描述了一些针对各种页都通用的一些信息，比方说这个页的编号是多少，它的上一个页、下一个页是谁， 这个部分占用固定的38 个字节，是由下边这些内容组成的：</p>
<div class="table-wrapper"><table><thead><tr><th>名称</th><th>占用空间（字节）</th><th>描述</th></tr></thead><tbody>
<tr><td>FIL_PAGE_SPACE_OR_CHKSUM</td><td>4</td><td>页的校验和（checksum值）</td></tr>
<tr><td>FIL_PAGE_OFFSET</td><td>4</td><td>页号</td></tr>
<tr><td>FIL_PAGE_PREV</td><td>4</td><td>上一个页的页号</td></tr>
<tr><td>FIL_PAGE_NEXT</td><td>4</td><td>下一个页的页号</td></tr>
<tr><td>FIL_PAGE_LSN</td><td>8</td><td>页面被最后修改时对应的日志序列位置（英文名是：Log SequenceNumber）</td></tr>
<tr><td>FIL_PAGE_TYPE</td><td>2</td><td>该页的类型</td></tr>
<tr><td>FIL_PAGE_FILE_FLUSH_LSN</td><td>8</td><td>仅在系统表空间的一个页中定义，代表文件至少被刷新到了对应的LSN值</td></tr>
<tr><td>FIL_PAGE_ARCH_LOG_NO_OR_SPACE_ID</td><td>4</td><td>页属于哪个表空间</td></tr>
</tbody></table>
</div>
<p>看几个重要的部分：</p>
<ul>
<li>
<p>FIL_PAGE_SPACE_OR_CHKSUM</p>
<p>这个代表当前页面的校验和（checksum）。校验和：就是对于一个很长很长的字节串来说，通过某种算法来计算一个比较短的值来代表这个很长的字节串，这个比较短的值就称为校验和。这样在比较两个很长的字节串之前先比较这两个长字节串的校验和，如果校验和都不一样两个长字节串肯定是不同的，所以省去了直接比较两个比较长的字节串的时间损耗。</p>
</li>
<li>
<p>FIL_PAGE_OFFSET</p>
<p>每一个页都有一个单独的页号，就跟你的身份证号码一样， InnoDB 通过页号来可以唯一定位一个页。</p>
</li>
<li>
<p>FIL_PAGE_TYPE</p>
<p>InnoDB 为了不同的目的而把页分为不同的类型，这篇文章介绍的其实都是存储记录的<strong>数据页</strong>，也就是所谓的索引页。其实还有很多别的类型的页：日志页、溢出页等。</p>
</li>
<li>
<p>FIL_PAGE_PREV 和FIL_PAGE_NEXT</p>
<p>InnoDB 都是以页为单位存放数据的，存放某种类型的数据占用的空间非常大（比方说一张表中可以有成千上万条记录）， InnoDB 可能不可以一次性为这么多数据分配一个非常大的存储空间，如果分散到多个不连续的页中存储的话需要把这些页关联起来， FIL_PAGE_PREV 和FIL_PAGE_NEXT就分别代表本页的上一个和下一个页的页号。这样通过建立一个双向链表把许许多多的页就都串联起来了，而无需这些页在物理上真正连着。</p>
</li>
</ul>
<p>需要注意的是，并不是所有类型的页都有上一个和下一个页的属性，不过本文中唠叨的数据页（也就是类型为FIL_PAGE_INDEX 的页）是有这两个属性的，所以索引的数据页其实是一个双链表。</p>
<h3 id="file-trailer文件尾部"><a class="header" href="#file-trailer文件尾部">File Trailer（文件尾部）</a></h3>
<p>InnoDB 存储引擎会把数据存储到磁盘上，但是磁盘速度太慢，需要以页为单位把数据加载到内存中处理，如果该页中的数据在内存中被修改了，那么在修改后的某个时间需要把数据同步到磁盘中。但是在同步了一半的时候中断电了咋办，这不是莫名尴尬么？为了检测一个页是否完整（也就是在同步的时候有没有发生只同步一半的尴尬情况），在每个页的尾部都加了一个File Trailer 部分，这个部分由8 个字节组成，可以分成2个小部分：</p>
<ul>
<li>
<p>前4个字节代表页的校验和</p>
<p>这个部分是和File Header 中的校验和相对应的。每当一个页面在内存中修改了，在同步之前就要把它的校验和算出来，因为File Header 在页面的前边，所以校验和会被首先同步到磁盘，当完全写完时，校验和也会被写到页的尾部，如果完全同步成功，则页的首部和尾部的校验和应该是一致的。如果写了一半儿断电了，那么在File Header 中的校验和就代表着已经修改过的页，而在File Trialer 中的校验和代表着原先的页，二者不同则意味着同步中间出了错。</p>
</li>
<li>
<p>后4个字节代表页面被最后修改时对应的日志序列位置（LSN）</p>
<p>这个部分也是为了校验页的完整性的，只不过我们目前还没说LSN 是个什么意思，所以大家可以先不用管这个属性。这个File Trailer 与File Header 类似，都是所有类型的页通用的。</p>
</li>
</ul>
<h3 id="innodb-的-buffer-pool-是如何管理数据页的"><a class="header" href="#innodb-的-buffer-pool-是如何管理数据页的">InnoDB 的 Buffer Pool 是如何管理数据页的</a></h3>
<p>对于 InnoDB 存储引擎来说，数据是存储在磁盘上，而执行引擎想要操作数据，必须先将磁盘的数据加载到内存中才能操作。当数据从磁盘中取出后，缓存内存中，下次查询同样的数据的时候，直接从内存中读取，这样大大提高了查询性能。</p>
<h4 id="innodb结构图"><a class="header" href="#innodb结构图">InnoDB结构图</a></h4>
<p><img src="https://cdn.jsdelivr.net/gh/chou401/pic-md@master/innodb-architecture-5-7.png" alt="InnoDB architecture diagram showing in-memory and on-disk structures." /></p>
<p>内存结构(In-Memory Structures)主要是针对的是数据及其操作，主要分为：</p>
<ul>
<li><strong>Buffer Pool： 缓冲池</strong>，数据缓冲池里面不直接存放数据而是存放的Page页，将数据存放在了Page页中，在缓冲池Page页是通过链表形式来存放的。</li>
<li><strong>Change Buffer：写缓冲区</strong>，正常情况下修改数据是先修改的缓冲池中Page的数据，但是缓冲池肯定不是所有的数据，而修改数据没有对应的Page数据的时候并不会直接把数据加载到缓冲池中去，而是放在了写缓冲区中记录，等到数据被读取的时候再把数据合并到缓冲池中。</li>
<li><strong>Adaptive Hash Index： 自适应Hash索引</strong>，InnoDB存储引擎会根据Page页的访问频率和模式建立对应的Hash索引，这个索引是根据查询情况自动建立的，称为自适应Hash索引。</li>
<li><strong>Log Buffer： 日志缓冲区</strong>，主要用来保存写入磁盘的(Redo/Undo)日志文件，日志缓冲区会定期刷新到磁盘log文件中，这样不用每次日志都进行磁盘IO操作，提高效率。</li>
</ul>
<p>磁盘结构(On-Disk Structures)主要针对的是表和表空间，主要分为以下结构：</p>
<ul>
<li><strong>Tablespaces： 表空间</strong>，对于表空间大家应该都不陌生，用来存储表结构和数据的。表空间又被分为系统表空间、独立表空间、通用表空间、临时表空间等多种类型。</li>
<li><strong>InnoDB Data Dictionary： 数据字典</strong>，InnoDB数据字典由内部系统表组成，这些表包含用于查找表、索引和表字段等对象的元数据。</li>
<li><strong>Doublewrite Buffer： 双写缓冲区</strong>，我们知道数据修改先修改的Page页后又刷到磁盘的，在刷到磁盘前这些数据会先存放在双写缓存区中，双写缓存区是用来保障数据写入磁盘时候出现问题的备份。</li>
<li><strong>Redo Logs： 重做日志</strong>，记录了所有缓冲池修改的数据，修改数据的时候先写日志，后修改的缓冲区，假设修改写入操作的时候数据库崩溃了或停电了，等下次启动通过重做日志来保持数据的正确性。</li>
</ul>
<h4 id="buffer-pool缓冲池"><a class="header" href="#buffer-pool缓冲池">Buffer Pool(缓冲池)</a></h4>
<p><strong>Buffer Pool是MySQL服务在启动的时候向操作系统申请的一片连续地址的内存空间</strong>，其本质就是一片内存，默认大小是 <strong>128M</strong>，可以在启动服务的时候，通过 innodb_buffer_pool 这个参数设置buffer pool的大小，单位是字节(B)，最小值是5MB。</p>
<p>那么Buffer Pool这段内存地址到底有什么，可以确定的就是肯定有16KB数据页，这里叫<strong>缓冲页</strong>。除此之外还有，索引页，undo 页，插入缓存、自适应哈希索引、锁信息。</p>
<p><img src="https://cdn.jsdelivr.net/gh/chou401/pic-md@master/image-20230904181941928.png" alt="image-20230904181941928" /></p>
<h5 id="内部组成"><a class="header" href="#内部组成">内部组成</a></h5>
<p>因为buffer pool被划分为某干个数据页，其数据页大小和表空间使用的页大小一致，为了更好的管理buffer pool中的缓冲页，innoDB为每个缓冲页都创建了一个控制信息。</p>
<p>这些控制信息主要包括该缓冲页的【表空间编号、页号、缓冲页在buffer pool中的地址、链表节点信息】，存储这些控制信息控制块。</p>
<p>缓冲页和控制块是一一对应的，其中控制块在buffer pool前面，而缓冲页在buffer后面。</p>
<p><strong>什么是碎片？</strong></p>
<p>当剩余空间不够一对控制块和缓冲页的大小时，这样的空间称为碎片。</p>
<p><strong>怎么查看MySQL实例的Buffer Pool信息呢？</strong></p>
<p><code>show variables like '%innodb_buffer_pool_size%';</code> 查看buffer pool的size。</p>
<p><code>show global status like '%innodb_buffer_pool%';</code> 查看相关参数，详细的参数代表的意思，大家自己去搜搜。</p>
<h4 id="管理buffer-pool"><a class="header" href="#管理buffer-pool">管理Buffer Pool</a></h4>
<p><code>Buffer Pool</code> 中的页有三种状态：</p>
<ol>
<li>空闲页：通过空闲页链表（Free List）管理。</li>
<li>正常页：通过LRU链表（LRU List）管理。</li>
<li>脏页：通过LRU链表和脏页链表（Flush List）管理。（缓冲池中被修改过的页，与磁盘上的数据页不一致）</li>
</ol>
<p>接下来我们分别看看三种链表是如何进行管理的。</p>
<h5 id="free链表"><a class="header" href="#free链表">Free链表</a></h5>
<p>初始化完的buffer pool时所有的页都是空闲页，所有空闲的缓冲页对应的<strong>控制块信息</strong>作为一个节点放到Free链表中。</p>
<p>要注意Free链表是一个个控制块，而控制块的信息中有缓存页的地址信息。</p>
<p>在有了free链表之后，当需要加载磁盘中的页到buffer pool中时，就去free链表中取一个空闲页所对应的控制块信息，<strong>根据控制块信息中的表空间号、页号找到buffer pool里对应的缓冲页，再将数据加载到该缓冲页中，随后删掉free链表该控制块信息对应的节点。</strong></p>
<p><strong>如何在buffer pool中快速查找缓冲页（数据页）呢？</strong></p>
<p>这里就可以对缓冲页进行Hash处理，用表空间号、页号做为Key，缓冲页的控制块就是value**维护一个Hash表，**根据表空间号、页号做为Key去查找有没有对应的缓冲信息，如果没有就需要去free 链表中取一个空闲的缓冲页控制快信息，随后将磁盘中的数据加载到该缓冲页位置。</p>
<h5 id="flush链表"><a class="header" href="#flush链表">Flush链表</a></h5>
<p>修改了buffer pool中缓冲页的数据，那么该页和磁盘就不一致了，这样的页就称为【脏页】，它不是立马刷入到磁盘中，而是由后台线程将脏页写入到磁盘。</p>
<p>Flush链表就是为了能知道哪些是脏页而设计的，它跟Free链表结构图相似，区别在于控制块指向的是脏页地址。</p>
<h5 id="lru链表"><a class="header" href="#lru链表">LRU链表</a></h5>
<p>对于频繁访问的数据和很少访问的数据我们对与它的期望是不一样的，很少访问的数据希望在某个时机淘汰掉，避免占用buffer pool的空间，因为缓冲空间大小是有限的。</p>
<p>MySQL设计了根据LRU算法设计了LRU链表来维护和淘汰缓冲页。</p>
<p>LRU 算法简单来说，如果用链表来实现，将最近命中（加载）的数据页移在头部，未使用的向后偏移，直至移除链表。这样的淘汰算法就叫做 LRU 算法，但是简单的LRU算法会带来两个问题：<strong>预读失效、Buffer Pool污染</strong>。</p>
<h5 id="预读机制和预读失效"><a class="header" href="#预读机制和预读失效">预读机制和预读失效</a></h5>
<p><strong>预读机制</strong>：当数据页从磁盘加载到 Buffer Pool 中时，会把相邻的数据页也提前加载到 Buffer Pool 中，这样做的好处就是减少未来可能的磁盘IO。</p>
<p><strong>预读失效</strong>：当预读机制提前加载的数据页一直未被访问，这就是失效</p>
<p>好，那么结合简单的LRU算法来看，可能预读页被加载到LRU链表头部，当Buffer Pool空间不够时，会把经常访问的位于LRU链表的尾部数据页给淘汰清理掉，这样缓冲就失效了。</p>
<h5 id="改进的lru-算法"><a class="header" href="#改进的lru-算法">改进的LRU 算法</a></h5>
<p>Buffer Pool的LRU算法中InnoDB 将LRU链表按照5:3的比例分成了young区域和old区域。链表头部的5/8是young区（被高频访问数据），链表尾部的3/8区域是old区域（低频访问数据）。</p>
<p>这样做的目的是，在预读的时候或访问不存在的缓冲页时，先加入到 old 区域的头部，当页被真正访问的时候，才将页插入 young 区域的头部。</p>
<p><img src="https://cdn.jsdelivr.net/gh/chou401/pic-md@master/v2-7ba7ee9eb267c9d62e95c3e858419e32_1440w.png" alt="img" /></p>
<p>现在有个编号为 20 的页被预读了，这个页只会被插入到 old 区域头部，而 old 区域末尾的页（10号）会被淘汰掉。</p>
<p><img src="https://cdn.jsdelivr.net/gh/chou401/pic-md@master/v2-b381ae4b18804701b12cad3b770167b2_1440w.png" alt="img" /></p>
<p>如果 20 号页一直不会被访问，它也没有占用到 young 区域的位置，而且还会比 young 区域的数据更早被淘汰出去。</p>
<p>如果 20 号页被预读后，立刻被访问了，那么就会将它插入到 young 区域的头部，young 区域末尾的页（7号），会被挤到 old 区域，作为 old 区域的头部，这个过程并不会有页被淘汰。</p>
<p><img src="https://cdn.jsdelivr.net/gh/chou401/pic-md@master/v2-73eeea4b1a6b0e6f0553b3ef07e36e4a_1440w.png" alt="img" /></p>
<h5 id="多buffer实例"><a class="header" href="#多buffer实例">多Buffer实例</a></h5>
<p>我们已经默认情况下**innodb_buffer_pool_size是128M， **此时的innodb_buffer_pool_instances的大小也就是实例是1个。因为innodb_buffer_pool_size 小于1G时，设置innodb_buffer_pool_instances是无效的，都会是1。</p>
<p>当一个buffer pool在多线程访问的时候，各个链表都会加锁处理，这样一来，多线程访问时，性能就会降低。</p>
<p>可以通过<strong>innodb_buffer_pool_instances</strong>参数来设置实例的个数。每个buffer pool实例的大小计算公式：**innodb_buffer_pool_size / innodb_buffer_pool_instances，**每个实例都有其对应的链表管理，互不干扰。</p>
<h5 id="修改buffer-pool大小"><a class="header" href="#修改buffer-pool大小">修改Buffer Pool大小</a></h5>
<p><strong>如何修改运行中MySQL的Buffer Pool的大小？</strong></p>
<p><strong>MySQL 5.7.5之前</strong>：是不允许在运行时调整buffer pool大小的，只能在服务器启动之前，通过innodb_buffer_pool_size大小来调整。</p>
<p>**MySQL 5.7.5之后：**是以chunk为单位来修改Buffer Pool的大小，比如innodb_buffer_pool_chunk_size默认大小是128M，调整Buffer Pool大小就以chunk为单位来增加或减少Buffer Pool大小。</p>
<p>我们应该要有这么一个概念就是：一个Buffer Pool可能有多个buffer pool实例，而每个实例由多个chunk组成，一个chunk是一块连续的内存空间，一个chunk默认大小是128M。</p>
<h5 id="缓存污染"><a class="header" href="#缓存污染">缓存污染</a></h5>
<p>虽然 MySQL 通过改进传统的 LRU 数据结构，避免了预读失效带来的影响。但是如果还是使用「只要数据被访问过一次，就将数据加入到 young 区域」这种方式的话，那么<strong>还存在缓存污染的问题</strong>。</p>
<p>当我们在批量读取数据的时候，由于数据被访问了一次，这些大量数据都会被加入到「活跃 LRU 链表」里，然后之前缓存在活跃 LRU 链表（或者 young 区域）里的热点数据全部都被淘汰了，<strong>如果这些大量的数据在很长一段时间都不会被访问的话，那么整个活跃 LRU 链表（或者 young 区域）就被污染了</strong>。</p>
<h5 id="缓存污染会带来什么问题"><a class="header" href="#缓存污染会带来什么问题">缓存污染会带来什么问题？</a></h5>
<p>缓存污染带来的影响就是很致命的，等这些热数据又被再次访问的时候，由于缓存未命中，就会产生大量的磁盘 I/O，系统性能就会急剧下降。</p>
<p>当某一个 SQL 语句<strong>扫描了大量的数据</strong>时，在 Buffer Pool 空间比较有限的情况下，可能会将 <strong>Buffer Pool 里的所有页都替换出去，导致大量热数据被淘汰了</strong>，等这些热数据又被再次访问的时候，由于缓存未命中，就会产生大量的磁盘 I/O，MySQL 性能就会急剧下降。</p>
<p>注意， 缓存污染并不只是查询语句查询出了大量的数据才出现的问题，即使查询出来的结果集很小，也会造成缓存污染。</p>
<p>比如，在一个数据量非常大的表，执行了这条语句：</p>
<pre><code class="language-text">select * from t_user where name like &quot;%xiaolin%&quot;;
</code></pre>
<p>可能这个查询出来的结果就几条记录，但是由于这条语句会发生索引失效，所以这个查询过程是全表扫描的，接着会发生如下的过程：</p>
<ul>
<li>从磁盘读到的页加入到 LRU 链表的 old 区域头部；</li>
<li>当从页里读取行记录时，也就是<strong>页被访问的时候，就要将该页放到 young 区域头部</strong>；</li>
<li>接下来拿行记录的 name 字段和字符串 xiaolin 进行模糊匹配，如果符合条件，就加入到结果集里；</li>
<li>如此往复，直到扫描完表中的所有记录。</li>
</ul>
<p>经过这一番折腾，由于这条 SQL 语句访问的页非常多，每访问一个页，都会将其加入 young 区域头部，那么<strong>原本 young 区域的热点数据都会被替换掉，导致缓存命中率下降</strong>。那些在批量扫描时，而被加入到 young 区域的页，如果在很长一段时间都不会再被访问的话，那么就污染了 young 区域。</p>
<p>举个例子，假设需要批量扫描：21，22，23，24，25 这五个页，这些页都会被逐一访问（读取页里的记录）。</p>
<p><img src="https://cdn.jsdelivr.net/gh/chou401/pic-md@master/v2-ce159c31ecabe38c68bb35cfce35e410_1440w.png" alt="img" /></p>
<p>在批量访问这些页的时候，会被逐一插入到 young 区域头部。</p>
<p><img src="https://cdn.jsdelivr.net/gh/chou401/pic-md@master/v2-1c75fa046988f1a9774fb258d73cba6f_1440w.png" alt="img" /></p>
<p>可以看到，原本在 young 区域的 6 和 7 号页都被淘汰了，而批量扫描的页基本占满了 young 区域，如果这些页在很长一段时间都不会被访问，那么就对 young 区域造成了污染。</p>
<p>如果 6 和 7 号页是热点数据，那么在被淘汰后，后续有 SQL 再次读取 6 和 7 号页时，由于缓存未命中，就要从磁盘中读取了，降低了 MySQL 的性能，这就是缓存污染带来的影响。</p>
<h5 id="怎么避免缓存污染造成的影响"><a class="header" href="#怎么避免缓存污染造成的影响">怎么避免缓存污染造成的影响？</a></h5>
<p>前面的 LRU 算法只要数据被访问一次，就将数据加入活跃 LRU 链表（或者 young 区域），<strong>这种 LRU 算法进入活跃 LRU 链表的门槛太低了</strong>！正式因为门槛太低，才导致在发生缓存污染的时候，很容就将原本在活跃 LRU 链表里的热点数据淘汰了。</p>
<p>所以，<strong>只要我们提高进入到活跃 LRU 链表（或者 young 区域）的门槛，就能有效地保证活跃 LRU 链表（或者 young 区域）里的热点数据不会被轻易替换掉</strong>。</p>
<p>Linux 操作系统和 MySQL Innodb 存储引擎分别是这样提高门槛的：</p>
<ul>
<li>
<p><strong>Linux 操作系统</strong>：在内存页被访问<strong>第二次</strong>的时候，才将页从 inactive list 升级到 active list 里。</p>
</li>
<li>
<p><strong>MySQL Innodb</strong>：在内存页被访问<strong>第二次</strong>的时候，并不会马上将该页从 old 区域升级到 young 区域，因为还要进行<strong>停留在 old 区域的时间判断</strong>：</p>
</li>
<li>
<ul>
<li>如果第二次的访问时间与第一次访问的时间<strong>在 1 秒内</strong>（默认值），那么该页就<strong>不会</strong>被从 old 区域升级到 young 区域；</li>
<li>如果第二次的访问时间与第一次访问的时间<strong>超过 1 秒</strong>，那么该页就<strong>会</strong>从 old 区域升级到 young 区域；</li>
</ul>
</li>
</ul>
<p>提高了进入活跃 LRU 链表（或者 young 区域）的门槛后，就很好了避免缓存污染带来的影响。</p>
<p>在批量读取数据时候，<strong>如果这些大量数据只会被访问一次，那么它们就不会进入到活跃 LRU 链表（或者 young 区域）</strong>，也就不会把热点数据淘汰，只会待在非活跃 LRU 链表（或者 old 区域）中，后续很快也会被淘汰。</p>
<h2 id="疑问"><a class="header" href="#疑问">疑问</a></h2>
<h3 id="小数精度问题"><a class="header" href="#小数精度问题">小数精度问题</a></h3>
<p>fload和double在存取时因为精度不一致会发生丢失，这里的丢失指的是扩展或者截断，丢失了原有的精度。</p>
<p>在mysql中，我们用【小数数据类型（总长度，小数点长度）】来表示小数的总长度和小数点后面的长度，如deicmal(m，n)。n就是小数点后面的数字个数。float(m,n)、double(m,n) 含义差不多，都是定义长度和精度的。既然定义了精度，为什么还会发生所谓的精度丢失问题呢？</p>
<p>float和double在<strong>存取</strong>时因为精度不一致会发生丢失，不能盲目的说float和double精度可能丢失。具体原因如下：</p>
<ol>
<li><strong>没有设置精度位数。</strong>
没有设置精度就是使用默认的精度，此时的策略就是，尽可能保证精度，因此一般使用最高精度存储数据。如果设置数据类型指定了精度，那么存储数据时就按照设置的精度来存储。例如，6.214522存入6位小数的float和double是不会丢失小数精度的，取出来的数还是6.214522。也就是说，一个小数存入相同的精度的数据类型时，精度是不会丢失的。</li>
<li><strong>设置的精度和存储时的精度不一致。</strong>
当7或更多位精度的数字存入6位精度类型字段时，会发生什么？结果会发生四舍五入。四舍五入的结果就是匹配字段的数据类型的精度长度。此时精度也会丢失。不管内部如何处理，我们得到的数据是经过四舍五入的。但是有一点可以确定，我们在读取取舍后的数字时，是固定的。虽然浮点数存储的不是确切的数值，但是在你指定的精度长度条件下，存取都是确定的一个数值。而发生精度变化的就是数值的精度和字段的精度长度不匹配，从而发生数值扩展精度和截断精度问题，这也就是浮点数精度不准确的问题。</li>
<li><strong>mysql数据库使用其他数据库引擎来查询。</strong>
这个精度丢失的原因，就可能是不同的数据库引擎对浮点数的精度扩展和截断处理策略不一致，而且，存储时策略也不一致。所以导致精度会出现各种变化。这种问题也就是催生decimal类型的出现。我们前面看到的decimal是可以确切存储小数的精度的。因为在存储的时候会将小数以字符串存储，就不会再发生精度的扩展问题。但是decimal依然会发生精度截断问题。如果decimal指定精度为2位小数，存入的是这样的值：12.123，你觉得结果如何？当然还是会发生四舍五入。结果就是12.12，然而12.12以字符串形式存入了数据库，此后，12.12始终都是12.12，变现出来的是小数，然而内部是字符串形式存储，所以，小数精度不会再发生变化了。我们不管以什么精度来获取这个值，都是12.12，而且，不管是一般数据库引擎读取到的也都是12.12，所以decimal才是大家推荐使用的金额存储类型。</li>
</ol>
<p>浮点数类型是把十进制数转换成二进制数存储，decimal是把十进制的整数部分和小数部分拆开，分别装换成十六进制，进行存储。这样，所有的数值，就都可以精准表达了。</p>
<h3 id="大数据查询"><a class="header" href="#大数据查询">大数据查询</a></h3>
<p><strong>创建表</strong></p>
<pre><code class="language-mysql">CREATE TABLE `user_operation_log`  (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `user_id` varchar(64) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `ip` varchar(20) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `op_data` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `attr1` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `attr2` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `attr3` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `attr4` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `attr5` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `attr6` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `attr7` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `attr8` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `attr9` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `attr10` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `attr11` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `attr12` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 1 CHARACTER SET = utf8mb4 COLLATE = utf8mb4_general_ci ROW_FORMAT = Dynamic;
</code></pre>
<p><strong>创建数据脚本</strong></p>
<p>采用批量插入，效率会快很多，而且每1000条数就commit，数据量太大，也会导致批量插入效率慢</p>
<pre><code class="language-mysql">DELIMITER ;;
CREATE PROCEDURE batch_insert_log()
BEGIN
  DECLARE i INT DEFAULT 1;
  DECLARE userId INT DEFAULT 10000000;
 set @execSql = 'INSERT INTO `test`.`user_operation_log`(`user_id`, `ip`, `op_data`, `attr1`, `attr2`, `attr3`, `attr4`, `attr5`, `attr6`, `attr7`, `attr8`, `attr9`, `attr10`, `attr11`, `attr12`) VALUES';
 set @execData = '';
  WHILE i&lt;=10000000 DO
   set @attr = &quot;'测试很长很长很长很长很长很长很长很长很长很长很长很长很长很长很长很长很长的属性'&quot;;
  set @execData = concat(@execData, &quot;(&quot;, userId + i, &quot;, '10.0.69.175', '用户登录操作'&quot;, &quot;,&quot;, @attr, &quot;,&quot;, @attr, &quot;,&quot;, @attr, &quot;,&quot;, @attr, &quot;,&quot;, @attr, &quot;,&quot;, @attr, &quot;,&quot;, @attr, &quot;,&quot;, @attr, &quot;,&quot;, @attr, &quot;,&quot;, @attr, &quot;,&quot;, @attr, &quot;,&quot;, @attr, &quot;)&quot;);
  if i % 1000 = 0
  then
     set @stmtSql = concat(@execSql, @execData,&quot;;&quot;);
    prepare stmt from @stmtSql;
    execute stmt;
    DEALLOCATE prepare stmt;
    commit;
    set @execData = &quot;&quot;;
   else
     set @execData = concat(@execData, &quot;,&quot;);
   end if;
  SET i=i+1;
  END WHILE;

END;;
DELIMITER ;
</code></pre>
<p><strong>开始测试</strong></p>
<blockquote>
<p>“</p>
<p>电脑配置比较低：win10 标压渣渣i5 读写约500MB的SSD</p>
</blockquote>
<p>由于配置低，本次测试只准备了3148000条数据，占用了磁盘5G(还没建索引的情况下)，跑了38min，电脑配置好的同学，可以插入多点数据测试</p>
<pre><code class="language-mysql">SELECT count(1) FROM `user_operation_log`
</code></pre>
<p>返回结果：3148000</p>
<p>三次查询时间分别为：</p>
<ul>
<li>14060 ms</li>
<li>13755 ms</li>
<li>13447 ms</li>
</ul>
<p><strong>普通分页查询</strong></p>
<p>MySQL 支持 LIMIT 语句来选取指定的条数数据， Oracle 可以使用 ROWNUM 来选取。</p>
<p>MySQL分页查询语法如下：</p>
<pre><code class="language-mysql">SELECT * FROM table LIMIT [offset,] rows | rows OFFSET offset
</code></pre>
<ul>
<li>第一个参数指定第一个返回记录行的偏移量</li>
<li>第二个参数指定返回记录行的最大数目</li>
</ul>
<p>下面我们开始测试查询结果：</p>
<pre><code class="language-mysql">SELECT * FROM `user_operation_log` LIMIT 10000, 10
</code></pre>
<p>查询3次时间分别为：</p>
<ul>
<li>59 ms</li>
<li>49 ms</li>
<li>50 ms</li>
</ul>
<p>这样看起来速度还行，不过是本地数据库，速度自然快点。</p>
<p>换个角度来测试</p>
<p><strong>相同偏移量，不同数据量</strong></p>
<pre><code class="language-mysql">SELECT * FROM `user_operation_log` LIMIT 10000, 10
SELECT * FROM `user_operation_log` LIMIT 10000, 100
SELECT * FROM `user_operation_log` LIMIT 10000, 1000
SELECT * FROM `user_operation_log` LIMIT 10000, 10000
SELECT * FROM `user_operation_log` LIMIT 10000, 100000
SELECT * FROM `user_operation_log` LIMIT 10000, 1000000
</code></pre>
<p>查询时间如下：</p>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">数量</th><th style="text-align: left">第一次</th><th style="text-align: left">第二次</th><th style="text-align: left">第三次</th></tr></thead><tbody>
<tr><td style="text-align: left">10条</td><td style="text-align: left">53ms</td><td style="text-align: left">52ms</td><td style="text-align: left">47ms</td></tr>
<tr><td style="text-align: left">100条</td><td style="text-align: left">50ms</td><td style="text-align: left">60ms</td><td style="text-align: left">55ms</td></tr>
<tr><td style="text-align: left">1000条</td><td style="text-align: left">61ms</td><td style="text-align: left">74ms</td><td style="text-align: left">60ms</td></tr>
<tr><td style="text-align: left">10000条</td><td style="text-align: left">164ms</td><td style="text-align: left">180ms</td><td style="text-align: left">217ms</td></tr>
<tr><td style="text-align: left">100000条</td><td style="text-align: left">1609ms</td><td style="text-align: left">1741ms</td><td style="text-align: left">1764ms</td></tr>
<tr><td style="text-align: left">1000000条</td><td style="text-align: left">16219ms</td><td style="text-align: left">16889ms</td><td style="text-align: left">17081ms</td></tr>
</tbody></table>
</div>
<p>从上面结果可以得出结束：<strong>数据量越大，花费时间越长</strong></p>
<p><strong>相同数据量，不同偏移量</strong></p>
<pre><code class="language-mysql">SELECT * FROM `user_operation_log` LIMIT 100, 100
SELECT * FROM `user_operation_log` LIMIT 1000, 100
SELECT * FROM `user_operation_log` LIMIT 10000, 100
SELECT * FROM `user_operation_log` LIMIT 100000, 100
SELECT * FROM `user_operation_log` LIMIT 1000000, 100
</code></pre>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">偏移量</th><th style="text-align: left">第一次</th><th style="text-align: left">第二次</th><th style="text-align: left">第三次</th></tr></thead><tbody>
<tr><td style="text-align: left">100</td><td style="text-align: left">36ms</td><td style="text-align: left">40ms</td><td style="text-align: left">36ms</td></tr>
<tr><td style="text-align: left">1000</td><td style="text-align: left">31ms</td><td style="text-align: left">38ms</td><td style="text-align: left">32ms</td></tr>
<tr><td style="text-align: left">10000</td><td style="text-align: left">53ms</td><td style="text-align: left">48ms</td><td style="text-align: left">51ms</td></tr>
<tr><td style="text-align: left">100000</td><td style="text-align: left">622ms</td><td style="text-align: left">576ms</td><td style="text-align: left">627ms</td></tr>
<tr><td style="text-align: left">1000000</td><td style="text-align: left">4891ms</td><td style="text-align: left">5076ms</td><td style="text-align: left">4856ms</td></tr>
</tbody></table>
</div>
<p>从上面结果可以得出结束：<strong>偏移量越大，花费时间越长</strong></p>
<pre><code class="language-mysql">SELECT * FROM `user_operation_log` LIMIT 100, 100
SELECT id, attr FROM `user_operation_log` LIMIT 100, 100
</code></pre>
<p><strong>如何优化</strong></p>
<p>既然我们经过上面一番的折腾，也得出了结论，针对上面两个问题：偏移大、数据量大，我们分别着手优化</p>
<p>优化偏移量大问题</p>
<p><strong>采用子查询方式</strong></p>
<p>我们可以先定位偏移位置的 id，然后再查询数据</p>
<pre><code class="language-mysql">SELECT * FROM `user_operation_log` LIMIT 1000000, 10

SELECT id FROM `user_operation_log` LIMIT 1000000, 1

SELECT * FROM `user_operation_log` WHERE id &gt;= (SELECT id FROM `user_operation_log` LIMIT 1000000, 1) LIMIT 10
</code></pre>
<p>查询结果如下：</p>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">sql</th><th style="text-align: left">花费时间</th></tr></thead><tbody>
<tr><td style="text-align: left">第一条</td><td style="text-align: left">4818ms</td></tr>
<tr><td style="text-align: left">第二条(无索引情况下)</td><td style="text-align: left">4329ms</td></tr>
<tr><td style="text-align: left">第二条(有索引情况下)</td><td style="text-align: left">199ms</td></tr>
<tr><td style="text-align: left">第三条(无索引情况下)</td><td style="text-align: left">4319ms</td></tr>
<tr><td style="text-align: left">第三条(有索引情况下)</td><td style="text-align: left">201ms</td></tr>
</tbody></table>
</div>
<p>从上面结果得出结论：</p>
<ul>
<li>第一条花费的时间最大，第三条比第一条稍微好点</li>
<li>子查询使用索引速度更快</li>
</ul>
<p>缺点：只适用于id递增的情况</p>
<p>id非递增的情况可以使用以下写法，但这种缺点是分页查询只能放在子查询里面</p>
<p>注意：某些 mysql 版本不支持在 in 子句中使用 limit，所以采用了多个嵌套select</p>
<pre><code class="language-mysql">SELECT * FROM `user_operation_log` WHERE id IN (SELECT t.id FROM (SELECT id FROM `user_operation_log` LIMIT 1000000, 10) AS t)
</code></pre>
<p><strong>采用 id 限定方式</strong></p>
<p>这种方法要求更高些，id必须是连续递增，而且还得计算id的范围，然后使用 between，sql如下</p>
<pre><code class="language-mysql">SELECT * FROM `user_operation_log` WHERE id between 1000000 AND 1000100 LIMIT 100

SELECT * FROM `user_operation_log` WHERE id &gt;= 1000000 LIMIT 100
</code></pre>
<p>查询结果如下：</p>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">sql</th><th style="text-align: left">花费时间</th></tr></thead><tbody>
<tr><td style="text-align: left">第一条</td><td style="text-align: left">22ms</td></tr>
<tr><td style="text-align: left">第二条</td><td style="text-align: left">21ms</td></tr>
</tbody></table>
</div>
<p>从结果可以看出这种方式非常快</p>
<p><em>注意：这里的 LIMIT 是限制了条数，没有采用偏移量</em></p>
<p><strong>优化数据量大问题</strong></p>
<p>返回结果的数据量也会直接影响速度</p>
<pre><code class="language-mysql">SELECT * FROM `user_operation_log` LIMIT 1, 1000000

SELECT id FROM `user_operation_log` LIMIT 1, 1000000

SELECT id, user_id, ip, op_data, attr1, attr2, attr3, attr4, attr5, attr6, attr7, attr8, attr9, attr10, attr11, attr12 FROM `user_operation_log` LIMIT 1, 1000000
</code></pre>
<p>查询结果如下：</p>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">sql</th><th style="text-align: left">花费时间</th></tr></thead><tbody>
<tr><td style="text-align: left">第一条</td><td style="text-align: left">15676ms</td></tr>
<tr><td style="text-align: left">第二条</td><td style="text-align: left">7298ms</td></tr>
<tr><td style="text-align: left">第三条</td><td style="text-align: left">15960ms</td></tr>
</tbody></table>
</div>
<p>从结果可以看出减少不需要的列，查询效率也可以得到明显提升</p>
<p>第一条和第三条查询速度差不多，这时候你肯定会吐槽，那我还写那么多字段干啥呢，直接 * 不就完事了</p>
<p>注意本人的 MySQL 服务器和客户端是在_同一台机器_上，所以查询数据相差不多，有条件的同学可以测测客户端与MySQL分开</p>
<p><strong>SELECT * 它不香吗？</strong></p>
<p>在这里顺便补充一下为什么要禁止 <code>SELECT *</code>。难道简单无脑，它不香吗？</p>
<p>主要两点：</p>
<ol>
<li>用 &quot;<code>SELECT * </code>&quot; 数据库需要解析更多的对象、字段、权限、属性等相关内容，在 SQL 语句复杂，硬解析较多的情况下，会对数据库造成沉重的负担。</li>
<li>增大网络开销，<code>*</code> 有时会误带上如log、IconMD5之类的无用且大文本字段，数据传输size会几何增涨。特别是MySQL和应用程序不在同一台机器，这种开销非常明显。</li>
</ol>
<h3 id="批量修改数据表和数据表中所有字段的字符集"><a class="header" href="#批量修改数据表和数据表中所有字段的字符集">批量修改数据表和数据表中所有字段的字符集</a></h3>
<p>查看数据表的行格式：</p>
<pre><code class="language-mysql">show table status like 库名
</code></pre>
<p>查看库的字符集：</p>
<pre><code class="language-mysql">show database status from 库名
</code></pre>
<p>查看表中所有列的字符集：</p>
<pre><code class="language-mysql">show full columns from 表名
</code></pre>
<p>更改表编码(字符集)<strong>和表中所有字段</strong>的编码(字符集)：</p>
<pre><code class="language-mysql">ALTER TABLE TABLE_NAME CONVERT TO CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;
</code></pre>
<p>如果一个数据库有很多表要修改，可以使用如下办法：</p>
<p>查询某个数据库所有表名的语句：</p>
<pre><code class="language-mysql">SELECT TABLE_NAME from information_schema.`TABLES` WHERE TABLE_SCHEMA = 'DATABASE_NAME';
</code></pre>
<p>得到所有的表名，我们可以把表名拼接到上面更改表编码(字符集)<strong>和表中所有字段</strong>的编码(字符集)的语句中去，得到如下语句：</p>
<pre><code class="language-sql">SELECT
	CONCAT(
		'ALTER TABLE ',
		TABLE_NAME,
		' CONVERT TO CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;'
	)
FROM
	information_schema.`TABLES`
WHERE
	TABLE_SCHEMA = 'DATABASE_NAME';
</code></pre>
<h2 id="性能优化"><a class="header" href="#性能优化">性能优化</a></h2>
<h3 id="建立索引的几个准则"><a class="header" href="#建立索引的几个准则">建立索引的几个准则</a></h3>
<ol>
<li>合理的建立索引能够加速数据读取效率，不合理的建立索引反而会拖慢数据库的响应速度。</li>
<li>索引越多，更新数据的速度越慢。</li>
<li>尽量在采用MyIsam作为引擎的时候使用索引（因为MySQL以BTree存储索引），而不是InnoDB，但MyISAM不支持Transcation。</li>
<li>当你的程序和数据库结构/SQL语句已经优化到无法优化的程度，而程序瓶颈并不能顺利解决，那就是应该考虑使用诸如memcached这样的分布式缓存系统的时候了。</li>
<li>习惯和强迫自己用EXPLAIN来分析你SQL语句的性能。</li>
</ol>
<h3 id="count的优化"><a class="header" href="#count的优化">count的优化</a></h3>
<p>比如：计算id大于5的城市。</p>
<p>a：</p>
<pre><code class="language-mysql">select count(*) from world.city where id &gt; 5;
</code></pre>
<p>b：</p>
<pre><code class="language-mysql">select (select count(*) from world.city) – count(*) from world.city where id &lt;= 5;
</code></pre>
<p>a语句当行数超过11行的时候需要扫描的行数比b语句要多，b语句扫描了6行，此种情况下，b语句比a语句更有效率。</p>
<p>当没有where语句的时候直接select count(*) from world.city这样会更快，因为MySQL总是知道表的行数。</p>
<h3 id="避免使用不兼容的数据类型"><a class="header" href="#避免使用不兼容的数据类型">避免使用不兼容的数据类型</a></h3>
<p>例如float和int、char和varchar、binary和varbinary是不兼容的，数据类型的不兼容可能使优化器无法执行一些本来可以进行的优化操作。</p>
<p><strong>在程序中，保证在实现功能的基础上：</strong></p>
<ul>
<li>尽量减少对数据库的访问次数；</li>
<li>通过搜索参数，尽量减少对表的访问行数,最小化结果集，从而减轻网络负担；</li>
<li>能够分开的操作尽量分开处理，提高每次的响应速度。</li>
</ul>
<p><strong>在数据窗口使用SQL时：</strong></p>
<ul>
<li>尽量把使用的索引放在选择的首列；</li>
<li>算法的结构尽量简单。</li>
</ul>
<p><strong>在查询时：</strong></p>
<ul>
<li>不要过多地使用通配符如 SELECT * FROM T1语句，要用到几列就选择几列如：SELECT COL1,COL2 FROM T1；</li>
<li>在可能的情况下尽量限制尽量结果集行数如：SELECT TOP 300 COL1,COL2,COL3 FROM T1,因为某些情况下用户是不需要那么多的数据的。</li>
</ul>
<p><strong>不要在应用中使用数据库游标：</strong></p>
<ul>
<li>游标是非常有用的工具，但比使用常规的、面向集的SQL语句需要更大的开销；</li>
<li>按照特定顺序提取数据的查找。</li>
</ul>
<h3 id="索引字段上进行运算会使索引失效"><a class="header" href="#索引字段上进行运算会使索引失效">索引字段上进行运算会使索引失效</a></h3>
<p>尽量避免在WHERE子句中对字段进行函数或表达式操作，这将导致引擎放弃使用索引而进行全表扫描。</p>
<p>如：</p>
<pre><code class="language-mysql">SELECT * FROM T1 WHERE F1/2=100
</code></pre>
<p>应改为：</p>
<pre><code class="language-mysql">SELECT * FROM T1 WHERE F1=100*2
</code></pre>
<h3 id="避免使用某些操作符"><a class="header" href="#避免使用某些操作符">避免使用某些操作符</a></h3>
<p>避免使用!=或＜＞、IS NULL或IS NOT NULL、IN ，NOT IN等这样的操作符。</p>
<p>因为这会使系统无法使用索引，而只能直接搜索表中的数据。</p>
<p>例如: SELECT id FROM employee WHERE id != “B%” 优化器将无法通过索引来确定将要命中的行数，因此需要搜索该表的所有行。</p>
<p>在in语句中能用exists语句代替的就用exists。</p>
<h3 id="尽量使用数字型字段"><a class="header" href="#尽量使用数字型字段">尽量使用数字型字段</a></h3>
<p>一部分开发人员和数据库管理人员喜欢把包含数值信息的字段设计为字符型，这会降低查询和连接的性能，并会增加存储开销。</p>
<p>这是因为引擎在处理查询和连接回逐个比较字符串中每一个字符，而对于数字型而言只需要比较一次就够了。</p>
<h3 id="合理使用existsnot-exists子句"><a class="header" href="#合理使用existsnot-exists子句">合理使用EXISTS、NOT EXISTS子句</a></h3>
<p>如下所示：</p>
<p>1：</p>
<pre><code class="language-mysql">SELECT SUM(T1.C1) FROM T1 WHERE (SELECT COUNT(*)FROM T2 WHERE T2.C2=T1.C2&gt;0)
</code></pre>
<p>2：</p>
<pre><code class="language-mysql">SELECT SUM(T1.C1) FROM T1WHERE EXISTS(SELECT * FROM T2 WHERE T2.C2=T1.C2)
</code></pre>
<p>两者生相同的结果，但是后者的效率显然要高于前者，因为后者不会产生大量锁定的表扫描或是索引扫描。</p>
<p>如果你想校验表里是否存在某条纪录，不要用count(*)那样效率很低，而且浪费服务器资源。可以用EXISTS代替。</p>
<p>如：</p>
<pre><code class="language-mysql">IF (SELECT COUNT(*) FROM table_name WHERE column_name = ‘xxx’)
</code></pre>
<p>可以写成：</p>
<pre><code class="language-mysql">IF EXISTS (SELECT * FROM table_name WHERE column_name = ‘xxx’)
</code></pre>
<h3 id="避免使用一些语句"><a class="header" href="#避免使用一些语句">避免使用一些语句</a></h3>
<ul>
<li>能够用BETWEEN的就不要用IN；</li>
<li>能够用DISTINCT的就不用GROUP BY；</li>
<li>尽量不要用SELECT INTO语句。SELECT INTO 语句会导致表锁定，阻止其他用户访问该表。</li>
</ul>
<h3 id="必要时强制查询优化器使用某个索引"><a class="header" href="#必要时强制查询优化器使用某个索引">必要时强制查询优化器使用某个索引</a></h3>
<pre><code class="language-mysql">SELECT * FROM T1 WHERE nextprocess = 1 AND processid IN (8,32,45)
</code></pre>
<p>改成：</p>
<pre><code class="language-mysql">SELECT * FROM T1 (INDEX = IX_ProcessID) WHERE nextprocess = 1 AND processid IN (8,32,45)
</code></pre>
<p>则查询优化器将会强行利用索引IX_ProcessID 执行查询。</p>
<h3 id="消除对大型表行数据的顺序存取"><a class="header" href="#消除对大型表行数据的顺序存取">消除对大型表行数据的顺序存取</a></h3>
<p>尽管在所有的检查列上都有索引，但某些形式的WHERE子句强迫优化器使用顺序存取。</p>
<p>如：</p>
<pre><code class="language-mysql">SELECT * FROM orders WHERE (customer_num=104 AND order_num&gt;1001) OR order_num=1008
</code></pre>
<p>解决办法可以使用并集来避免顺序存取：</p>
<pre><code class="language-mysql"> SELECT * FROM orders WHERE customer_num=104 AND order_num&gt;1001 UNION SELECT * FROM orders WHERE order_num=1008
</code></pre>
<p>这样就能利用索引路径处理查询。jacking 数据结果集很多，但查询条件限定后结果集不大的情况下，后面的语句快。</p>
<h3 id="避免使用非打头字母搜索"><a class="header" href="#避免使用非打头字母搜索">避免使用非打头字母搜索</a></h3>
<p>尽量避免在索引过的字符数据中，使用非打头字母搜索。这也使得引擎无法利用索引。</p>
<p>见如下例子：</p>
<pre><code class="language-mysql">SELECT * FROM T1 WHERE NAME LIKE ‘%L%’ SELECT * FROM T1 WHERE SUBSTING(NAME,2,1)=’L’ SELECT * FROM T1 WHERE NAME LIKE ‘L%’
</code></pre>
<p>即使NAME字段建有索引，前两个查询依然无法利用索引完成加快操作，引擎不得不对全表所有数据逐条操作来完成任务。</p>
<p>而第三个查询能够使用索引来加快操作，不要习惯性的使用 ‘%L%’这种方式(会导致全表扫描)，如果可以使用`L%’相对来说更好。</p>
<h3 id="建议"><a class="header" href="#建议">建议</a></h3>
<p>虽然UPDATE、DELETE语句的写法基本固定，但是还是对UPDATE语句给点建议：</p>
<ul>
<li>尽量不要修改主键字段；</li>
<li>当修改VARCHAR型字段时，尽量使用相同长度内容的值代替；</li>
<li>尽量最小化对于含有UPDATE触发器的表的UPDATE操作；</li>
<li>避免UPDATE将要复制到其他数据库的列；</li>
<li>避免UPDATE建有很多索引的列；</li>
<li>避免UPDATE在WHERE子句条件中的列。</li>
</ul>
<h3 id="能用union-all就不要用union"><a class="header" href="#能用union-all就不要用union">能用UNION ALL就不要用UNION</a></h3>
<p>UNION ALL不执行SELECT DISTINCT函数，这样就会减少很多不必要的资源。</p>
<p>在跨多个不同的数据库时使用UNION是一个有趣的优化方法，UNION从两个互不关联的表中返回数据，这就意味着不会出现重复的行，同时也必须对数据进行排序。</p>
<p>我们知道排序是非常耗费资源的，特别是对大表的排序，UNION ALL可以大大加快速度，如果你已经知道你的数据不会包括重复行，或者你不在乎是否会出现重复的行，在这两种情况下使用UNION ALL更适合。</p>
<p>此外，还可以在应用程序逻辑中采用某些方法避免出现重复的行，这样UNION ALL和UNION返回的结果都是一样的，但UNION ALL不会进行排序。</p>
<p>![图片](data:image/svg+xml,&lt;%3Fxml version='1.0' encoding='UTF-8'%3F&gt;<svg width='1px' height='1px' viewBox='0 0 1 1' version='1.1' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'><title></title><g stroke='none' stroke-width='1' fill='none' fill-rule='evenodd' fill-opacity='0'><g transform='translate(-249.000000, -126.000000)' fill='%23FFFFFF'><rect x='249' y='126' width='1' height='1'></rect></g></g></svg>)</p>
<h3 id="字段数据类型优化"><a class="header" href="#字段数据类型优化">字段数据类型优化</a></h3>
<p>避免使用NULL类型：NULL对于大多数数据库都需要特殊处理，MySQL也不例外。</p>
<p>它需要更多的代码，更多的检查和特殊的索引逻辑，有些开发人员完全没有意识到，创建表时NULL是默认值，但大多数时候应该使用NOT NULL，或者使用一个特殊的值，如0，-1作为默认值。</p>
<p>尽可能使用更小的字段：MySQL从磁盘读取数据后是存储到内存中的，然后使用cpu周期和磁盘I/O读取它。</p>
<p>这意味着越小的数据类型占用的空间越小，从磁盘读或打包到内存的效率都更好，但也不要太过执着减小数据类型，要是以后应用程序发生什么变化就没有空间了。</p>
<p>修改表将需要重构，间接地可能引起代码的改变，这是很头疼的问题，因此需要找到一个平衡点。</p>
<p>优先使用定长型。</p>
<h3 id="一次性插入多条数据"><a class="header" href="#一次性插入多条数据">一次性插入多条数据</a></h3>
<p>程序中如果一次性对同一个表插入多条数据，比如以下语句：</p>
<pre><code class="language-mysql">insert into person(name,age) values(‘xboy’, 14);
insert into person(name,age) values(‘xgirl’, 15);
insert into person(name,age) values(‘nia’, 19);
</code></pre>
<p>把它拼成一条语句执行效率会更高：</p>
<pre><code class="language-mysql">insert into person(name,age) values(‘xboy’, 14), (‘xgirl’, 15),(‘nia’, 19);
</code></pre>
<h3 id="无意义语句"><a class="header" href="#无意义语句">无意义语句</a></h3>
<p>不要在选择的栏位上放置索引，这是无意义的。应该在条件选择的语句上合理的放置索引，比如where、order by。</p>
<pre><code class="language-mysql">SELECT id,title,content,cat_id FROM article WHERE cat_id = 1;
</code></pre>
<p>上面这个语句，你在id/title/content上放置索引是毫无意义的，对这个语句没有任何优化作用。但是如果你在外键cat_id上放置一个索引，那作用就相当大了。</p>
<h3 id="order-by语句的mysql优化"><a class="header" href="#order-by语句的mysql优化">ORDER BY语句的MySQL优化</a></h3>
<p>ORDER BY + LIMIT组合的索引优化。如果一个SQL语句形如：</p>
<pre><code class="language-mysql">SELECT [column1],[column2],…. FROM [TABLE] ORDER BY [sort] LIMIT [offset],[LIMIT];
</code></pre>
<p>这个SQL语句优化比较简单，在[sort]这个栏位上建立索引即可。</p>
<p>b. WHERE + ORDER BY + LIMIT组合的索引优化，形如：</p>
<pre><code class="language-mysql">SELECT [column1],[column2],…. FROM [TABLE] WHERE [columnX] = [VALUE] ORDER BY [sort] LIMIT [offset],[LIMIT];
</code></pre>
<p>这个语句，如果你仍然采用第一个例子中建立索引的方法，虽然可以用到索引，但是效率不高。</p>
<p>更高效的方法是建立一个联合索引(columnX,sort)。WHERE + IN + ORDER BY + LIMIT组合的索引优化，形如：</p>
<pre><code class="language-mysql">SELECT [column1],[column2],…. FROM [TABLE] WHERE [columnX] IN ([value1],[value2],…) ORDER BY [sort] LIMIT [offset],[LIMIT];
</code></pre>
<p>这个语句如果你采用第二个例子中建立索引的方法，会得不到预期的效果（仅在[sort]上是using index，WHERE那里是using where;using filesort），理由是这里对应columnX的值对应多个。目前还没有找到比较优秀的办法，等待高手指教。</p>
<p>WHERE+ORDER BY多个栏位+LIMIT，比如:</p>
<pre><code class="language-mysql">SELECT * FROM [table] WHERE uid=1 ORDER x,y LIMIT 0,10;
</code></pre>
<p>对于这个语句，大家可能是加一个这样的索引：(x,y,uid)。但实际上更好的效果是(uid,x,y)。这是由MySQL处理排序的机制造成的。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="netty"><a class="header" href="#netty">Netty</a></h1>
<h2 id="bioblocking-io"><a class="header" href="#bioblocking-io">BIO（Blocking IO）</a></h2>
<p><img src="https://github.com/chou401/pic-md/raw/master/img/image-20230313103444295.png" alt="image-20230313103444295" /></p>
<h2 id="nionon-blocking-io"><a class="header" href="#nionon-blocking-io">NIO（Non Blocking IO）</a></h2>
<p><img src="https://github.com/chou401/pic-md/raw/master/img/image-20230313103559073.png" alt="image-20230313103559073" /></p>
<p>selector（多路复用器）</p>
<p>epoll</p>
<p>I/O多路复用底层主要用的linux内核函数（select，poll，epoll）来实现，windows不支持epoll实现，windows底层是基于winsock2的select函数实现的（不开源）</p>
<p>创建两个线程组bossGroup和workerGroup，含有的子线程NioEventLoop的个数默认为cpu合数的两倍，bossGroup只是处理连接请求，真正的和客户端业务处理，会交给workerGroup完成。</p>
<p>零拷贝机制</p>
<p><img src="https://github.com/chou401/pic-md/raw/master/img/image-20230314182800432.png" alt="image-20230314182800432" /></p>
<p>长连接心跳保活机制</p>
<p>直接内存</p>
<p>DiretByteBuffer 分配在物理内存</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="slf4j"><a class="header" href="#slf4j">Slf4j</a></h1>
<p>SLF4J：全称是 Simple Logging Facade for Java，Java 的简单日志门面，是现在 Java 生态中最流行的一个门面日志框架。</p>
<p><img src="https://raw.githubusercontent.com/chou401/pic-md/master/image-20230822165303257.png" alt="image-20230822165303257" /></p>
<p><img src="https://raw.githubusercontent.com/chou401/pic-md/master/image-20230822165834387.png" alt="image-20230822165834387" /></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="spring"><a class="header" href="#spring">Spring</a></h1>
<h2 id="常见异常"><a class="header" href="#常见异常">常见异常</a></h2>
<div class="table-wrapper"><table><thead><tr><th>异常</th><th>描述</th></tr></thead><tbody>
<tr><td>ClassCastException</td><td>类型强制转换异常</td></tr>
<tr><td>NegativeArrayException</td><td>数组负下标异常</td></tr>
<tr><td>ArrayIndexOutOfBoundsException</td><td>数组下标越界异常</td></tr>
<tr><td>SecturityException</td><td>违背安全原则异常</td></tr>
<tr><td>EOFException</td><td>文件已结束异常</td></tr>
<tr><td>FileNotFoundException</td><td>文件未找到异常</td></tr>
<tr><td>NumberFormatException</td><td>字符串转换为数字异常</td></tr>
<tr><td>SQLException</td><td>操作数据库异常</td></tr>
<tr><td>IOException</td><td>输入输出异常</td></tr>
<tr><td>NoSuchMethodException</td><td>方法未找到异常</td></tr>
<tr><td>Java.lang.AbstractMethodError</td><td>抽象方法错误。当应用试图调用抽象方法时抛出。</td></tr>
<tr><td>java.lang.AssertionError</td><td>断言错。用来指示一个断言失败的情况。</td></tr>
<tr><td>java.lang.ClassCircularityError</td><td>类循环依赖错误。在初始化一个类时，若检测到类之间循环依赖则抛出该异常。</td></tr>
<tr><td>java.lang.ClassFormatError</td><td>类格式错误。当Java虚拟机试图从一个文件中读取Java类，而检测到该文件的内容不符合类的有效格式时抛出。</td></tr>
<tr><td>java.lang.Error</td><td>错误。是所有错误的基类，用于标识严重的程序运行问题。这些问题通常描述一些不应被应用程序捕获的反常情况。</td></tr>
<tr><td>java.lang.ExceptionInInitializerError</td><td>初始化程序错误。当执行一个类的静态初始化程序的过程中，发生了异常时抛出。静态初始化程序是指直接包含于类中的static语句段。</td></tr>
<tr><td>java.lang.IllegalAccessError</td><td>违法访问错误。当一个应用试图访问、修改某个类的域(Field)或者调用其方法，但是又违反域或方法的可见性声明，则抛出该异常。</td></tr>
<tr><td>java.lang.IncompatibleClassChangeError</td><td>不兼容的类变化错误。当正在执行的方法所依赖的类定义发生了不兼容的改变时，抛出该异常。一般在修改了应用中的某些类的声明定义而没有对整个应用重新编译而直接运行的情况下，容易引发该错误。</td></tr>
<tr><td>java.lang.InstantiationError</td><td>实例化错误。当一个应用试图通过Java的new操作符构造一个抽象类或者接口时抛出该异常.</td></tr>
<tr><td>java.lang.InternalError</td><td>内部错误。用于指示Java虚拟机发生了内部错误。</td></tr>
<tr><td>java.lang.LinkageError</td><td>链接错误。该错误及其所有子类指示某个类依赖于另外一些类，在该类编译之后，被依赖的类改变了其类定义而没有重新编译所有的类，进而引发错误的情况。</td></tr>
<tr><td>java.lang.NoClassDefFoundError</td><td>未找到类定义错误。当Java虚拟机或者类装载器试图实例化某个类，而找不到该类的定义时抛出该错误。</td></tr>
<tr><td>java.lang.NoSuchFieldError</td><td>域不存在错误。当应用试图访问或者修改某类的某个域，而该类的定义中没有该域的定义时抛出该错误。</td></tr>
<tr><td>java.lang.NoSuchMethodError</td><td>方法不存在错误。当应用试图调用某类的某个方法，而该类的定义中没有该方法的定义时抛出该错误。</td></tr>
<tr><td>java.lang.OutOfMemoryError</td><td>内存不足错误。当可用内存不足以让Java虚拟机分配给一个对象时抛出该错误。</td></tr>
<tr><td>java.lang.StackOverflowError</td><td>堆栈溢出错误。当一个应用递归调用的层次太深而导致堆栈溢出时抛出该错误。</td></tr>
<tr><td>java.lang.ThreadDeath</td><td>线程结束。当调用Thread类的stop方法时抛出该错误，用于指示线程结束。</td></tr>
<tr><td>java.lang.UnknownError</td><td>未知错误。用于指示Java虚拟机发生了未知严重错误的情况。</td></tr>
<tr><td>java.lang.UnsatisfiedLinkError</td><td>未满足的链接错误。当Java虚拟机未找到某个类的声明为native方法的本机语言定义时抛出。</td></tr>
<tr><td>java.lang.UnsupportedClassVersionError</td><td>不支持的类版本错误。当Java虚拟机试图从读取某个类文件，但是发现该文件的主、次版本号不被当前Java虚拟机支持的时候，抛出该错误。</td></tr>
<tr><td>java.lang.VerifyError</td><td>验证错误。当验证器检测到某个类文件中存在内部不兼容或者安全问题时抛出该错误。</td></tr>
<tr><td>java.lang.VirtualMachineError</td><td>虚拟机错误。用于指示虚拟机被破坏或者继续执行操作所需的资源不足的情况</td></tr>
</tbody></table>
</div>
<h2 id="lambda"><a class="header" href="#lambda">lambda</a></h2>
<p>求两个对象 list 的交集</p>
<pre><code class="language-java">private List&lt;People&gt; sameList(List&lt;People&gt; oldArrayList, List&lt;People&gt; newArrayList) {
    List&lt;People&gt; resultList = newArrayList.stream()
            .filter(item -&gt; oldArrayList.stream().map(e -&gt; e.getCode())
                    .collect(Collectors.toList()).contains(item.getCode()))
            .collect(Collectors.toList());
    return resultList;
}
</code></pre>
<p>求两个对象 list 的差集</p>
<pre><code class="language-java">private List&lt;People&gt; diffList(List&lt;People&gt; firstArrayList, List&lt;People&gt; secondArrayList) {
        List&lt;People&gt; resultList = firstArrayList.stream()
                .filter(item -&gt; !secondArrayList.stream().map(e -&gt; e.getCode()).collect(Collectors.toList()).contains(item.getCode()))
                .collect(Collectors.toList());
        return resultList;
    }
</code></pre>
<p>list 去除另一个 list 重复元素的数据</p>
<pre><code class="language-java">firstList.removeIf(first -&gt; secondList.stream().anyMatch(second -&gt; first.getCode().equals(second.getCode())));
</code></pre>
<h2 id="正则"><a class="header" href="#正则">正则</a></h2>
<p>(?!0(.0+)?$) 使用负向前瞻，排除0、0.0、0.00等数字。</p>
<p>(?!0+(.\d+)?$) 使用负向前瞻，排除以0开头的数字，如0.123、0.001等。</p>
<p>\d+(.\d+)? 匹配正整数和小数，其中小数点后面至少有一位数字</p>
<h2 id="spring-boot"><a class="header" href="#spring-boot">Spring boot</a></h2>
<p>为什么打成的jar包，通过java -jar xxx.jar 就能启动运行？</p>
<p>jar包里面含有一下三部分文件</p>
<p><img src="https://github.com/chou401/pic-md/raw/master/img/image-20230404172555912.png" alt="image-20230404172555912" /></p>
<blockquote>
<p>org：主要存放springboot相关的class文件
META-INF：主要存放maven和MANIFEST.MF文件
BOOT-INF/classes：主要存放应用编译后的class文件
BOOT-INF/lib：主要存放应用依赖的jar包文件</p>
</blockquote>
<p>打开META-INF下MENIFEST.MF文件，内容如下：</p>
<p><img src="https://github.com/chou401/pic-md/raw/master/img/image-20230404172728434.png" alt="image-20230404172728434" /></p>
<p>从上述MANIFEST.MF中可以看到Main-Class及Start-Class配置，其中Main-Class指定jar文件的入口类JarLauncher，当使用java -jar执行jar包的时候会调用JarLauncher的main方法，而不是我们编写的启动类。</p>
<p>JarLauncher叫做jar包启动器，当我们运行java -jar 的时候就会找到这个启动器。</p>
<p>这个启动器是我们在打包的时候弄进去的，也就是我们在pom文件中加入的插件：</p>
<pre><code class="language-xml">&lt;build&gt;
&lt;plugins&gt;
&lt;plugin&gt;
&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
&lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;
&lt;/plugin&gt;
&lt;/plugins&gt;
&lt;/build&gt;
</code></pre>
<blockquote>
<p>注意：
只有添加了spring-boot-maven-plugin插件，运行mvn:package命令后打成的jar包才能直接运行。</p>
</blockquote>
<p>这个插件在打包时候就会把jar启动器添加进去。</p>
<p><strong>java -jar 做了什么</strong></p>
<blockquote>
<p>官网对java -jar的解释如下：</p>
<p>If the -jar option is specified, its argument is the name of the JAR file containing class and resource files for the application. The startup class must be indicated by the Main-Class manifest header in its source code.</p>
<p>如果指定了-jar选项，它的参数是包含应用程序的类和资源文件的JAR文件的名称。启动类必须由其源代码中的Main-Class清单头指明。</p>
</blockquote>
<p>由此可见：当使用java -jar 启动springboot jar包时是去找Manifast.MF文件中的Main-Class指定的类来启动项目。</p>
<p><strong>JarLauncher的执行流程</strong></p>
<blockquote>
<p>org.springframework.boot.loader.JarLauncher#main
org.springframework.boot.loader.Launcher#launch(java.lang.String[])
org.springframework.boot.loader.Launcher#launch(java.lang.String[], java.lang.String, java.lang.ClassLoader) 中的第二个参数mainClass-》org.springframework.boot.loader.ExecutableArchiveLauncher#getMainClass
org.springframework.boot.loader.Launcher#createMainMethodRunner
org.springframework.boot.loader.MainMethodRunner#run</p>
</blockquote>
<p>添加spring-boot-loader依赖，才可以查看源码</p>
<pre><code class="language-xml">&lt;dependency&gt;
	&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
	&lt;artifactId&gt;spring-boot-loader&lt;/artifactId&gt;
	&lt;version&gt;2.1.16.RELEASE&lt;/version&gt;
&lt;/dependency&gt;
</code></pre>
<pre><code class="language-java">package org.springframework.boot.loader;
 
import org.springframework.boot.loader.archive.Archive;
 
/**
 * {@link Launcher} for JAR based archives. This launcher assumes that dependency jars are
 * included inside a {@code /BOOT-INF/lib} directory and that application classes are
 * included inside a {@code /BOOT-INF/classes} directory.
 *
 * {@link Launcher}用于基于JAR的档案。该启动程序假设依赖jar包含在{@code BOOT-INFlib}目录中，并且应用程序类包含在{@code BOOT-INFclasses}目录中。
 *
 * @author Phillip Webb
 * @author Andy Wilkinson
 * @since 1.0.0
 */
public class JarLauncher extends ExecutableArchiveLauncher {
 
	static final String BOOT_INF_CLASSES = &quot;BOOT-INF/classes/&quot;;
 
	static final String BOOT_INF_LIB = &quot;BOOT-INF/lib/&quot;;
 
	public JarLauncher() {
	}
 
	protected JarLauncher(Archive archive) {
		super(archive);
	}
 
	@Override
	protected boolean isNestedArchive(Archive.Entry entry) {
		if (entry.isDirectory()) {
			return entry.getName().equals(BOOT_INF_CLASSES);
		}
		return entry.getName().startsWith(BOOT_INF_LIB);
	}
	//main方法入口， 构造JarLauncher，然后调用它的launch方法。参数是控制台传递的
	public static void main(String[] args) throws Exception {
		new JarLauncher().launch(args);
	}
 
}
</code></pre>
<p><strong>启动类基类</strong>：org.springframework.boot.loader.Launcher-》org.springframework.boot.loader.Launcher#launch(java.lang.String[])</p>
<pre><code class="language-java">/**
 * Base class for launchers that can start an application with a fully configured
 * classpath backed by one or more {@link Archive}s.
 *	启动器的基类，可以用一个或多个{@link Archive}支持的完整配置的类路径启动应用程序。
 * @author Phillip Webb
 * @author Dave Syer
 * @since 1.0.0
 */
public abstract class Launcher {
 
	/**
	 * Launch the application. This method is the initial entry point that should be
	 * called by a subclass {@code public static void main(String[] args)} method.
	 * 启动应用程序。这个方法是一个初始入口点，它应该被子类{@code public static void main(String[] args)}方法调用。
	 * @param args the incoming arguments
	 * @throws Exception if the application fails to launch
	 */
	protected void launch(String[] args) throws Exception {
		//在系统属性中设置注册了自定义的URL处理器：org.springframework.boot.loader.jar.Handler。如果URL中没有指定处理器，会去系统属性中查询
		JarFile.registerUrlProtocolHandler();
		// getClassPathArchives方法在会去找lib目录下对应的第三方依赖JarFileArchive，同时也会项目自身的JarFileArchive
        // 根据getClassPathArchives得到的JarFileArchive集合去创建类加载器ClassLoader。这里会构造一个LaunchedURLClassLoader类加载器，这个类加载器继承URLClassLoader，并使用这些JarFileArchive集合的URL构造成URLClassPath
        // LaunchedURLClassLoader类加载器的父类加载器是当前执行类JarLauncher的类加载器
		ClassLoader classLoader = createClassLoader(getClassPathArchives());
		// getMainClass方法会去项目自身的Archive中的Manifest中找出key为Start-Class的类
		// 调用重载方法launch
		launch(args, getMainClass(), classLoader);
	}
	......
	......
}
</code></pre>
<p>可执行存档启动类的基类：org.springframework.boot.loader.ExecutableArchiveLauncher -》org.springframework.boot.loader.ExecutableArchiveLauncher#getMainClass</p>
<pre><code class="language-java">/**
 * Base class for executable archive {@link Launcher}s.
 * 可执行存档{@link启动器}的基类。
 * @author Phillip Webb
 * @author Andy Wilkinson
 * @since 1.0.0
 */
public abstract class ExecutableArchiveLauncher extends Launcher {
 
	private final Archive archive;
 
	public ExecutableArchiveLauncher() {
		try {
			this.archive = createArchive();
		}
		catch (Exception ex) {
			throw new IllegalStateException(ex);
		}
	}
 
	protected ExecutableArchiveLauncher(Archive archive) {
		this.archive = archive;
	}
 
	protected final Archive getArchive() {
		return this.archive;
	}
 
	@Override
	protected String getMainClass() throws Exception {
		//跟代码this.archive.getManifest()发现对应的是org.springframework.boot.loader.archive.JarFileArchive#getManifest
		//继续跟进入org.springframework.boot.loader.jar.JarFile#getManifest
		//最后org.springframework.boot.loader.jar.JarFile#getManifest对应的是META-INF/MANIFEST.MF文件的内容
		Manifest manifest = this.archive.getManifest();
		String mainClass = null;
		if (manifest != null) {
			//获取META-INF/MANIFEST.MF文件内容中的Start-Class，这才是我们自己写的启动类
			mainClass = manifest.getMainAttributes().getValue(&quot;Start-Class&quot;);
		}
		if (mainClass == null) {
			throw new IllegalStateException(&quot;No 'Start-Class' manifest entry specified in &quot; + this);
		}
		return mainClass;
	}
	......
	......
}
</code></pre>
<p>到此可以看出org.springframework.boot.loader.Launcher#launch(java.lang.String[], java.lang.String, java.lang.ClassLoader)中的mainClass参数正是我们自己写的启动类，也就是META-INF/MANIFEST.MF文件中Start-Class指定的类。</p>
<p><strong>Launcher的launch方法</strong>：org.springframework.boot.loader.Launcher#launch(java.lang.String[], java.lang.String, java.lang.ClassLoader)</p>
<pre><code class="language-java">/**
 * Launch the application given the archive file and a fully configured classloader.
 * 启动应用程序，给出归档文件和一个完全配置的类加载器。
 * @param args the incoming arguments
 * @param mainClass the main class to run
 * @param classLoader the classloader
 * @throws Exception if the launch fails
 */
protected void launch(String[] args, String mainClass, ClassLoader classLoader) throws Exception {
	Thread.currentThread().setContextClassLoader(classLoader);
	createMainMethodRunner(mainClass, args, classLoader).run();
}
</code></pre>
<p><strong>org.springframework.boot.loader.Launcher#createMainMethodRunner</strong></p>
<pre><code class="language-java">/**
 * Create the {@code MainMethodRunner} used to launch the application.
 * @param mainClass the main class
 * @param args the incoming arguments
 * @param classLoader the classloader
 * @return the main method runner
 */
protected MainMethodRunner createMainMethodRunner(String mainClass, String[] args, ClassLoader classLoader) {
	return new MainMethodRunner(mainClass, args);
}
</code></pre>
<p><strong>MainMethodRunner</strong>：org.springframework.boot.loader.MainMethodRunner-》org.springframework.boot.loader.MainMethodRunner#run </p>
<pre><code class="language-java">/**
 * Utility class that is used by {@link Launcher}s to call a main method. The class
 * containing the main method is loaded using the thread context class loader.
 * 被{@link Launcher}用来调用main方法的实用程序类。包含main方法的类是使用线程上下文类装入器装入的。
 * @author Phillip Webb
 * @author Andy Wilkinson
 * @since 1.0.0
 */
public class MainMethodRunner {
 
	private final String mainClassName;
 
	private final String[] args;
 
	/**
	 * Create a new {@link MainMethodRunner} instance.
	 * @param mainClass the main class
	 * @param args incoming arguments
	 */
	public MainMethodRunner(String mainClass, String[] args) {
		this.mainClassName = mainClass;
		this.args = (args != null) ? args.clone() : null;
	}
 
	public void run() throws Exception {
		Class&lt;?&gt; mainClass = Thread.currentThread().getContextClassLoader().loadClass(this.mainClassName);
		Method mainMethod = mainClass.getDeclaredMethod(&quot;main&quot;, String[].class);
		mainMethod.invoke(null, new Object[] { this.args });
	}
 
}
</code></pre>
<p>上述关键代码执行流程简化如下图:</p>
<p><img src="https://raw.githubusercontent.com/chou401/pic-md/master/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0VmbHlpbmdz,size_16,color_FFFFFF,t_70.png" alt="img" /></p>
<p><strong>使用依赖包common</strong> </p>
<p>common 执行mvn install时，会报错提示 Unable to find a single main class。spring boot项目使用maven打包，如果没有做配置的话，会自动寻找签名是public static void main(String[] args)的方法。common 只是一个服务工程，本来就不会存在启动入口。</p>
<p>在common中添加过滤配置即可打包成功：</p>
<pre><code class="language-xml">&lt;plugin&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;
    &lt;configuration&gt;
        &lt;skip&gt;true&lt;/skip&gt;
    &lt;/configuration&gt;
&lt;/plugin&gt;
</code></pre>
<p><strong>jar启动器的作用</strong></p>
<p>当我们使用java -jar的时候 JarLauncher 会将BOOT-INF/classes下的类文件和BOOT-INF/lib下依赖的jar包加载到classpath下，最后调用META-INF下的MANIFEST.MF文件的Start-Class属性来完成应用程序的启动。</p>
<h3 id="spring-自动配置"><a class="header" href="#spring-自动配置">Spring 自动配置</a></h3>
<p>![image-20230823113954382](/Users/chouchou/Library/Application Support/typora-user-images/image-20230823113954382.png)</p>
<p>SpringBoot 自动配置，Auto-Configuration</p>
<ul>
<li>它是指基于你引入的依赖 jar 包，对 SpringBoot 应用进行自动配置</li>
<li>它是SpringBoot框架的“开箱即用”提供了基础支撑</li>
</ul>
<p>术语“配置类”，Configuration Class</p>
<ul>
<li>广义的“配置类”：被注解@Component 直接或间接修饰的某个类，即我们常说的 Spring 组件，其中包括了@Configuration 类</li>
<li>狭义的“配置类”：特指被注解 @Configuration 所修饰的某个类，又成为 @Configuration 类</li>
</ul>
<p><img src="https://raw.githubusercontent.com/chou401/pic-md/master/image-20230822172218836.png" alt="image-20230822172218836" /></p>
<p><img src="https://raw.githubusercontent.com/chou401/pic-md/master/image-20230822172402498.png" alt="image-20230822172402498" /></p>
<p><img src="https://raw.githubusercontent.com/chou401/pic-md/master/image-20230822173011734.png" alt="image-20230822173011734" /></p>
<p><img src="https://raw.githubusercontent.com/chou401/pic-md/master/image-20230823113418389.png" alt="image-20230823113418389" /></p>
<p><img src="https://raw.githubusercontent.com/chou401/pic-md/master/image-20230823113448199.png" alt="image-20230823113448199" /></p>
<p><img src="https://raw.githubusercontent.com/chou401/pic-md/master/image-20230823113602551.png" alt="image-20230823113602551" /></p>
<p><img src="https://raw.githubusercontent.com/chou401/pic-md/master/image-20230823113646014.png" alt="image-20230823113646014" /></p>
<h4 id="conditional"><a class="header" href="#conditional">@Conditional</a></h4>
<ul>
<li>它的作用是实现：只有在特定条件满足时，才会向 IOC 容器注册指定的组件</li>
<li>我们可以将 @Conditional 理解为某种 if 语句</li>
</ul>
<p><img src="https://raw.githubusercontent.com/chou401/pic-md/master/image-20230823113909162.png" alt="image-20230823113909162" /></p>
<h4 id="componentscan"><a class="header" href="#componentscan">@ComponentScan</a></h4>
<p>@ComponentScan，来自 Spring 框架的一个注解</p>
<ul>
<li>对指定的 package 进行扫描，找到其中符合条件的类，默认是搜索被注解@Component 修饰的配置类</li>
<li>通过属性 basePackages 或 basePackageClasses，来指定要进行扫描的 package</li>
<li>如果未指定 package，则默认扫描当前 @ComponentScan 所修饰的类所在的 package</li>
</ul>
<h4 id="import--configuration"><a class="header" href="#import--configuration">@Import &amp; @Configuration</a></h4>
<p>通常，<code>@Import</code> 和 <code>@Configuration</code> 共同使用，用于在容器中注册对应的 <strong>BeanDefinition</strong>。</p>
<h5 id="configuration"><a class="header" href="#configuration">@Configuration</a></h5>
<p>被 <code>@Configuration</code> 标注的类，通常称为 <strong>配置类</strong>，但配置类，并不单单指标注了 <code>@Configuration</code> 的类</p>
<ul>
<li>标注了 @Configuration 的配置类，称为 FULL 配置类，在 FULL 配置类中注册的 组件类，会在 ConfigurationClassPostProcessor#postProcessBeanFactory 方法中被 ConfigurationClassEnhancer 代理，交由 容器 处理依赖关系</li>
<li>而对于没有标注 <code>@Configuration</code>，但是标注了 <code>@Import</code> <code>Component</code> <code>ComponentScan</code> <code>ImportResource</code> 或者含有被 <code>Bean</code> 注解标注方法的配置类，称为 <strong>LITE</strong> 配置类</li>
<li>对于 FULL配置类 和 LITE配置类，ConfigurationClassPostProcessor 会委托 ConfigurationClassParser 类解析处理对应的 Component @PropertySource @ComponentScan @Import @ImportResource 注解以及标注了 @Bean 的方法</li>
</ul>
<h6 id="full--lite"><a class="header" href="#full--lite">FULL &amp; LITE</a></h6>
<p><strong>FULL配置类</strong> &amp; <strong>LITE配置类</strong> 的区别，可以看以下示例体会</p>
<pre><code class="language-java">public class A {
	public A() {
		System.out.println(&quot;...A&quot;);
	}
}

public class B {
	public B(A a) {
		System.out.println(&quot;...B&quot;);
	}
}

@Configuration
@ComponentScan(&quot;com.xsn.configurationtest&quot;)
public class MyConfigurationConfig {

	@Bean
	public A a() {
		return new A();
	}

	@Bean
	public B b() {
		return new B(a());
	}
}

public static void main(String[] args) {
	AnnotationConfigApplicationContext ac =
			new AnnotationConfigApplicationContext(MyConfigurationConfig.class);

	A a = ac.getBean(A.class);
	System.out.println(a);

	B b = ac.getBean(B.class);
	System.out.println(b);

}

结果：
FULL配置类（加了 @Configuration）：
...A
...B

LITE配置类（注释掉 @Configuration）：
...A
...A
...B

</code></pre>
<p>可以看到在 <strong>FULL配置类</strong> 下，<strong>A</strong> 和 <strong>B</strong> 的 <strong>依赖关系</strong> 将由 <strong>容器</strong> 处理。</p>
<p>我们可以看到，没有 @Configuration 修饰的时候，A 被实例化了两次。</p>
<p>现在我们搞清楚了@Configuration主要是用来做什么的了吧，它就是为了能够让我们spring，比如所我们的springboot或者spring在写上这种@Bean注解的时候（利用Java Config注解来完成对spring环境开发的时候），保证bean的一个作用域，保证它（bean）的生命周期跟它的作用域，包括Scope，Scope就是我们讲的单例（singletion）和原型（prototype）。</p>
<p>正常来说，我们在 B 中实现了 A 就应该是实例化两次，为什么会出现添加了 @Configuration 只实例化一次的情况那？</p>
<p>那么它没有执行两遍只有一个原因，你们可以思考一下，当我们一个方法调用的时候它的预期结果跟你想的不一样，那么你觉得是什么导致的。说白了，就是这个方法被改变了，这个方法不再是原来的这个方法，。因为我们这个方法，它的结果是必然的，它必然会产生一个类，但是我们调用两次它只产生一个类。那就违背了它的必然结果，那就说明了这个代码已经被别人改了。那么被随改了，肯定是被spring改了。那么按照我们现在所学的知识当中，我们要去改变一个方法的行为，没有改源码，可以用什么实现？</p>
<p>在这里用的是cglib动态代理。</p>
<p>不添加 @Configuration</p>
<pre><code class="language-java">public static void main(String[] args) {
	AnnotationConfigApplicationContext ac =
			new AnnotationConfigApplicationContext(MyConfigurationConfig.class);

	MyConfigurationConfig myConfigurationConfig = ac.getBean(MyConfigurationConfig.class);
	System.out.println(myConfigurationConfig);

}

结果：
  （注释掉 @Configuration）
  xxx.MyConfigurationConfig@2833cc44
  （加了 @Configuration）
  xxx.MyConfigurationConfig$$EnhancerBySpringCGLIB$$e52e37ff@588df31b
</code></pre>
<p>当然这里，会有疑问既然加不加 @Configuration 都可以获取 bean，那为什么还要使用那？</p>
<p>别傻了，小伙子，这里只是一个特殊情况，我们自己手动注册实现的，AnnotationConfigApplicationContext 里面会执行 this.register(componentClasses)，正常情况，不添加 @Configuration，Spring 容器根本就不会扫描，怎么可能会获取到 bean 那。</p>
<h5 id="import"><a class="header" href="#import">@Import</a></h5>
<ul>
<li>提供了一种显示地从其他地方加载配置类的方式，这样可以避免使用性能较差的组件扫描（Component Scan）</li>
<li>属性值
<ul>
<li>
<p>@Import 的属性值可以是一个 配置类，此处的配置类，可以是一个 @Configuration 注解标注的配置类（FULL 配置类）、一个标注了 @Import Component ComponentScan ImportResource 或者含有被 Bean 注解标注的方法（LITE 配置类）、甚至一个普通类</p>
</li>
<li>
<p>一个实现了 <strong>ImportSelector</strong> 的类</p>
</li>
<li>
<p>一个实现了 <strong>ImportBeanDefinitionRegistrar</strong> 的类</p>
</li>
</ul>
</li>
</ul>
<p><code>@Import</code> 和 <code>@Configuration</code> 共同使用，用于在容器中注册对应的 <strong>BeanDefinition</strong></p>
<pre><code class="language-java">@Target(ElementType.TYPE)
@Retention(RetentionPolicy.RUNTIME)
@Documented
public @interface Import {

	Class&lt;?&gt;[] value();

}
</code></pre>
<p><strong>配置类</strong></p>
<pre><code class="language-java">public class C {
	public C() {
		System.out.println(&quot;...c&quot;);
	}
}

@Configuration
@ComponentScan(&quot;com.xsn.configurationtest&quot;)
@Import(C.class)
public class MyConfigurationConfig {

}

public static void main(String[] args) {
	AnnotationConfigApplicationContext ac =
			new AnnotationConfigApplicationContext(MyConfigurationConfig.class);

	C c = ac.getBean(C.class);
	System.out.println(c);
}

结果：
com.xsn.configurationtest.C@71ba6d4e
</code></pre>
<p>类 <strong>C</strong> 就是一个普通类，同样也可以 <strong>Import</strong> 一个配置类（<strong>FULL</strong> &amp; <strong>LITE</strong>），如下</p>
<pre><code class="language-java">@Configuration
@Import(C.class)
public class ImportConfiguration {

}

@Configuration
@ComponentScan(&quot;com.xsn.configurationtest&quot;)
@Import(ImportConfiguration.class)
public class MyConfigurationConfig {

}

public static void main(String[] args) {
	AnnotationConfigApplicationContext ac =
			new AnnotationConfigApplicationContext(MyConfigurationConfig.class);

	C c = ac.getBean(C.class);
	System.out.println(c);
}

结果：
com.xsn.configurationtest.C@71ba6d4e
</code></pre>
<h6 id="importselector"><a class="header" href="#importselector">ImportSelector</a></h6>
<p>同样，<code>@Import</code> 注解可以 <strong>Import</strong> 一个 <strong>ImportSelector</strong> 的实现类</p>
<pre><code class="language-java">public interface ImportSelector {

	// 返回要 Import 的配置类名
	String[] selectImports(AnnotationMetadata importingClassMetadata);

	// 允许提供一个 Predicate 过滤 selectImports 方法对应的类
	@Nullable
	default Predicate&lt;String&gt; getExclusionFilter() {
		return null;
	}

}
</code></pre>
<p>类似于直接 Import 配置类，但是 ImportSelector 的实现类可以基于对应配置类的 AnnotationMetadata 属性进行 select，同时还可以实现各种 Aware 接口类似 EnvironmentAware BeanFactoryAware 等，持有对应的 Environment BeanFactory 来进行 select</p>
<pre><code class="language-java">public class MyImportSelector implements ImportSelector {

	@Override
	public String[] selectImports(AnnotationMetadata importingClassMetadata) {
		StandardAnnotationMetadata standardAnnotationMetadata
				= (StandardAnnotationMetadata) importingClassMetadata;
		return new String[]{&quot;com.xsn.configurationtest.C&quot;};
	}

	@Override
	public Predicate&lt;String&gt; getExclusionFilter() {
		return null;
	}
}

@Configuration
@ComponentScan(&quot;com.xsn.configurationtest&quot;)
@Import(MyImportSelector.class)
public class MyConfigurationConfig {

}

public static void main(String[] args) {
	AnnotationConfigApplicationContext ac =
			new AnnotationConfigApplicationContext(MyConfigurationConfig.class);

	C c = ac.getBean(C.class);
	System.out.println(c);
}

结果：
com.xsn.configurationtest.C@5ab956d7
</code></pre>
<h6 id="deferredimportselector"><a class="header" href="#deferredimportselector">DeferredImportSelector</a></h6>
<p><strong>DeferredImportSelector</strong> 继承了 <strong>ImportSelector</strong>，当 <strong>Import</strong> 的是一个 <strong>DeferredImportSelector</strong> 时，该 <strong>DeferredImportSelector</strong> 会在最后解析，主要用于有 <code>@Conditional</code> 注解的配置类</p>
<h6 id="importbeandefinitionregistrar"><a class="header" href="#importbeandefinitionregistrar">ImportBeanDefinitionRegistrar</a></h6>
<p>同样，<code>@Import</code> 注解可以 <strong>Import</strong> 一个 <strong>ImportBeanDefinitionRegistrar</strong> 的实现类</p>
<pre><code class="language-java">public interface ImportBeanDefinitionRegistrar {

	// 基于 AnnotationMetadata BeanDefinitionRegistry 注册对应的 BeanDefinition
	default void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry,
			BeanNameGenerator importBeanNameGenerator) {

		registerBeanDefinitions(importingClassMetadata, registry);
	}

	default void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) {
	}

}
</code></pre>
<p><strong>ImportBeanDefinitionRegistrar</strong> 也可以实现各种 <strong>Aware</strong> 接口类似 <strong>EnvironmentAware</strong> <strong>BeanFactoryAware</strong> 等，持有对应的 <strong>Environment</strong> <strong>BeanFactory</strong> 来进行 <code>register</code></p>
<p>我们使用 <strong>Spring AOP</strong> 时，在配置类上添加的 <code>@EnableAspectJAutoProxy</code> 注解</p>
<pre><code class="language-java">@Target(ElementType.TYPE)
@Retention(RetentionPolicy.RUNTIME)
@Documented
@Import(AspectJAutoProxyRegistrar.class)
public @interface EnableAspectJAutoProxy
</code></pre>
<p>它 Import 的 AspectJAutoProxyRegistrar 便是一个 ImportBeanDefinitionRegistrar，该类会帮我们注册一个 AnnotationAwareAspectJAutoProxyCreator 的 BeanDefinition，实现 AOP 代理</p>
<h3 id="spring-自动装配"><a class="header" href="#spring-自动装配">Spring 自动装配</a></h3>
<p>自动配置：Auto-Configuration</p>
<p>自动装配：Autowire</p>
<p>这是两个不同的东西。</p>
<h4 id="spring注解发展过程"><a class="header" href="#spring注解发展过程">Spring注解发展过程</a></h4>
<p>SpringBoot的自动装配依赖于注解，所以我们先来看一下注解的发展过程。</p>
<p>以下主要对核心注解进行说明</p>
<ul>
<li>
<p><strong>Spring1.0</strong>：刚刚出现注解。</p>
<ul>
<li>@Transaction：简化了事务的操作</li>
</ul>
</li>
<li>
<p><strong>Spring2.0</strong>：一些配置开始被 xml 代替，但是还不能完全摆脱xml，主要是component-scan标签。</p>
<ul>
<li>@Required：用在set方法上，如果加上该注解，表示在xml中必须设置属性的值，不然就会报错。</li>
<li>@Aspect ：AOP相关的一个注解，用来标识配置类。</li>
<li>@Autowired，@Qualifier：依赖注入</li>
<li>@Component，@Service，@Controller，@Repository：主要是声明一些bean对象放入IOC中。</li>
<li>@RequestMapping： 声明请求对应的处理方法</li>
</ul>
</li>
<li>
<p><strong>Spring3.0</strong>：已经完全可以用注解代替xml文件了</p>
<ul>
<li>
<p>@Configuration：配置类，代理xml配置文件</p>
</li>
<li>
<p>@ComponentScan：扫描其他注解，代理xml中的component-scan标签。</p>
</li>
<li>
<p>@Import：只能用在类上，主要是用来加载第三方的类。</p>
<ul>
<li>
<p>@import(value = {XXX.class})：加载一个普通的类</p>
</li>
<li>
<p>@Import(MyImportSelector.class)：这种主要是根据业务选择性加载一些类。</p>
<pre><code class="language-java">public class MyImportSelector implements ImportSelector {//继承该接口
    @Override　　//重写selectImports方法
    public String[] selectImports(AnnotationMetadata importingClassMetadata) {
        //返回对象对应的类型的全类路径的字符串数组
        return new String[]{XXX1.class.getName(), XXX2.class.getName()};
    }
}
</code></pre>
</li>
<li>
<p>@Import(MyImportBeanDefinitionRegistrar.class)：跟上面一样，都是根据业务选择性的加载一些类。只是返回的内容不一样，上面是直接返回选择的类的全路径，这个是将加载的类注册到一个BeanDefinitionRegistry中返回。</p>
<pre><code class="language-java">public class MyImportBeanDefinitionRegistrar implements ImportBeanDefinitionRegistrar {//继承该接口

    @Override   //重写registerBeanDefinitions方法
    public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) {
         // 将需要注册的对象封装为 RootBeanDefinition 对象 
        RootBeanDefinition xxx1 = new RootBeanDefinition(XXX1.class);
        registry.registerBeanDefinition(&quot;xxx1&quot;, xxx1);
        //再注册一个
        RootBeanDefinition xxx2 = new RootBeanDefinition(XXX2.class);
        registry.registerBeanDefinition(&quot;xxx2&quot;, xxx2);
    }
}
</code></pre>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Spring4.0</strong>：</p>
<ul>
<li>
<p>@Conditional：按照一定的条件进行判断，满足条件就给容器注册Bean实例。</p>
<pre><code class="language-java">/**
 * 定义一个 Condition 接口的是实现
 */
public class MyCondition implements Condition {
    @Override
    public boolean matches(ConditionContext context, AnnotatedTypeMetadata metadata) {
        //业务逻辑...
        return false; // 默认返回false
    }
}
</code></pre>
<pre><code class="language-java">//使用
@Configuration
public class JavaConfig {
    @Bean
    // 条件注解，添加的类型必须是 实现了 Condition 接口的类型
    // MyCondition的 matches 方法返回true 则注入，返回false 则不注入
    @Conditional(MyCondition.class)
    public StudentService studentService() {
        return new StudentService();
    }
}
</code></pre>
</li>
</ul>
</li>
<li>
<p><strong>Spring5.0</strong>:</p>
<ul>
<li>@Indexed：在Spring Boot应用场景中，大量使用@ComponentScan扫描，导致Spring模式的注解解析时间耗时增大，因此，5.0时代引入@Indexed，为Spring模式注解添加索引。
<ul>
<li>当我们在项目中使用了 @Indexed 之后，编译打包的时候会在项目中自动生成METAINT/spring.components文件。根据该文件进行扫描注入，可以提高效率。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="springboot自动装配原理"><a class="header" href="#springboot自动装配原理">SpringBoot自动装配原理</a></h4>
<p>自动装配还是利用了SpringFactoriesLoader来加载META-INF/spring.factoires文件里所有配置的EnableAutoConfgruation，它会经过exclude和filter等操作，最终确定要装配的类。</p>
<p><strong>1.一切的开始都源于@SpringBootApplication，它是一个组合注解</strong></p>
<p>除了元注解之外，关注这三个注解：</p>
<pre><code class="language-java">@SpringBootConfiguration
@EnableAutoConfiguration
@ComponentScan
</code></pre>
<ul>
<li>@SpringBootConfiguration该注解的作用是用来指定扫描路径的，如果不指定特定的扫描路径的话，扫描的路径是当前修饰的类所在的包及其子包。</li>
<li>@SpringBootConfiguration这个注解的本质其实是@Configuration注解。</li>
</ul>
<p><strong>2.看来这个@EnableAutoConfiguration不简单</strong></p>
<pre><code class="language-java">@Import(AutoConfigurationImportSelector.class)
</code></pre>
<p>它的内部主要是使用@import注解导入一个选择器。</p>
<p><strong>3.那么我们看看这个AutoConfigurationImportSelector类</strong></p>
<p>上文提到继承ImportSelector接口的类，需要重写 selectImports( )，那我们就看看这个方法</p>
<pre><code class="language-java">@Override
    public String[] selectImports(AnnotationMetadata annotationMetadata) {
        if (!isEnabled(annotationMetadata)) {
            return NO_IMPORTS;
        }
        AutoConfigurationEntry autoConfigurationEntry = getAutoConfigurationEntry(annotationMetadata);
        return StringUtils.toStringArray(autoConfigurationEntry.getConfigurations());
    }
</code></pre>
<p>该方法其实也没说啥，现在的重心就放在getAutoConfigurationEntry()中。</p>
<p><strong>4.getAutoConfigurationEntry()</strong></p>
<pre><code class="language-java">protected AutoConfigurationEntry getAutoConfigurationEntry(AnnotationMetadata annotationMetadata) {
    if (!isEnabled(annotationMetadata)) {
        return EMPTY_ENTRY;
    }　　　　　
    AnnotationAttributes attributes = getAttributes(annotationMetadata);
  	//获取候选配置信息,加载的是当前项目的classpath目录下的所有的 spring.factories 文件中的 key 为  
  	//org.springframework.boot.autoconfigure.EnableAutoConfiguration 的信息。
  	//点进去通过&quot;SpringFactoriesLoader&quot;进行加载
 		List&lt;String&gt; configurations = getCandidateConfigurations(annotationMetadata, attributes);
    // removeDuplicates方法的作用是 移除同名的
    configurations = removeDuplicates(configurations);
    // 获取我们配置的 exclude 信息
    // 比如：@SpringBootApplication(exclude = {RabbitAutoConfiguration.class}) ,显示的指定不要加载那个配置类
    Set&lt;String&gt; exclusions = getExclusions(annotationMetadata, attributes);
    checkExcludedClasses(configurations, exclusions);
    configurations.removeAll(exclusions);
    // filter的作用是 过滤掉咱们不需要使用的配置类。
    configurations = getConfigurationClassFilter().filter(configurations);
    fireAutoConfigurationImportEvents(configurations, exclusions);
    return new AutoConfigurationEntry(configurations, exclusions);
}
</code></pre>
<p><strong>5.前面几个都好理解，现在我们主要看看filter()，是怎么移除不需要的类</strong></p>
<p><img src="https://github.com/chou401/pic-md/raw/master/2597186-20220218230920130-226480162.png" alt="img" /></p>
<p>我们可以看到有具体的匹配方法 match。里面有个关键的属性是 autoConfigurationMetadata , 的本质是 加载的 META-INF/spring-autoconfigure-metadata.properties 的文件中的内容。</p>
<p><img src="https://github.com/chou401/pic-md/raw/master/2597186-20220218231102908-1017908901.png" alt="img" /></p>
<p>其实原理很简单，如果没有对应的实现类，就不进行加载。</p>
<h4 id="何时进行自动装配"><a class="header" href="#何时进行自动装配">何时进行自动装配</a></h4>
<ul>
<li>处理@Configuration的核心还是ConfigurationClassPostProcessor，这个类实现了BeanFactoryPostProcessor,</li>
<li>因此当AbstractApplicationContext执行refresh方法里的invokeBeanFactoryPostProcessors(beanFactory)方法时会执行自动装配</li>
</ul>
<h4 id="run-方法"><a class="header" href="#run-方法">run 方法</a></h4>
<pre><code class="language-java">@SpringBootApplication
public class SpringBootVipDemoApplication {
    public static void main(String[] args) {
        // 基于配置文件的方式
        ApplicationContext ac1 = new ClassPathXmlApplicationContext(&quot;&quot;);
        // 基于Java配置类的方式
        ApplicationContext ac2 = new AnnotationConfigApplicationContext(SpringBootVipDemoApplication.class);
        // run 方法的返回对象是 ConfigurableApplicationContext 对象,
        //ConfigurableApplicationContext就是ApplicationContext的一个子接口
        ConfigurableApplicationContext ac3 = SpringApplication.run(SpringBootVipDemoApplication.class, args);
    }
}
</code></pre>
<p>根据返回结果，我们猜测SpringBoot项目的启动其实就是Spring的初始化操作【IOC】。</p>
<p><img src="https://github.com/chou401/pic-md/raw/master/2597186-20220218232932423-556100027.png" alt="img" /></p>
<h3 id="什么是-starter"><a class="header" href="#什么是-starter">什么是 Starter</a></h3>
<p>starter 是“一站式服务（one-stop）”的依赖 jar 包：</p>
<ul>
<li>包含Spring以及相关技术（比如 Redis）的所有依赖</li>
<li>提供了自动配置的功能，开箱即用</li>
<li>提供了良好的依赖管理，避免了包遗漏、版本冲突等问题。</li>
</ul>
<p><img src="https://github.com/chou401/pic-md/raw/master/image-20230819192249343.png" alt="image-20230819192249343" /></p>
<h3 id="maven-中的可选依赖"><a class="header" href="#maven-中的可选依赖">Maven 中的可选依赖</a></h3>
<p>可选依赖（optional）的作用：阻断“<strong>依赖传递</strong>”</p>
<h3 id="spring-中的注解处理器"><a class="header" href="#spring-中的注解处理器">Spring 中的注解处理器</a></h3>
<p>注解处理器：在编译阶段，生成指定注解的元数据。</p>
<ul>
<li>spring-boot-configuration-processor</li>
<li>spring-boot-autoconfigure-processor</li>
</ul>
<h3 id="自定义装换器"><a class="header" href="#自定义装换器">自定义装换器</a></h3>
<ol>
<li>实现WebMvcConfigurer： 不会覆盖WebMvcAutoConfiguration的配置。</li>
<li>实现WebMvcConfigurer+注解@EnableWebMvc：会覆盖WebMvcAutoConfiguration的配置。</li>
<li>继承WebMvcConfigurationSupport：会覆盖WebMvcAutoConfiguration的配置。</li>
<li>继承DelegatingWebMvcConfiguration：会覆盖WebMvcAutoConfiguration的配置。</li>
</ol>
<h4 id="配置类"><a class="header" href="#配置类">配置类</a></h4>
<h5 id="webmvcconfigurationadapter"><a class="header" href="#webmvcconfigurationadapter">WebMvcConfigurationAdapter</a></h5>
<ul>
<li>WebMvcConfigurerAdapter 是 WebMvcConfigurer 的实现类大部分为空方法，是 WebMvcConfigurer的子类实现，由于Java8中可以使用default关键字为接口添加默认方法，为在源代码中spring5.0之后就已经弃用本类，如果需要可以实现WebMvcConfigurer类。</li>
<li><code>WebMvcConfigurationAdapter</code>已经废弃，最好用<code>WebMvcConfigurer</code>代替。</li>
</ul>
<h5 id="webmvcconfigurationsupport"><a class="header" href="#webmvcconfigurationsupport">WebMvcConfigurationSupport</a></h5>
<ul>
<li>WebMvcConfigurationSupport 是mvc的基本实现并包含了WebMvcConfigurer接口中的方法。</li>
</ul>
<h5 id="webmvcautoconfiguration"><a class="header" href="#webmvcautoconfiguration">WebMvcAutoConfiguration</a></h5>
<ul>
<li>
<p>WebMvcAutoConfiguration 是mvc的自动装在类并部分包含了WebMvcConfigurer接口中的方法。</p>
</li>
<li>
<p>springboot会自动启用WebMvcAutoConfiguration类做自动加载；项目中的配置都是默认的，比如静态资源文件的访问。</p>
</li>
<li>
<pre><code class="language-java">@Configuration
@ConditionalOnWebApplication(type = Type.SERVLET)
@ConditionalOnClass({ Servlet.class, DispatcherServlet.class, WebMvcConfigurer.class })
@ConditionalOnMissingBean(WebMvcConfigurationSupport.class)
@AutoConfigureOrder(Ordered.HIGHEST_PRECEDENCE + 10)
@AutoConfigureAfter({ DispatcherServletAutoConfiguration.class,
		TaskExecutionAutoConfiguration.class, ValidationAutoConfiguration.class })
public class WebMvcAutoConfiguration {
	...
}
</code></pre>
<ul>
<li>
<p>@ConditionalOnMissingBean({WebMvcConfigurationSupport.class})，当Spring容器中不存在WebMvcConfigurationSupportbean，WebMvcAutoConfiguration才会注入。</p>
</li>
<li>
<p>如果有配置文件继承了DelegatingWebMvcConfiguration，或者WebMvcConfigurationSupport，或者配置类注解了@EnableWebMvc，那么WebMvcAutoConfiguration 将不会被自动配置，而是使用WebMvcConfigurationSupport的配置。那么所有实现了WebMvcConfigurer的配置类有可能会全部失效。</p>
</li>
</ul>
</li>
</ul>
<h5 id="webmvcconfigurer"><a class="header" href="#webmvcconfigurer">WebMvcConfigurer</a></h5>
<ul>
<li>
<p>用途：跨域、拦截器、静态资源处理。</p>
</li>
<li>
<p>接口方法的作用：</p>
<pre><code>addInterceptors：拦截器
addViewControllers：页面跳转
addResourceHandlers：静态资源
configureDefaultServletHandling：默认静态资源处理器
configureViewResolvers：视图解析器
configureContentNegotiation：配置内容裁决的一些参数
addCorsMappings：跨域
configureMessageConverters：信息转换器
</code></pre>
</li>
<li>
<p>WebMvcConfigurer配置类其实是<code>Spring</code>内部的种配置方式，可以自定义一些Handler，Interceptor，ViewResolver，MessageConverter等等的东西对springmvc框架进行配置。</p>
</li>
<li>
<pre><code class="language-java">@Configuration
public class MyWebMvcConfigurer implements WebMvcConfigurer {
    @Override
    public void configureMessageConverters(List&lt;HttpMessageConverter&lt;?&gt;&gt; converters) {
        //创建fastJson消息转换器
        FastJsonHttpMessageConverter converter = new FastJsonHttpMessageConverter();

        List&lt;MediaType&gt; supportedMediaTypes = new ArrayList&lt;MediaType&gt;();
        MediaType mediaTypeJson = MediaType.valueOf(MediaType.APPLICATION_JSON_UTF8_VALUE);
        supportedMediaTypes.add(mediaTypeJson);
        converter.setSupportedMediaTypes(supportedMediaTypes);
        //创建配置类
        FastJsonConfig config = new FastJsonConfig();
        config.getSerializeConfig().put(Json.class, new SwaggerJsonSerializer());

        //修改配置返回内容的过滤
        //WriteNullListAsEmpty  ：List字段如果为null,输出为[],而非null
        //WriteNullStringAsEmpty ： 字符类型字段如果为null,输出为&quot;&quot;,而非null
        //DisableCircularReferenceDetect ：消除对同一对象循环引用的问题，默认为false（如果不配置有可能会进入死循环）
        //WriteNullBooleanAsFalse：Boolean字段如果为null,输出为false,而非null
        //WriteMapNullValue：是否输出值为null的字段,默认为false
        //WriteDateUseDateFormat：全局修改日期格式，不添加会导致@JsonFormat失效
        config.setSerializerFeatures(SerializerFeature.WriteMapNullValue
                , SerializerFeature.WriteNonStringKeyAsString,
                SerializerFeature.WriteNullListAsEmpty,
                SerializerFeature.DisableCircularReferenceDetect,
                SerializerFeature.WriteDateUseDateFormat,
                SerializerFeature.WriteNullBooleanAsFalse);
        converter.setFastJsonConfig(config);
        //将fastjson添加到视图消息转换器列表内
        converters.add(0, converter);
        //WebMvcConfigurer失效
        converters.add(converter);
        
    }
}
</code></pre>
</li>
<li>
<p>默认已经有多个消息转换器了。而 configureMessageConverters 方法中是一个 list 参数。直接向其中添加 HttpMessageConverter后，默认是排在最后的。就造成了你自定义的消息转换器不生效。其实是被其他转换器接管了。因此，想要让我们自定义的消息转换器生效只需要把它添加到list 的第一个就可以了。</p>
</li>
<li>
<p>SerializerFeature属性</p>
<p><img src="https://github.com/chou401/pic-md/raw/master/img/image-20230203141903620.png" alt="image-20230203141903620" /></p>
</li>
</ul>
<h4 id="注解"><a class="header" href="#注解">注解</a></h4>
<h5 id="enablewebmvc"><a class="header" href="#enablewebmvc"><strong>@EnableWebMVC</strong></a></h5>
<pre><code class="language-java">@Retention(RetentionPolicy.RUNTIME)
@Target(ElementType.TYPE)
@Documented
@Import(DelegatingWebMvcConfiguration.class)
public @interface EnableWebMvc {
}

</code></pre>
<p>如果引用了<code>@EnableWebMVC</code>注解，就会往spring容器中注入了一个<code>DelegatingWebMvcConfiguration</code>来统一管理所有的配置类。</p>
<pre><code class="language-java">@Configuration
public class DelegatingWebMvcConfiguration extends WebMvcConfigurationSupport {
	private final WebMvcConfigurerComposite configurers = new WebMvcConfigurerComposite();
	...
}

</code></pre>
<p><strong>失效问题解决</strong></p>
<ol>
<li>
<p>在类上加注解解决失效问题</p>
<pre><code class="language-java">@EnableWebMvc
@Configuration
public class WebMvcConfig implements WebMvcConfigurer {
    
}
</code></pre>
<p>@EnableWebMvc表示完全自己控制mvc配置，也就是说所有配置自己重写，所有默认配置都没了！有时会导致很多请求进不来，或者参数转换出错之类的，因为spring mvc默认的转换器已经不生效了,包括全局配置的Jackson也会失效，所以在大多数情况下我们需要的是在其基础配置上添加自定义配置。</p>
</li>
<li>
<p>注解+继承解决失效问题</p>
<pre><code class="language-java">@EnableWebMvc
@Configuration
public class WebMvcConfig extends WebMvcAutoConfiguration implements WebMvcConfigurer {

}
</code></pre>
</li>
</ol>
<p>@SpringBootApplication</p>
<ul>
<li>
<pre><code class="language-java">@Target(ElementType.TYPE)
@Retention(RetentionPolicy.RUNTIME)
@Documented
@Inherited
@SpringBootConfiguration
@EnableAutoConfiguration
@ComponentScan(excludeFilters = {
		@Filter(type = FilterType.CUSTOM, classes = TypeExcludeFilter.class),
		@Filter(type = FilterType.CUSTOM,
				classes = AutoConfigurationExcludeFilter.class) })
public @interface SpringBootApplication {
	@AliasFor(annotation = EnableAutoConfiguration.class)
	Class&lt;?&gt;[] exclude() default {};
	@AliasFor(annotation = EnableAutoConfiguration.class)
	String[] excludeName() default {};
	@AliasFor(annotation = ComponentScan.class, attribute = &quot;basePackages&quot;)
	String[] scanBasePackages() default {};
	@AliasFor(annotation = ComponentScan.class, attribute = &quot;basePackageClasses&quot;)
	Class&lt;?&gt;[] scanBasePackageClasses() default {};
}
 
</code></pre>
<ul>
<li>这里引用了<code>@EnableAutoConfiguration</code>注解</li>
</ul>
</li>
</ul>
<h5 id="enableautoconfiguration"><a class="header" href="#enableautoconfiguration">@EnableAutoConfiguration</a></h5>
<ul>
<li>
<pre><code class="language-java">@Target(ElementType.TYPE)
@Retention(RetentionPolicy.RUNTIME)
@Documented
@Inherited
@AutoConfigurationPackage
@Import(AutoConfigurationImportSelector.class)
public @interface EnableAutoConfiguration {
	String ENABLED_OVERRIDE_PROPERTY = &quot;spring.boot.enableautoconfiguration&quot;;
	Class&lt;?&gt;[] exclude() default {};
	String[] excludeName() default {};

}
</code></pre>
</li>
<li>
<p>注解<code>@AutoConfigurationPackage</code>的主要作用就是：将主程序类所在包及所有子包下的组件到扫描到spring容器中。</p>
</li>
<li>
<pre><code class="language-java">@Target(ElementType.TYPE)
@Retention(RetentionPolicy.RUNTIME)
@Documented
@Inherited
@Import(AutoConfigurationPackages.Registrar.class)
public @interface AutoConfigurationPackage {
}
</code></pre>
</li>
<li>
<p><code>AutoConfigurationImportSelector</code>的作用可以参考：<a href="https://blog.csdn.net/qq_39482039/article/details/120585957">springboot源码自动装配-AutoConfigurationImportSelector</a></p>
</li>
<li>
<pre><code class="language-java">public class AutoConfigurationImportSelector implements DeferredImportSelector, BeanClassLoaderAware,
		ResourceLoaderAware, BeanFactoryAware, EnvironmentAware, Ordered {
	...
	@Override
	public String[] selectImports(AnnotationMetadata annotationMetadata) {
		// 是否启用自动配置
		if (!isEnabled(annotationMetadata)) {
			return NO_IMPORTS;
		}
		// 获取META-INF/spring-autoconfigure-metadata.properties文件的配置，返回AutoConfigurationMetadata类
		AutoConfigurationMetadata autoConfigurationMetadata = AutoConfigurationMetadataLoader
				.loadMetadata(this.beanClassLoader);
		// 获取自动配置类，返回AutoConfigurationEntry
		AutoConfigurationEntry autoConfigurationEntry = getAutoConfigurationEntry(
				autoConfigurationMetadata, annotationMetadata);
		// 返回要自动配置的类名
		return StringUtils.toStringArray(autoConfigurationEntry.getConfigurations());
	}
	...
}
</code></pre>
</li>
<li>
<p>如果引用了<code>@EnableAutoConfiguration</code>注解，就会往spring容器中注入两个类。</p>
<ol>
<li><code>AutoConfigurationPackages.Registrar</code>：扫包。</li>
<li><code>AutoConfigurationImportSelector</code>：等所有类全加载到spring容器之后扫描配置类。</li>
</ol>
</li>
</ul>
<h3 id="junit"><a class="header" href="#junit">junit</a></h3>
<p>spring boot 2，在进行单元测试的时候，<strong>不支持.yml文件</strong>，配件文件需要设置为properties。</p>
<p>pom 中增加testResources，其他操作按照正常创建 test 流程即可。</p>
<pre><code class="language-xml">&lt;build&gt;
        &lt;resources&gt;
            &lt;resource&gt;
                &lt;directory&gt;${basedir}/config/${build.profile.id}/&lt;/directory&gt;
            &lt;/resource&gt;
            &lt;resource&gt;
                &lt;directory&gt;${basedir}/src/main/resources/&lt;/directory&gt;
            &lt;/resource&gt;
        &lt;/resources&gt;
				&lt;finalName&gt;xxxx&lt;/finalName&gt;
        &lt;testResources&gt;
            &lt;testResource&gt;
                &lt;directory&gt;${basedir}/config/${build.profile.id}/&lt;/directory&gt;
            &lt;/testResource&gt;
            &lt;testResource&gt;
                &lt;directory&gt;${basedir}/src/main/resources/&lt;/directory&gt;
            &lt;/testResource&gt;
        &lt;/testResources&gt;
    &lt;/build&gt;
</code></pre>
<h2 id="疑问-1"><a class="header" href="#疑问-1">疑问</a></h2>
<h3 id="守护线程和用户线程有什么区别"><a class="header" href="#守护线程和用户线程有什么区别"><strong>守护线程和用户线程有什么区别？</strong></a></h3>
<ul>
<li>用户（User）线程：运行在前台，执行具体的任务，如程序的主线程、连接网络的子线程等都是用户线程。</li>
<li>守护（Darmon）线程：运行在后台，为其他前台线程服务。也可以说守护线程是JVM中非守护线程的“佣人”。一旦所有用户线程都结束运行，守护线程会随JVM一起结束工作。</li>
</ul>
<p>main函数所在的线程就是一个用户线程，main函数启动的同时在JVM内部同时启动了好多守护线程，比如垃圾回收线程。比较明显的区别之一就是用户线程结束，JVM退出，不管这个时候有没有守护线程运行。而守护线程不会影响JVM的退出。</p>
<p><strong>注意事项</strong></p>
<ol>
<li>setDaemon（true）必须在start（）方法前执行，否则会抛出 IllegalThreadStateException 异常。</li>
<li>在守护线程中产生的新线程也是守护线程。</li>
<li>不是所有的任务都可以分配给守护线程来执行，比如读写操作或者计算逻辑。</li>
<li>守护（Darmon）线程中不能依靠 finally 块的内容来确保执行关闭或清理资源的逻辑。因为我们上面说过了一旦所有用户线程都结束运行，守护线程会随JVM一起结束工作，所有守护（Daemon）线程中的finally 语句块可能无法被执行。</li>
</ol>
<h3 id="mysql56specified-key-was-too-long-max-key-length-is-767-bytes"><a class="header" href="#mysql56specified-key-was-too-long-max-key-length-is-767-bytes">MySQL5.6：Specified key was too long； max key length is 767 bytes</a></h3>
<p>在数据库中，索引的字段设置太长了，导致不支持。<strong>【根本原因：5.6版本的innodb大长度前缀默认是关闭的】</strong></p>
<p>mysql 建立索引时，数据库计算key的长度是累加所有index用到的字段的char长度，按照一定的比例乘起来不能超过限定的key长度767。</p>
<ul>
<li>latin 1 = 1 byte = 1character</li>
<li>uft8 = 3 byte = 1 character</li>
<li>utf8mb4 = 4byte = 1character</li>
<li>gbk = 2 byte = 1 character</li>
</ul>
<pre><code class="language-mysql">CREATE TABLE `xxl_job_registry` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `registry_group` varchar(50) NOT NULL,
  `registry_key` varchar(190) NOT NULL,
  `registry_value` varchar(250) NOT NULL,
  `update_time` datetime DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `i_g_k_v` (`registry_key`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
 
 
registry_key 190 * 4 = 760因此创建成功
 
若将registry_key的字节数改成192，则195 * 4 = 780 则创建不成功
</code></pre>
<p>如果是联合索引时，应该是两个索引的字节加起来，然后折算成字节数。</p>
<pre><code class="language-mysql">CREATE TABLE `xxl_job_registry` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `registry_group` varchar(50) NOT NULL,
  `registry_key` varchar(190) NOT NULL,
  `registry_value` varchar(110) NOT NULL,
  `update_time` datetime DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `i_g_k_v` (`registry_key`, `registry_value`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
 
那么索引需要的字节数是：（190 + 110） * 4 = 1200
创建不成功
 
 
但是实际上呢，是能创建成功。
在创建索引的时候进行了优化，取字节数最长的那个 190 * 4 = 760因此能创建成功。
</code></pre>
<p><strong>解决方法</strong></p>
<ol>
<li>
<p>修改索引的varchar字符，只要让字符 * 字节数 &lt; 767 即可。但是有时某个字段的字符数是一定要足够大的，那就用第二种方式。</p>
</li>
<li>
<pre><code class="language-mysql">// 查看
 
show variables like &quot;innodb_large_prefix&quot;;
 
show variables like &quot;innodb_file_format&quot;;
 
//修改最大索引长度限制
set global innodb_large_prefix=1;
或
set global innodb_large_prefix=on;
 
set global innodb_file_format=BARRACUDA;
</code></pre>
</li>
</ol>
<h3 id="项目开发阶段有一个关于下单发货的需求如果今天下午-3-点前进行下单那么发货时间是明天如果今天下午-3-点后进行下单那么发货时间是后天如果被确定的时间是周日那么在此时间上再加-1-天为发货时间"><a class="header" href="#项目开发阶段有一个关于下单发货的需求如果今天下午-3-点前进行下单那么发货时间是明天如果今天下午-3-点后进行下单那么发货时间是后天如果被确定的时间是周日那么在此时间上再加-1-天为发货时间">项目开发阶段，有一个关于下单发货的需求：如果今天下午 3 点前进行下单，那么发货时间是明天，如果今天下午 3 点后进行下单，那么发货时间是后天，如果被确定的时间是周日，那么在此时间上再加 1 天为发货时间</a></h3>
<pre><code class="language-java">
final DateTime DISTRIBUTION_TIME_SPLIT_TIME = new DateTime().withTime(15,0,0,0);
private Date calculateDistributionTimeByOrderCreateTime(Date orderCreateTime){
    DateTime orderCreateDateTime = new DateTime(orderCreateTime);
    Date tomorrow = orderCreateDateTime.plusDays(1).toDate();
    Date theDayAfterTomorrow = orderCreateDateTime.plusDays(2).toDate();
    return orderCreateDateTime.isAfter(DISTRIBUTION_TIME_SPLIT_TIME) ? wrapDistributionTime(theDayAfterTomorrow) : wrapDistributionTime(tomorrow);
}
private Date wrapDistributionTime(Date distributionTime){
    DateTime currentDistributionDateTime = new DateTime(distributionTime);
    DateTime plusOneDay = currentDistributionDateTime.plusDays(1);
    boolean isSunday = (DateTimeConstants.SUNDAY == currentDistributionDateTime.getDayOfWeek());
    return isSunday ? plusOneDay.toDate() : currentDistributionDateTime.toDate() ;
}
</code></pre>
<h3 id="nacos-多个-ip-挂载-无法下线-did-not-find-the-leader-node"><a class="header" href="#nacos-多个-ip-挂载-无法下线-did-not-find-the-leader-node">nacos 多个 ip 挂载 无法下线 did not find the Leader node</a></h3>
<p>删除 nacos 目录下的 protocol，之后重启 nacos</p>
<pre><code class="language-c">rm -rf protocol
</code></pre>
<p>关闭nacos 服务</p>
<pre><code class="language-c">sh shutdown.sh
</code></pre>
<p>切换到bin目录，执行命令：</p>
<pre><code class="language-c">sh startup.sh -m standalone
</code></pre>
<p>后台运行</p>
<pre><code class="language-c">nohup sh startup.sh -m standalone &amp;
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="threadpoolexecutor"><a class="header" href="#threadpoolexecutor">ThreadPoolExecutor</a></h1>
<h2 id="线程池介绍"><a class="header" href="#线程池介绍">线程池介绍</a></h2>
<p><img src="https://github.com/chou401/pic-md/raw/master/img/image-20230411174505779.png" alt="image-20230411174505779" /></p>
<pre><code class="language-java">// 是个int类型的数值 表达了两个意思 1：声明当前线程池的状态 2：声明线程池中的线程数
// 高3位是线程池状态 低29位是线程池中线程个数
private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));
// 29 方便后面的位运算
private static final int COUNT_BITS = Integer.SIZE - 3;
// 通过位运算得出最大容量
private static final int COUNT_MASK = (1 &lt;&lt; COUNT_BITS) - 1;

// runState is stored in the high-order bits
// 线程池状态
private static final int RUNNING    = -1 &lt;&lt; COUNT_BITS; // 111 代表线程池为RUNNING，代表正常接收任务
private static final int SHUTDOWN   =  0 &lt;&lt; COUNT_BITS; // 000 代表线程池为SHUTDOWN，不接收新任务，但是内部还会处理阻塞队列中的任务，正在进行的任务也会正常处理
private static final int STOP       =  1 &lt;&lt; COUNT_BITS; // 001 代表线程池为STOP，不接收新任务，也不会处理阻塞队列中的任务，同时会中断正在进行的任务
private static final int TIDYING    =  2 &lt;&lt; COUNT_BITS; // 010 代表线程池为TIDYING，过渡的状态，代表当前线程池即将 Game Over
private static final int TERMINATED =  3 &lt;&lt; COUNT_BITS; // 011 代表线程池TERMINATED，代表当前线程池已经 Game Over，要执行terminated()

// Packing and unpacking ctl
private static int runStateOf(int c)     { return c &amp; ~COUNT_MASK; } // 得到线程池的状态
private static int workerCountOf(int c)  { return c &amp; COUNT_MASK; } // 得到当前线程池的线程数量
private static int ctlOf(int rs, int wc) { return rs | wc; } // 得到上面提到的 32 位 int类型的数值
</code></pre>
<h2 id="线程池状态变化"><a class="header" href="#线程池状态变化">线程池状态变化</a></h2>
<p><img src="https://github.com/chou401/pic-md/raw/master/img/image-20230411173800910.png" alt="image-20230411173800910" /></p>
<pre><code class="language-java">public void execute(Runnable command) {
    // 代码健壮性判断
    if (command == null)
        throw new NullPointerException();
    /*
     * Proceed in 3 steps:
     *
     * 1. If fewer than corePoolSize threads are running, try to
     * start a new thread with the given command as its first
     * task.  The call to addWorker atomically checks runState and
     * workerCount, and so prevents false alarms that would add
     * threads when it shouldn't, by returning false.
     *
     * 2. If a task can be successfully queued, then we still need
     * to double-check whether we should have added a thread
     * (because existing ones died since last checking) or that
     * the pool shut down since entry into this method. So we
     * recheck state and if necessary roll back the enqueuing if
     * stopped, or start a new thread if there are none.
     *
     * 3. If we cannot queue task, then we try to add a new
     * thread.  If it fails, we know we are shut down or saturated
     * and so reject the task.
     */
    
    // 拿到32 位的int
    int c = ctl.get();
    // 获取 工作线程数 &lt; 核心线程数
    if (workerCountOf(c) &lt; corePoolSize) {
        // 创建核心线程数
        if (addWorker(command, true))
            return;
        // 创建核心线程数失败，重新获取 ctl
        c = ctl.get();
    }
    // 判断线程池是不是 RUNNING 将任务添加到阻塞队列中
    if (isRunning(c) &amp;&amp; workQueue.offer(command)) {
        int recheck = ctl.get();
        // 再次判断是否 RUNNING 如果不是RUNNING 移除任务
        if (! isRunning(recheck) &amp;&amp; remove(command))
            // 拒绝策略
            reject(command);
        // 如果线程池 处在RUNNING 而且工作线程为0 
        else if (workerCountOf(recheck) == 0)
            // 阻塞队列中有任务 但是没有工作线程 添加一个任务为空的工作线程处理阻塞队列中的任务
            addWorker(null, false);
    }
    // 创建非核心线程 进行处理任务
    else if (!addWorker(command, false))
        // 拒绝策略
        reject(command);
}
</code></pre>
<pre><code class="language-java">private boolean addWorker(Runnable firstTask, boolean core) {
    retry:
    for (int c = ctl.get();;) {
        // Check if queue empty only if necessary.
        if (runStateAtLeast(c, SHUTDOWN) // 除了 RUNNING 都有可能
            &amp;&amp; (runStateAtLeast(c, STOP) // 只可能是STOP或者更高的状态
                || firstTask != null // 任务不为空
                || workQueue.isEmpty())) // 阻塞队列为空
            // 构建工作线程失败
            return false;

        for (;;) {
            if (workerCountOf(c) // 获取工作线程个数
                &gt;= ((core ? corePoolSize : maximumPoolSize) &amp; COUNT_MASK)) // 判断是否超过核心线程或者最大线程
                return false;
            // 将工作线程数+1 采用cas的方式
            if (compareAndIncrementWorkerCount(c))
                break retry;
            c = ctl.get();  // Re-read ctl
            // 重新判断线程池的状态
            if (runStateAtLeast(c, SHUTDOWN))
                continue retry;
            // else CAS failed due to workerCount change; retry inner loop
        }
    }

    boolean workerStarted = false;
    boolean workerAdded = false;
    Worker w = null;
    try {
        // 创建Worker 传入任务
        w = new Worker(firstTask);
        // 从Worker中获取线程 t
        final Thread t = w.thread;
        if (t != null) {
            // 获取线程池的全局锁 避免线程添加任务时，其他线程干掉了线程池 干掉线程池需要先获取这个锁
            final ReentrantLock mainLock = this.mainLock;
            // 加锁
            mainLock.lock();
            try {
                // Recheck while holding lock.
                // Back out on ThreadFactory failure or if
                // shut down before lock acquired.
                int c = ctl.get();

                if (isRunning(c) ||
                    (runStateLessThan(c, STOP) &amp;&amp; firstTask == null)) {
                    // RUNNING 或者 是STOP之后的状态 创建空任务工作线程 用来处理阻塞队列中的任务
                    if (t.getState() != Thread.State.NEW)
                        throw new IllegalThreadStateException();
                    
                    // 将工作线程添加到集合
                    workers.add(w);
                    // workerAdded为true 添加工作线程成功
                    workerAdded = true;
                    // 获取工作线程个数
                    int s = workers.size();
                    // 如果工作线程个数大于之前记录的最大工作线程数 就替换一下
                    if (s &gt; largestPoolSize)
                        largestPoolSize = s;
                }
            } finally {
                mainLock.unlock();
            }
            if (workerAdded) {
                // 启动工作线程
                t.start();
                // 启动工作线程成功
                workerStarted = true;
            }
        }
    } finally {
        // 启动工作线程失败
        if (! workerStarted)
            addWorkerFailed(w);
    }
    return workerStarted;
}
</code></pre>
<pre><code class="language-java">// 如果可以在不超过队列容量的情况下立即插入指定的元素，则在该队列的尾部插入该元素；如果成功，则返回true；如果该队列已满，则返回false
public boolean offer(E e) {
    // 不允许元素为空
    Objects.requireNonNull(e);
    final ReentrantLock lock = this.lock;
    lock.lock(); // 加锁 保证调用 offer 方法的时候只有一个线程
    try {
        // 队列满
        if (count == items.length)
            return false;
        else {
            // 队列未满
            enqueue(e);
            return true;
        }
    } finally {
        // 释放锁 让其他线程可以调用 offer 方法
        lock.unlock();
    }
}
</code></pre>
<pre><code class="language-java">// 在当前放置位置插入元素、前进和发出信号。只有在锁定的情况下才能呼叫。
private void enqueue(E e) {
    final Object[] items = this.items;
    // 元素添加到数组中
    items[putIndex] = e;
    // 当索引满了 修改为0
    if (++putIndex == items.length) putIndex = 0;
    count++;
    // 使用条件对象 notEmpty 通知 比如使用 take 方法的时候队列中没有数据 被阻塞 这个时候队列中插入了数据 需要调用 signal() 进行通知
    notEmpty.signal();
}
</code></pre>
<h2 id="woker"><a class="header" href="#woker">Woker</a></h2>
<pre><code class="language-java">private final class Worker
        extends AbstractQueuedSynchronizer
        implements Runnable {
  /**
   * This class will never be serialized, but we provide a
   * serialVersionUID to suppress a javac warning.
   */
  private static final long serialVersionUID = 6138294804551838833L;

  /** Thread this worker is running in.  Null if factory fails. */
  final Thread thread;
  /** Initial task to run.  Possibly null. */
  Runnable firstTask;
  /** Per-thread task counter */
  volatile long completedTasks;

  // TODO: switch to AbstractQueuedLongSynchronizer and move
  // completedTasks into the lock word.

  /**
   * Creates with given first task and thread from ThreadFactory.
   * @param firstTask the first task (null if none)
   */
  Worker(Runnable firstTask) {
    setState(-1); // inhibit interrupts until runWorker
    this.firstTask = firstTask;
    // 创建 worker 线程 
    this.thread = getThreadFactory().newThread(this);
  }

  /** Delegates main run loop to outer runWorker. */
  public void run() {
    runWorker(this);
  }

  // Lock methods
  //
  // The value 0 represents the unlocked state.
  // The value 1 represents the locked state.

  private boolean isHeldExclusively() {
    return getState() != 0;
  }

  private boolean tryAcquire(int unused) {
    if (compareAndSetState(0, 1)) {
      setExclusiveOwnerThread(Thread.currentThread());
      return true;
    }
    return false;
  }

  private boolean tryRelease(int unused) {
    setExclusiveOwnerThread(null);
    setState(0);
    return true;
  }

  public void lock() {
    acquire(1);
  }

  public boolean tryLock() {
    return tryAcquire(1);
  }

  public void unlock() {
    release(1);
  }

  public boolean isLocked() {
    return isHeldExclusively();
  }

  void interruptIfStarted() {
    Thread t;
    if (getState() &gt;= 0 &amp;&amp; (t = thread) != null &amp;&amp; !t.isInterrupted()) {
      try {
        t.interrupt();
      } catch (SecurityException ignore) {
      }
    }
  }
}
</code></pre>
<pre><code class="language-java">final void runWorker(Worker w) {
    // 获取当前线程
    Thread wt = Thread.currentThread();
    // 获取任务
    Runnable task = w.firstTask;
    w.firstTask = null;
    w.unlock(); // allow interrupts
    boolean completedAbruptly = true;
    try {
        // 任务不为空 执行任务  如果任务为空 通过getTask()从阻塞队列中获取任务
        while (task != null || (task = getTask()) != null) {
            // 加锁 避免被 SHUTDOWN 任务也不会中断
            w.lock();
            //如果线程池状态大于等于STOP，请确保线程被中断；如果没有，请确保线程没有中断。这需要在第二种情况下重新检查，以处理关闭在清除中断时无竞争
            if ((runStateAtLeast(ctl.get(), STOP) ||
                 (Thread.interrupted() &amp;&amp;
                  runStateAtLeast(ctl.get(), STOP))) &amp;&amp;
                !wt.isInterrupted())
                // 中断
                wt.interrupt();
            try {
                // 执行任务前的操作
                beforeExecute(wt, task);
                try {
                    task.run();
                    afterExecute(task, null);
                } catch (Throwable ex) {
                    // 执行任务后的操作
                    afterExecute(task, ex);
                    throw ex;
                }
            } finally {
                task = null;
                w.completedTasks++;
                w.unlock();
            }
        }
        completedAbruptly = false;
    } finally {
        processWorkerExit(w, completedAbruptly);
    }
}
</code></pre>
<h1 id="-4"><a class="header" href="#-4"></a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="homebrew"><a class="header" href="#homebrew">Homebrew</a></h1>
<p>mac 标准安装脚本</p>
<pre><code class="language-bash">/bin/zsh -c &quot;$(curl -fsSL https://gitee.com/cunkai/HomebrewCN/raw/master/Homebrew.sh)&quot;
</code></pre>
<p>mac 卸载脚本</p>
<pre><code class="language-bash">/bin/zsh -c &quot;$(curl -fsSL https://gitee.com/cunkai/HomebrewCN/raw/master/HomebrewUninstall.sh)&quot;
</code></pre>
<p>如果遇到报错中含有errno <strong>54</strong> / <strong>443</strong> / 的问题，这种一般切换源以后没有问题，因为都是公益服务器，不稳定性很大。</p>
<p>使用中科大国内源</p>
<pre><code class="language-bash">/bin/zsh -c &quot;$(curl -fsSL https://gitee.com/cunkai/HomebrewCN/raw/master/Homebrew.sh)&quot;
</code></pre>
<blockquote>
<p>brew help查看帮助</p>
<p>brew -v查看版本</p>
<p>brew update更新brew</p>
<p>brew install &lt;包&gt;安装</p>
<p>brew uninstall &lt;包名&gt;卸载</p>
<p>brew outdated查询可更新的包</p>
<p>brew upgrade 全部更新包
brew upgrade 包名 指定包更新包</p>
<p>brew cleanup清理旧版本</p>
<p>brew info 包名查看包信息</p>
<p>brew list查看安装列表</p>
<p>brew search &lt;包名&gt;查询可用包</p>
</blockquote>
<h1 id="nvm"><a class="header" href="#nvm">nvm</a></h1>
<p>nvm 安装命令，版本号可以从官方最新看到。</p>
<pre><code class="language-bash">curl -o- https://raw.githubusercontent.com/creationix/nvm/v0.39.1/install.sh | bash
</code></pre>
<p>安装中提示</p>
<pre><code> Failed to connect to raw.githubusercontent.com port 443 after 23 ms: Couldn't connect to server
</code></pre>
<p>可以使用 </p>
<pre><code class="language-bash">brew install nvm
</code></pre>
<p>首先要保证之前没有安装过node，如果之前安装过，就先 brew uninstall node。</p>
<p>安装成功之后，环境配置文件 .zshrc 中添加</p>
<pre><code class="language-bash">export NVM_DIR=&quot;$HOME/.nvm&quot;
[ -s &quot;$NVM_DIR/nvm.sh&quot; ] &amp;&amp; \. &quot;$NVM_DIR/nvm.sh&quot;  # This loads nvm
[ -s &quot;$NVM_DIR/bash_completion&quot; ] &amp;&amp; \. &quot;$NVM_DIR/bash_completion&quot;  # This loads nvm bash_completion
</code></pre>
<h1 id="node"><a class="header" href="#node">node</a></h1>
<pre><code class="language-bash">nvm install node
</code></pre>
<p>如果出现卡住无法下载，改国内源。</p>
<p>mac 只需要执行下面这句话就行了</p>
<pre><code class="language-bash">export NVM_NODEJS_ORG_MIRROR=https://npm.taobao.org/mirrors/node/
</code></pre>
<p>windows 需要在nvm的安装路径下，找到settings.txt打开，在后面加加上</p>
<pre><code>node_mirror: https://npm.taobao.org/mirrors/node/ 
npm_mirror: https://npm.taobao.org/mirrors/npm/
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><div class="table-wrapper"><table><thead><tr><th>颜色公式</th><th>颜色效果</th></tr></thead><tbody>
<tr><td>\textcolor{GreenYellow}{GreenYellow}</td><td>$\textcolor{GreenYellow}{GreenYellow} $</td></tr>
<tr><td>\textcolor{Yellow}{Yellow}</td><td>$\textcolor{Yellow}{Yellow}$</td></tr>
<tr><td>\textcolor{Goldenrod}{Goldenrod}</td><td>$\textcolor{Goldenrod}{Goldenrod} $</td></tr>
<tr><td>\textcolor{Dandelion}{Dandelion}</td><td>$\textcolor{Dandelion}{Dandelion}$</td></tr>
<tr><td>\textcolor{Apricot}{Apricot}</td><td>$\textcolor{Apricot}{Apricot} $</td></tr>
<tr><td>\textcolor{Peach}{Peach}</td><td>$\textcolor{Peach}{Peach}$</td></tr>
<tr><td>\textcolor{Melon}{Melon}</td><td>$\textcolor{Melon}{Melon} $</td></tr>
<tr><td>\textcolor{YellowOrange}{YellowOrange}</td><td>$\textcolor{YellowOrange}{YellowOrange}$</td></tr>
<tr><td>\textcolor{Orange}{Orange}</td><td>$\textcolor{Orange}{Orange} $</td></tr>
<tr><td>\textcolor{BurntOrange}{BurntOrange}</td><td>$\textcolor{BurntOrange}{BurntOrange}$</td></tr>
<tr><td>\textcolor{Bittersweet}{Bittersweet}</td><td>$\textcolor{Bittersweet}{Bittersweet}$</td></tr>
<tr><td>\textcolor{RedOrange}{RedOrange}</td><td>$\textcolor{RedOrange}{RedOrange} $</td></tr>
<tr><td>\textcolor{Mahogany}{Mahogany}</td><td>$\textcolor{Mahogany}{Mahogany}$</td></tr>
<tr><td>\textcolor{Maroon}{Maroon}</td><td>$\textcolor{Maroon}{Maroon} $</td></tr>
<tr><td>\textcolor{BrickRed}{BrickRed}</td><td>$\textcolor{BrickRed}{BrickRed}$</td></tr>
<tr><td>\textcolor{Red}{Red}</td><td>$\textcolor{Red}{Red} $</td></tr>
<tr><td>\textcolor{OrangeRed}{OrangeRed}</td><td>$\textcolor{OrangeRed}{OrangeRed}$</td></tr>
<tr><td>\textcolor{RubineRed}{RubineRed}</td><td>$\textcolor{RubineRed}{RubineRed}$</td></tr>
<tr><td>\textcolor{WildStrawberry}{WildStrawberry}</td><td>$\textcolor{WildStrawberry}{WildStrawberry}$</td></tr>
<tr><td>\textcolor{Salmon}{Salmon}</td><td>$\textcolor{Salmon}{Salmon}$</td></tr>
<tr><td>\textcolor{CarnationPink}{CarnationPink}</td><td>$\textcolor{CarnationPink}{CarnationPink}$</td></tr>
<tr><td>\textcolor{Magenta}{Magenta}</td><td>$\textcolor{Magenta}{Magenta} $</td></tr>
<tr><td>\textcolor{VioletRed}{VioletRed}</td><td>$\textcolor{VioletRed}{VioletRed}$</td></tr>
<tr><td>\textcolor{Rhodamine}{Rhodamine}</td><td>$\textcolor{Rhodamine}{Rhodamine} $</td></tr>
<tr><td>\textcolor{Mulberry}{Mulberry}</td><td>$\textcolor{Mulberry}{Mulberry}$</td></tr>
<tr><td>\textcolor{RedViolet}{RedViolet}</td><td>$\textcolor{RedViolet}{RedViolet} $</td></tr>
<tr><td>\textcolor{Fuchsia}{Fuchsia}</td><td>$\textcolor{Fuchsia}{Fuchsia}$</td></tr>
<tr><td>\textcolor{Lavender}{Lavender}</td><td>$\textcolor{Lavender}{Lavender} $</td></tr>
<tr><td>\textcolor{Thistle}{Thistle}</td><td>$\textcolor{Thistle}{Thistle}$</td></tr>
<tr><td>\textcolor{Orchid}{Orchid}</td><td>$\textcolor{Orchid}{Orchid} $</td></tr>
<tr><td>\textcolor{DarkOrchid}{DarkOrchid}</td><td>$\textcolor{DarkOrchid}{DarkOrchid}$</td></tr>
<tr><td>\textcolor{Purple}{Purple}</td><td>$\textcolor{Purple}{Purple} $</td></tr>
<tr><td>\textcolor{Plum}{Plum}</td><td>$\textcolor{Plum}{Plum}$</td></tr>
<tr><td>\textcolor{Violet}{Violet}</td><td>$\textcolor{Violet}{Violet} $</td></tr>
<tr><td>\textcolor{RoyalPurple}{RoyalPurple}</td><td>$\textcolor{RoyalPurple}{RoyalPurple}$</td></tr>
<tr><td>\textcolor{BlueViolet}{BlueViolet}</td><td>$\textcolor{BlueViolet}{BlueViolet}$</td></tr>
<tr><td>\textcolor{Periwinkle}{Periwinkle}</td><td>$\textcolor{Periwinkle}{Periwinkle}$</td></tr>
<tr><td>\textcolor{CadetBlue}{CadetBlue}</td><td>$\textcolor{CadetBlue}{CadetBlue}$</td></tr>
<tr><td>\textcolor{CornflowerBlue}{CornflowerBlue}</td><td>$\textcolor{CornflowerBlue}{CornflowerBlue}$</td></tr>
<tr><td>\textcolor{MidnightBlue}{MidnightBlue}</td><td>$\textcolor{MidnightBlue}{MidnightBlue}$</td></tr>
<tr><td>\textcolor{NavyBlue}{NavyBlue}</td><td>$\textcolor{NavyBlue}{NavyBlue} $</td></tr>
<tr><td>\textcolor{RoyalBlue}{RoyalBlue}</td><td>$\textcolor{RoyalBlue}{RoyalBlue}$</td></tr>
<tr><td>\textcolor{Blue}{Blue}</td><td>$\textcolor{Blue}{Blue} $</td></tr>
<tr><td>\textcolor{Cerulean}{Cerulean}</td><td>$\textcolor{Cerulean}{Cerulean}$</td></tr>
<tr><td>\textcolor{Cyan}{Cyan}</td><td>$\textcolor{Cyan}{Cyan} $</td></tr>
<tr><td>\textcolor{ProcessBlue}{ProcessBlue}</td><td>$\textcolor{ProcessBlue}{ProcessBlue}$</td></tr>
<tr><td>\textcolor{SkyBlue}{SkyBlue}</td><td>$\textcolor{SkyBlue}{SkyBlue} $</td></tr>
<tr><td>\textcolor{Turquoise}{Turquoise}</td><td>$\textcolor{Turquoise}{Turquoise}$</td></tr>
<tr><td>\textcolor{TealBlue}{TealBlue}</td><td>$\textcolor{TealBlue}{TealBlue} $</td></tr>
<tr><td>\textcolor{Aquamarine}{Aquamarine}</td><td>$\textcolor{Aquamarine}{Aquamarine}$</td></tr>
<tr><td>\textcolor{BlueGreen}{BlueGreen}</td><td>$\textcolor{BlueGreen}{BlueGreen} $</td></tr>
<tr><td>\textcolor{Emerald}{Emerald}</td><td>$\textcolor{Emerald}{Emerald}$</td></tr>
<tr><td>\textcolor{JungleGreen}{JungleGreen}</td><td>$\textcolor{JungleGreen}{JungleGreen}$</td></tr>
<tr><td>\textcolor{SeaGreen}{SeaGreen}</td><td>$\textcolor{SeaGreen}{SeaGreen} $</td></tr>
<tr><td>\textcolor{Green}{Green}</td><td>$\textcolor{Green}{Green}$</td></tr>
<tr><td>\textcolor{ForestGreen}{ForestGreen}</td><td>$\textcolor{ForestGreen}{ForestGreen}$</td></tr>
<tr><td>\textcolor{PineGreen}{PineGreen}</td><td>$\textcolor{PineGreen}{PineGreen} $</td></tr>
<tr><td>\textcolor{LimeGreen}{LimeGreen}</td><td>$\textcolor{LimeGreen}{LimeGreen}$</td></tr>
<tr><td>\textcolor{YellowGreen}{YellowGreen}</td><td>$\textcolor{YellowGreen}{YellowGreen}$</td></tr>
<tr><td>\textcolor{SpringGreen}{SpringGreen}</td><td>$\textcolor{SpringGreen}{SpringGreen}$</td></tr>
<tr><td>\textcolor{OliveGreen}{OliveGreen}</td><td>$\textcolor{OliveGreen}{OliveGreen}$</td></tr>
<tr><td>\textcolor{RawSienna}{RawSienna}</td><td>$\textcolor{RawSienna}{RawSienna} $</td></tr>
<tr><td>\textcolor{Sepia}{Sepia}</td><td>$\textcolor{Sepia}{Sepia}$</td></tr>
<tr><td>\textcolor{Brown}{Brown}</td><td>$\textcolor{Brown}{Brown} $</td></tr>
<tr><td>\textcolor{Tan}{Tan}</td><td>$\textcolor{Tan}{Tan}$</td></tr>
<tr><td>\textcolor{Gray}{Gray}</td><td>$\textcolor{Gray}{Gray} $</td></tr>
<tr><td>\textcolor{Black}{Black}</td><td>$\textcolor{Black}{Black}$</td></tr>
<tr><td></td><td></td></tr>
<tr><td></td><td></td></tr>
</tbody></table>
</div>
<p><strong>mac 快捷键</strong></p>
<p>一级标题：⌘1 (command + 1)
二级标题：⌘2 (command + 2)
三级标题：⌘3 (command + 3)
四级标题：⌘4 (command + 4)
五级标题：⌘5 (command + 5)</p>
<p>段落：⌘o 不生效，快捷键冲突，使用⌃o (control + o)</p>
<p>提升标题级别：⌘= (command + =)
降低标题级别：⌘- (command + -)</p>
<p>表格：⌥⌘T (option + command + T)
代码块：⌥⌘C (option + command + C)
公式块：⌥⌘B (option + command + B)</p>
<p>引用：⌥⌘Q (option + command + Q)
有序列表：⌥⌘O (option + command + O)
无序列表：⌥⌘U (option + command + U)</p>
<p>任务列表：⌥⌘X (option + command + X)
列表缩进：
​ 增加缩进：⌘] ( command + ])
​ 减少缩进：⌘[ ( command + [)</p>
<p>链接引用：⌥⌘L (option + command + L)
脚注：⌥⌘R (option + command + R)</p>
<p>水平分割线：⇧⌘- (shift + command + -)</p>
<p>加粗：⌘B (command + B)
斜体：⌘I (command + I)
下划线：⌘U (command + U)</p>
<p>代码：⇧⌘<code>(shift + command +</code>)</p>
<p>内联公式：⌃M (control + M)
删除线：⌃~ (control + ~)
注释：⌃- (control + -)</p>
<p>超链接:⌘K (command + K)
图像：⌃⌘I (control + command + U)
清除样式：⌘\ (command + )</p>
<p>显示/隐藏侧边栏：⇧⌘L (shift + command + L)
大纲视图：⌃⌘1 (control + command + 1)
文档列表视图：⌃⌘2 (control + command +2)
文件树视图：⌃⌘3 (control + command + 3)</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>

    </div>
    </body>
</html>
